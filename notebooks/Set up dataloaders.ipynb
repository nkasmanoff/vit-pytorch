{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate train, valid, and test dataloaders for each of the three datasets\n",
    "\n",
    "To turn the torch datasets into a validation split as well, following the instructions at\n",
    "https://medium.com/@sergioalves94/deep-learning-in-pytorch-with-cifar-10-dataset-858b504a6b54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from linformer import Linformer\n",
    "from PIL import Image\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../vit_pytorch/')\n",
    "sys.path.append('../')\n",
    "\n",
    "from vit import ViT\n",
    "from recorder import Recorder # import the Recorder and instantiate\n",
    "\n",
    "#from vit_pytorch.efficient import ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR 10 first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CIFAR_data(number='10',\n",
    "                   val_size = 5000,\n",
    "                   batch_size = 64,\n",
    "                   transforms=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                                   ])):\n",
    "\n",
    "    if number == '10':\n",
    "        dataset = datasets.CIFAR10(root='../data/', download=True, transform=transforms)\n",
    "        test_dataset = datasets.CIFAR10(root='../data/', train=False, transform=transforms)\n",
    "    elif number == '100': \n",
    "        dataset = datasets.CIFAR100(root='../data/', download=True, transform=transforms)\n",
    "        test_dataset = datasets.CIFAR100(root='../data/', train=False, transform=transforms)\n",
    "        \n",
    "    else:\n",
    "        print(\"Must select 10 or 100\")\n",
    "        sys.exit()\n",
    "        \n",
    "        \n",
    "\n",
    "    train_size = len(dataset) - val_size \n",
    "\n",
    "    train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = get_CIFAR_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dataset = datasets.CIFAR10(root='../data/', download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10(root='../data/', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = {}\n",
    "for _, index in dataset:\n",
    "    label = classes[index]\n",
    "    if label not in class_count:\n",
    "        class_count[label] = 0\n",
    "    class_count[label] += 1\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 5000\n",
    "train_size = len(dataset) - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in train_loader:\n",
    "    print('images.shape:', images.shape)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is basically all we need to do for these torchvision datasets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR100\n",
    "\n",
    "\n",
    "Basically copy and pasting above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = datasets.CIFAR100(root='../data/', download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR100(root='../data/', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_count = {}\n",
    "for _, index in dataset:\n",
    "    label = classes[index]\n",
    "    if label not in class_count:\n",
    "        class_count[label] = 0\n",
    "    class_count[label] += 1\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 5000\n",
    "train_size = len(dataset) - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Proof still balanced after splitting.\")\n",
    "class_count = {}\n",
    "for _, index in val_ds:\n",
    "    label = classes[index]\n",
    "    if label not in class_count:\n",
    "        class_count[label] = 0\n",
    "    class_count[label] += 1\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in train_loader:\n",
    "    print('images.shape:', images.shape)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset found here: https://www.robots.ox.ac.uk/~vgg/data/pets/\n",
    "\n",
    "following code for loading data here: https://github.com/benihime91/pytorch_examples/blob/master/image_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn import preprocessing, model_selection\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None, \"display.max_row\", None)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pets(root_dir = '../data/oxford_iiit_pet2'):\n",
    "    \n",
    "    data_url = 'https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz'\n",
    "    annotations_url = 'https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz'\n",
    "        \n",
    "    #download dataset\n",
    "    if not os.path.exists(root_dir + '/images'):\n",
    "        !wget {data_url} --directory-prefix {root_dir}\n",
    "        !tar -xzf {root_dir + '/images.tar.gz'} --directory {root_dir}\n",
    "    \n",
    "    #download annotations\n",
    "    if not os.path.exists(root_dir + '/annotations'):\n",
    "        !wget {annotations_url} --directory-prefix {root_dir}\n",
    "        !tar -xzf {root_dir + '/annotations.tar.gz'} --directory {root_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 128 #@param{type:\"integer\"}\n",
    "w = 128 #@param{type:\"integer\"}\n",
    "\n",
    "def transforms(trn:bool=False):\n",
    "    if trn: \n",
    "        tfms = [A.CLAHE(), A.IAAPerspective(), A.IAASharpen(), A.RandomBrightness(),\n",
    "                A.Rotate(limit=60), A.HorizontalFlip()]\n",
    "    else: tfms = []\n",
    "    tfms.append(A.Resize(h,w, always_apply=True))\n",
    "    tfms.append(A.Normalize(always_apply=True))\n",
    "    tfms.append(ToTensorV2(always_apply=True))\n",
    "    tfs = A.Compose(tfms)\n",
    "    return tfs\n",
    "\n",
    "\n",
    "class ParseData(Dataset):\n",
    "    def __init__(self, pth, tfms_fn):\n",
    "        self.df = pd.read_csv(pth)\n",
    "        self.tfms = tfms_fn\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        try: pth = self.df.fnames[idx]\n",
    "        except Exception: print(idx)\n",
    "        im = cv2.cvtColor(cv2.imread(pth), cv2.COLOR_BGR2RGB)\n",
    "        im = self.tfms(image=im)[\"image\"]\n",
    "        lbl = self.df.targets[idx]\n",
    "        return im, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PETS_data(root_dir ='../data/oxford_iiit_pet',\n",
    "                 test_size = 0.20,\n",
    "                val_size = 0.20):\n",
    "    \n",
    "    download_pets(root_dir)\n",
    "    \n",
    "    pat = r'/([^/]+)_\\d+.jpg$'\n",
    "    pat = re.compile(pat)\n",
    "    \n",
    "    #collect list of images\n",
    "    desc = Path(root_dir + \"/images\")\n",
    "    ims = list(desc.iterdir())\n",
    "    im_list = []\n",
    "\n",
    "    for im in ims:\n",
    "        if str(im).split(os.path.sep)[-1].split(\".\")[-1] == \"jpg\": im_list.append(str(im))\n",
    "    \n",
    "    #check for and remove corrupted images\n",
    "    print('checking for corrupted images')\n",
    "    for im in tqdm(im_list):\n",
    "        try: _ = cv2.cvtColor(cv2.imread(im), cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            im_list.remove(im)\n",
    "            print(f\"[INFO] Corrupted Image: {im}\")\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    df[\"fnames\"] = im_list\n",
    "    df[\"labels\"] = [ pat.search(fname).group(1).lower() for fname in df.fnames]\n",
    "    df[\"targets\"] = preprocessing.LabelEncoder().fit_transform(df.labels.values)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    y = df.labels.values\n",
    "    \n",
    "    #train, val, test split \n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(df, y, test_size=test_size, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=val_size / (1-test_size), random_state=42)\n",
    "\n",
    "    X_train.to_csv(root_dir + '/train_images.csv', index = False)\n",
    "    X_val.to_csv(root_dir + '/val_images.csv', index = False)\n",
    "    X_test.to_csv(root_dir + '/test_images.csv', index = False)\n",
    "    \n",
    "    train_loader = DataLoader(ParseData(root_dir + '/train_images.csv', transforms(True)),batch_size=128,shuffle=True, pin_memory=True)\n",
    "    val_loader = DataLoader(ParseData(root_dir + '/val_images.csv', transforms(False)),batch_size=128,shuffle=False, pin_memory=True)\n",
    "    test_loader = DataLoader(ParseData(root_dir + '/test_images.csv', transforms(False)),batch_size=128,shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from torchvision.utils import make_grid\n",
    "\n",
    "# # Extract and plot 1 batch for sanity-check\n",
    "# batch = next(iter(train_loader))\n",
    "\n",
    "# im, _ = batch\n",
    "# grid = make_grid(im[:64], normalize=True, padding=True).permute(1, 2, 0)\n",
    "\n",
    "# _, ax = plt.subplots(1, 1, figsize=(22, 15))\n",
    "# ax.imshow(grid.numpy())\n",
    "# ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
