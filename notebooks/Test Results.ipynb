{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incomplete-emission",
   "metadata": {},
   "source": [
    "This notebook contains how to load in the pre-trained weights from some methods best model, along with some figures demonstrating the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "enormous-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pytorch_lightning import Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import cv2\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../vit_pytorch/')\n",
    "sys.path.append('..')\n",
    "from vit import ViT\n",
    "from recorder import Recorder # import the Recorder and instantiate\n",
    "#from dataloaders import *\n",
    "\n",
    "from training_loop import ViT_Trainer\n",
    "from resnet_training_loop import *\n",
    "from resnet import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from argparse import ArgumentParser, Namespace\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from dataloader import get_CIFAR_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "initial-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "model = ResNet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "painful-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_best_model_path = '../vit_pytorch/lightning_logs/version_6668335/checkpoints/epoch=130.ckpt'\n",
    "#best_model_path = '/scratch/nsk367/SP21/vit-pytorch/vit_pytorch/lightning_logs/version_6680321/checkpoints/epoch=64.ckpt'\n",
    "#best_CNN_model_path = '/scratch/nsk367/SP21/vit-pytorch/vit_pytorch/lightning_logs/version_6708167/checkpoints/epoch=36.ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aggregate-raising",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# Init our model\n",
    "model = ViT_Trainer.load_from_checkpoint(base_best_model_path)\n",
    "\n",
    "#model = ViT_Trainer.load_from_checkpoint(best_model_path)\n",
    "#model = CNN_Trainer.load_from_checkpoint(best_CNN_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deadly-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in model.test_dataloader():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dominant-problem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ViTBase'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reserved-tamil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "elder-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "protected-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "clean-agency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58341028"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#count_parameters(model._ViT_Trainer__model)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "welcome-party",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 32, 32])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "seasonal-forty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.4 ms ± 17.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(batch[0].cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-cleaners",
   "metadata": {},
   "source": [
    "128 image batch passed through ResNet 18 which is 11173962 parameters, takes 9.81 ms ± 11.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-confusion",
   "metadata": {},
   "source": [
    "128 image batch passed through ResNet 34 which is 21328292 parameters, takes 17.3 ms ± 7.29 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-cinema",
   "metadata": {},
   "source": [
    "128 image batch passed through ResNet 152 which is 58341028 parameters, takes 90.4 ms ± 17.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-polyester",
   "metadata": {},
   "source": [
    "128 image batch passed through ViT base, which is 85124362 parameters, takes 133 ms ± 1.12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-newport",
   "metadata": {},
   "source": [
    "128 image batch passed through ViT large, which is 302457956 parameters, takes 450 ms ± 1.12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adopted-cabinet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet18 runtime per params  =  8.779338966787251e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"Resnet18 runtime per params  = \", 9.81/11173962 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "closing-reservoir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet34 runtime per params  =  8.111291799643404e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"Resnet34 runtime per params  = \", 17.3/21328292 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "grand-shift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet152 runtime per params  =  1.5495098920780073e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"Resnet152 runtime per params  = \", 90.4/58341028 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "warming-swing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT Base runtime per params  =  1.5624199333206162e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"ViT Base runtime per params  = \", 133/85124362 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "global-aruba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT Large runtime per params  =  1.4878100941738825e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"ViT Large runtime per params  = \", 450/302457956 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-pleasure",
   "metadata": {},
   "source": [
    "While ViT performs worse, it scales much better than "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27 times the parameters, 50 times the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scaling is not particularly helpful. Instead, let's try with vitBase now too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-coaching",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch[0][0].numpy().transpose((1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(batch[0].cuda()).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = batch[0][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rec.attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 128 # using the jth element from that batch \n",
    "attn_mat = model.rec.attn[j].cpu()\n",
    "img = batch[0]\n",
    "im = img[j].cpu().numpy().transpose(1,2,0)\n",
    "attn_mat = torch.mean(attn_mat, dim=1) # average across heads \n",
    "# To account for residual connections, we add an identity matrix to the\n",
    "# attention matrix and re-normalize the weights.\n",
    "residual_att = torch.eye(attn_mat.size(1))\n",
    "aug_att_mat = attn_mat + residual_att\n",
    "aug_att_mat = aug_att_mat / aug_att_mat.sum(dim=-1).unsqueeze(-1)\n",
    "# Recursively multiply the weight matrices\n",
    "joint_attentions = torch.zeros(aug_att_mat.size())\n",
    "joint_attentions[0] = aug_att_mat[0]\n",
    "for n in range(1, aug_att_mat.size(0)):\n",
    "    joint_attentions[n] = torch.matmul(aug_att_mat[n], joint_attentions[n-1])\n",
    "\n",
    "# combines all the different layers which apply attention. \n",
    "\n",
    "# Attention from the output token to the input space.\n",
    "v = joint_attentions[-1]\n",
    "grid_size = int(np.sqrt(aug_att_mat.size(-1)))\n",
    "mask = v[0, 1:].reshape(grid_size, grid_size).detach().numpy()\n",
    "mask = cv2.resize(mask / mask.max(), (model.image_size,model.image_size))[..., np.newaxis]\n",
    "result = (mask * im.astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name[batch[1][j].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name[model(batch[0].cuda()).argmax(dim=1)[j].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "class_name = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-feature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
