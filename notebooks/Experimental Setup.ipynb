{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "marine-guyana",
   "metadata": {},
   "source": [
    "This will need to be done more customizably in .py code, but an example model comparison setup will be made here which we can eventually refactor for comparing the performance of a Vision Transformer vs. Some out of the box ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dressed-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from linformer import Linformer\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../vit_pytorch/')\n",
    "sys.path.append('../')\n",
    "\n",
    "from vit import ViT\n",
    "from recorder import Recorder # import the Recorder and instantiate\n",
    "\n",
    "#from vit_pytorch.efficient import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-occasion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "clean-traffic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 1.8.1+cu102\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "smaller-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training settings\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "lr = 3e-5\n",
    "gamma = 0.7\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "general-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fewer-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "device  = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-issue",
   "metadata": {},
   "source": [
    "Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "difficult-carbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ../data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab68e0c459146d4bf289623e1b635ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169001437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-100-python.tar.gz to ../data\n"
     ]
    }
   ],
   "source": [
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Grayscale(num_output_channels=1),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.,), (1.,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.Grayscale(num_output_channels=1),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.,), (1.,))\n",
    "                   ])),\n",
    "    batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "wicked-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does not have validation, so would not recomend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_dimensions = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-audience",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "focused-pastor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show some images\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy(),cmap='gray')\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prepared-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = Recorder()\n",
    "\n",
    "dim = 128\n",
    "image_size = 28\n",
    "patch_size = image_size // 7\n",
    "channels = 1\n",
    "depth = 64\n",
    "heads = 32\n",
    "mlp_dim = 128\n",
    "dropout = .2\n",
    "num_classes = output_size\n",
    "model = ViT(\n",
    "    dim=dim,\n",
    "    image_size=image_size,\n",
    "    patch_size=patch_size,\n",
    "    num_classes=num_classes,\n",
    "    channels=channels,\n",
    "    depth = depth,\n",
    "    heads=heads, \n",
    "    mlp_dim=mlp_dim,\n",
    "    dropout=dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "square-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "responsible-miami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59207c39f8964102a7438b4a5dc9e8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 - loss : 1.6543 - acc: 0.3777 - val_loss : 0.0011 - val_acc: 0.0006\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc545760f564626ab2e13aec7430ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-98813c34bf26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    for data, label in tqdm(train_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (output.argmax(dim=1) == label).float().mean()\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        for data, label in test_loader: # interchangable with val for this toy experiment\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(val_output, label)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_val_accuracy += acc / test_loader.dataset.__len__()\n",
    "            epoch_val_loss += val_loss / test_loader.dataset.__len__()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "derived-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abandoned-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "canadian-incentive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-quality",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
