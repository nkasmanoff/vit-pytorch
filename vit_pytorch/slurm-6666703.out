/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO:lightning:GPU available: True, used: True
INFO:lightning:CUDA_VISIBLE_DEVICES: [0]
INFO:lightning:Set SLURM handle signals.
INFO:lightning:
    | Name                                                    | Type        | Params
------------------------------------------------------------------------------------
0   | _ViT_Trainer__model                                     | ViT         | 25 M  
1   | _ViT_Trainer__model.to_patch_embedding                  | Sequential  | 25 K  
2   | _ViT_Trainer__model.to_patch_embedding.0                | Rearrange   | 0     
3   | _ViT_Trainer__model.to_patch_embedding.1                | Linear      | 25 K  
4   | _ViT_Trainer__model.dropout                             | Dropout     | 0     
5   | _ViT_Trainer__model.transformer                         | Transformer | 25 M  
6   | _ViT_Trainer__model.transformer.layers                  | ModuleList  | 25 M  
7   | _ViT_Trainer__model.transformer.layers.0                | ModuleList  | 2 M   
8   | _ViT_Trainer__model.transformer.layers.0.0              | PreNorm     | 1 M   
9   | _ViT_Trainer__model.transformer.layers.0.0.norm         | LayerNorm   | 1 K   
10  | _ViT_Trainer__model.transformer.layers.0.0.fn           | Attention   | 1 M   
11  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_qkv    | Linear      | 1 M   
12  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_out    | Sequential  | 393 K 
13  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_out.0  | Linear      | 393 K 
14  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_out.1  | Dropout     | 0     
15  | _ViT_Trainer__model.transformer.layers.0.1              | PreNorm     | 526 K 
16  | _ViT_Trainer__model.transformer.layers.0.1.norm         | LayerNorm   | 1 K   
17  | _ViT_Trainer__model.transformer.layers.0.1.fn           | FeedForward | 525 K 
18  | _ViT_Trainer__model.transformer.layers.0.1.fn.net       | Sequential  | 525 K 
19  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.0     | Linear      | 262 K 
20  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.1     | GELU        | 0     
21  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.2     | Dropout     | 0     
22  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.3     | Linear      | 262 K 
23  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.4     | Dropout     | 0     
24  | _ViT_Trainer__model.transformer.layers.1                | ModuleList  | 2 M   
25  | _ViT_Trainer__model.transformer.layers.1.0              | PreNorm     | 1 M   
26  | _ViT_Trainer__model.transformer.layers.1.0.norm         | LayerNorm   | 1 K   
27  | _ViT_Trainer__model.transformer.layers.1.0.fn           | Attention   | 1 M   
28  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_qkv    | Linear      | 1 M   
29  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_out    | Sequential  | 393 K 
30  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_out.0  | Linear      | 393 K 
31  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_out.1  | Dropout     | 0     
32  | _ViT_Trainer__model.transformer.layers.1.1              | PreNorm     | 526 K 
33  | _ViT_Trainer__model.transformer.layers.1.1.norm         | LayerNorm   | 1 K   
34  | _ViT_Trainer__model.transformer.layers.1.1.fn           | FeedForward | 525 K 
35  | _ViT_Trainer__model.transformer.layers.1.1.fn.net       | Sequential  | 525 K 
36  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.0     | Linear      | 262 K 
37  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.1     | GELU        | 0     
38  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.2     | Dropout     | 0     
39  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.3     | Linear      | 262 K 
40  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.4     | Dropout     | 0     
41  | _ViT_Trainer__model.transformer.layers.2                | ModuleList  | 2 M   
42  | _ViT_Trainer__model.transformer.layers.2.0              | PreNorm     | 1 M   
43  | _ViT_Trainer__model.transformer.layers.2.0.norm         | LayerNorm   | 1 K   
44  | _ViT_Trainer__model.transformer.layers.2.0.fn           | Attention   | 1 M   
45  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_qkv    | Linear      | 1 M   
46  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_out    | Sequential  | 393 K 
47  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_out.0  | Linear      | 393 K 
48  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_out.1  | Dropout     | 0     
49  | _ViT_Trainer__model.transformer.layers.2.1              | PreNorm     | 526 K 
50  | _ViT_Trainer__model.transformer.layers.2.1.norm         | LayerNorm   | 1 K   
51  | _ViT_Trainer__model.transformer.layers.2.1.fn           | FeedForward | 525 K 
52  | _ViT_Trainer__model.transformer.layers.2.1.fn.net       | Sequential  | 525 K 
53  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.0     | Linear      | 262 K 
54  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.1     | GELU        | 0     
55  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.2     | Dropout     | 0     
56  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.3     | Linear      | 262 K 
57  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.4     | Dropout     | 0     
58  | _ViT_Trainer__model.transformer.layers.3                | ModuleList  | 2 M   
59  | _ViT_Trainer__model.transformer.layers.3.0              | PreNorm     | 1 M   
60  | _ViT_Trainer__model.transformer.layers.3.0.norm         | LayerNorm   | 1 K   
61  | _ViT_Trainer__model.transformer.layers.3.0.fn           | Attention   | 1 M   
62  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_qkv    | Linear      | 1 M   
63  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_out    | Sequential  | 393 K 
64  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_out.0  | Linear      | 393 K 
65  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_out.1  | Dropout     | 0     
66  | _ViT_Trainer__model.transformer.layers.3.1              | PreNorm     | 526 K 
67  | _ViT_Trainer__model.transformer.layers.3.1.norm         | LayerNorm   | 1 K   
68  | _ViT_Trainer__model.transformer.layers.3.1.fn           | FeedForward | 525 K 
69  | _ViT_Trainer__model.transformer.layers.3.1.fn.net       | Sequential  | 525 K 
70  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.0     | Linear      | 262 K 
71  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.1     | GELU        | 0     
72  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.2     | Dropout     | 0     
73  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.3     | Linear      | 262 K 
74  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.4     | Dropout     | 0     
75  | _ViT_Trainer__model.transformer.layers.4                | ModuleList  | 2 M   
76  | _ViT_Trainer__model.transformer.layers.4.0              | PreNorm     | 1 M   
77  | _ViT_Trainer__model.transformer.layers.4.0.norm         | LayerNorm   | 1 K   
78  | _ViT_Trainer__model.transformer.layers.4.0.fn           | Attention   | 1 M   
79  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_qkv    | Linear      | 1 M   
80  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_out    | Sequential  | 393 K 
81  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_out.0  | Linear      | 393 K 
82  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_out.1  | Dropout     | 0     
83  | _ViT_Trainer__model.transformer.layers.4.1              | PreNorm     | 526 K 
84  | _ViT_Trainer__model.transformer.layers.4.1.norm         | LayerNorm   | 1 K   
85  | _ViT_Trainer__model.transformer.layers.4.1.fn           | FeedForward | 525 K 
86  | _ViT_Trainer__model.transformer.layers.4.1.fn.net       | Sequential  | 525 K 
87  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.0     | Linear      | 262 K 
88  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.1     | GELU        | 0     
89  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.2     | Dropout     | 0     
90  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.3     | Linear      | 262 K 
91  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.4     | Dropout     | 0     
92  | _ViT_Trainer__model.transformer.layers.5                | ModuleList  | 2 M   
93  | _ViT_Trainer__model.transformer.layers.5.0              | PreNorm     | 1 M   
94  | _ViT_Trainer__model.transformer.layers.5.0.norm         | LayerNorm   | 1 K   
95  | _ViT_Trainer__model.transformer.layers.5.0.fn           | Attention   | 1 M   
96  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_qkv    | Linear      | 1 M   
97  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_out    | Sequential  | 393 K 
98  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_out.0  | Linear      | 393 K 
99  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_out.1  | Dropout     | 0     
100 | _ViT_Trainer__model.transformer.layers.5.1              | PreNorm     | 526 K 
101 | _ViT_Trainer__model.transformer.layers.5.1.norm         | LayerNorm   | 1 K   
102 | _ViT_Trainer__model.transformer.layers.5.1.fn           | FeedForward | 525 K 
103 | _ViT_Trainer__model.transformer.layers.5.1.fn.net       | Sequential  | 525 K 
104 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.0     | Linear      | 262 K 
105 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.1     | GELU        | 0     
106 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.2     | Dropout     | 0     
107 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.3     | Linear      | 262 K 
108 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.4     | Dropout     | 0     
109 | _ViT_Trainer__model.transformer.layers.6                | ModuleList  | 2 M   
110 | _ViT_Trainer__model.transformer.layers.6.0              | PreNorm     | 1 M   
111 | _ViT_Trainer__model.transformer.layers.6.0.norm         | LayerNorm   | 1 K   
112 | _ViT_Trainer__model.transformer.layers.6.0.fn           | Attention   | 1 M   
113 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_qkv    | Linear      | 1 M   
114 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_out    | Sequential  | 393 K 
115 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_out.0  | Linear      | 393 K 
116 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_out.1  | Dropout     | 0     
117 | _ViT_Trainer__model.transformer.layers.6.1              | PreNorm     | 526 K 
118 | _ViT_Trainer__model.transformer.layers.6.1.norm         | LayerNorm   | 1 K   
119 | _ViT_Trainer__model.transformer.layers.6.1.fn           | FeedForward | 525 K 
120 | _ViT_Trainer__model.transformer.layers.6.1.fn.net       | Sequential  | 525 K 
121 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.0     | Linear      | 262 K 
122 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.1     | GELU        | 0     
123 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.2     | Dropout     | 0     
124 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.3     | Linear      | 262 K 
125 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.4     | Dropout     | 0     
126 | _ViT_Trainer__model.transformer.layers.7                | ModuleList  | 2 M   
127 | _ViT_Trainer__model.transformer.layers.7.0              | PreNorm     | 1 M   
128 | _ViT_Trainer__model.transformer.layers.7.0.norm         | LayerNorm   | 1 K   
129 | _ViT_Trainer__model.transformer.layers.7.0.fn           | Attention   | 1 M   
130 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_qkv    | Linear      | 1 M   
131 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_out    | Sequential  | 393 K 
132 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_out.0  | Linear      | 393 K 
133 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_out.1  | Dropout     | 0     
134 | _ViT_Trainer__model.transformer.layers.7.1              | PreNorm     | 526 K 
135 | _ViT_Trainer__model.transformer.layers.7.1.norm         | LayerNorm   | 1 K   
136 | _ViT_Trainer__model.transformer.layers.7.1.fn           | FeedForward | 525 K 
137 | _ViT_Trainer__model.transformer.layers.7.1.fn.net       | Sequential  | 525 K 
138 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.0     | Linear      | 262 K 
139 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.1     | GELU        | 0     
140 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.2     | Dropout     | 0     
141 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.3     | Linear      | 262 K 
142 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.4     | Dropout     | 0     
143 | _ViT_Trainer__model.transformer.layers.8                | ModuleList  | 2 M   
144 | _ViT_Trainer__model.transformer.layers.8.0              | PreNorm     | 1 M   
145 | _ViT_Trainer__model.transformer.layers.8.0.norm         | LayerNorm   | 1 K   
146 | _ViT_Trainer__model.transformer.layers.8.0.fn           | Attention   | 1 M   
147 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_qkv    | Linear      | 1 M   
148 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_out    | Sequential  | 393 K 
149 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_out.0  | Linear      | 393 K 
150 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_out.1  | Dropout     | 0     
151 | _ViT_Trainer__model.transformer.layers.8.1              | PreNorm     | 526 K 
152 | _ViT_Trainer__model.transformer.layers.8.1.norm         | LayerNorm   | 1 K   
153 | _ViT_Trainer__model.transformer.layers.8.1.fn           | FeedForward | 525 K 
154 | _ViT_Trainer__model.transformer.layers.8.1.fn.net       | Sequential  | 525 K 
155 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.0     | Linear      | 262 K 
156 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.1     | GELU        | 0     
157 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.2     | Dropout     | 0     
158 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.3     | Linear      | 262 K 
159 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.4     | Dropout     | 0     
160 | _ViT_Trainer__model.transformer.layers.9                | ModuleList  | 2 M   
161 | _ViT_Trainer__model.transformer.layers.9.0              | PreNorm     | 1 M   
162 | _ViT_Trainer__model.transformer.layers.9.0.norm         | LayerNorm   | 1 K   
163 | _ViT_Trainer__model.transformer.layers.9.0.fn           | Attention   | 1 M   
164 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_qkv    | Linear      | 1 M   
165 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_out    | Sequential  | 393 K 
166 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_out.0  | Linear      | 393 K 
167 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_out.1  | Dropout     | 0     
168 | _ViT_Trainer__model.transformer.layers.9.1              | PreNorm     | 526 K 
169 | _ViT_Trainer__model.transformer.layers.9.1.norm         | LayerNorm   | 1 K   
170 | _ViT_Trainer__model.transformer.layers.9.1.fn           | FeedForward | 525 K 
171 | _ViT_Trainer__model.transformer.layers.9.1.fn.net       | Sequential  | 525 K 
172 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.0     | Linear      | 262 K 
173 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.1     | GELU        | 0     
174 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.2     | Dropout     | 0     
175 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.3     | Linear      | 262 K 
176 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.4     | Dropout     | 0     
177 | _ViT_Trainer__model.transformer.layers.10               | ModuleList  | 2 M   
178 | _ViT_Trainer__model.transformer.layers.10.0             | PreNorm     | 1 M   
179 | _ViT_Trainer__model.transformer.layers.10.0.norm        | LayerNorm   | 1 K   
180 | _ViT_Trainer__model.transformer.layers.10.0.fn          | Attention   | 1 M   
181 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_qkv   | Linear      | 1 M   
182 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_out   | Sequential  | 393 K 
183 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_out.0 | Linear      | 393 K 
184 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_out.1 | Dropout     | 0     
185 | _ViT_Trainer__model.transformer.layers.10.1             | PreNorm     | 526 K 
186 | _ViT_Trainer__model.transformer.layers.10.1.norm        | LayerNorm   | 1 K   
187 | _ViT_Trainer__model.transformer.layers.10.1.fn          | FeedForward | 525 K 
188 | _ViT_Trainer__model.transformer.layers.10.1.fn.net      | Sequential  | 525 K 
189 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.0    | Linear      | 262 K 
190 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.1    | GELU        | 0     
191 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.2    | Dropout     | 0     
192 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.3    | Linear      | 262 K 
193 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.4    | Dropout     | 0     
194 | _ViT_Trainer__model.transformer.layers.11               | ModuleList  | 2 M   
195 | _ViT_Trainer__model.transformer.layers.11.0             | PreNorm     | 1 M   
196 | _ViT_Trainer__model.transformer.layers.11.0.norm        | LayerNorm   | 1 K   
197 | _ViT_Trainer__model.transformer.layers.11.0.fn          | Attention   | 1 M   
198 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_qkv   | Linear      | 1 M   
199 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_out   | Sequential  | 393 K 
200 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_out.0 | Linear      | 393 K 
201 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_out.1 | Dropout     | 0     
202 | _ViT_Trainer__model.transformer.layers.11.1             | PreNorm     | 526 K 
203 | _ViT_Trainer__model.transformer.layers.11.1.norm        | LayerNorm   | 1 K   
204 | _ViT_Trainer__model.transformer.layers.11.1.fn          | FeedForward | 525 K 
205 | _ViT_Trainer__model.transformer.layers.11.1.fn.net      | Sequential  | 525 K 
206 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.0    | Linear      | 262 K 
207 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.1    | GELU        | 0     
208 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.2    | Dropout     | 0     
209 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.3    | Linear      | 262 K 
210 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.4    | Dropout     | 0     
211 | _ViT_Trainer__model.to_latent                           | Identity    | 0     
212 | _ViT_Trainer__model.mlp_head                            | Sequential  | 6 K   
213 | _ViT_Trainer__model.mlp_head.0                          | LayerNorm   | 1 K   
214 | _ViT_Trainer__model.mlp_head.1                          | Linear      | 5 K   
Files already downloaded and verified
Files already downloaded and verified
Validation sanity check: 0it [00:00, ?it/s]WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Validation sanity check:  20%|██        | 1/5 [00:04<00:16,  4.07s/it]Validation sanity check:  40%|████      | 2/5 [00:04<00:05,  1.75s/it]Validation sanity check:  60%|██████    | 3/5 [00:04<00:02,  1.01s/it]Validation sanity check:  80%|████████  | 4/5 [00:04<00:00,  1.52it/s]Validation sanity check: 100%|██████████| 5/5 [00:04<00:00,  2.13it/s]                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/196 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/196 [00:00<?, ?it/s] /scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Epoch 1:   1%|          | 1/196 [00:01<04:16,  1.32s/it]Epoch 1:   1%|          | 1/196 [00:01<04:17,  1.32s/it, loss=2.646, v_num=6666703]Epoch 1:   1%|          | 2/196 [00:01<02:41,  1.20it/s, loss=2.646, v_num=6666703]Epoch 1:   1%|          | 2/196 [00:01<02:41,  1.20it/s, loss=3.044, v_num=6666703]Epoch 1:   2%|▏         | 3/196 [00:02<02:09,  1.49it/s, loss=3.044, v_num=6666703]Epoch 1:   2%|▏         | 3/196 [00:02<02:09,  1.49it/s, loss=3.435, v_num=6666703]Epoch 1:   2%|▏         | 4/196 [00:02<01:53,  1.69it/s, loss=3.435, v_num=6666703]Epoch 1:   2%|▏         | 4/196 [00:02<01:53,  1.69it/s, loss=3.563, v_num=6666703]Epoch 1:   3%|▎         | 5/196 [00:02<01:43,  1.84it/s, loss=3.563, v_num=6666703]Epoch 1:   3%|▎         | 5/196 [00:02<01:43,  1.84it/s, loss=3.540, v_num=6666703]Epoch 1:   3%|▎         | 6/196 [00:03<01:37,  1.95it/s, loss=3.540, v_num=6666703]Epoch 1:   3%|▎         | 6/196 [00:03<01:37,  1.95it/s, loss=3.501, v_num=6666703]Epoch 1:   4%|▎         | 7/196 [00:03<01:32,  2.05it/s, loss=3.501, v_num=6666703]Epoch 1:   4%|▎         | 7/196 [00:03<01:32,  2.05it/s, loss=3.365, v_num=6666703]Epoch 1:   4%|▍         | 8/196 [00:03<01:28,  2.12it/s, loss=3.365, v_num=6666703]Epoch 1:   4%|▍         | 8/196 [00:03<01:28,  2.12it/s, loss=3.426, v_num=6666703]Epoch 1:   5%|▍         | 9/196 [00:04<01:25,  2.18it/s, loss=3.426, v_num=6666703]Epoch 1:   5%|▍         | 9/196 [00:04<01:25,  2.18it/s, loss=3.300, v_num=6666703]Epoch 1:   5%|▌         | 10/196 [00:04<01:23,  2.23it/s, loss=3.300, v_num=6666703]Epoch 1:   5%|▌         | 10/196 [00:04<01:23,  2.23it/s, loss=3.206, v_num=6666703]Epoch 1:   6%|▌         | 11/196 [00:04<01:21,  2.28it/s, loss=3.206, v_num=6666703]Epoch 1:   6%|▌         | 11/196 [00:04<01:21,  2.28it/s, loss=3.137, v_num=6666703]Epoch 1:   6%|▌         | 12/196 [00:05<01:19,  2.32it/s, loss=3.137, v_num=6666703]Epoch 1:   6%|▌         | 12/196 [00:05<01:19,  2.32it/s, loss=3.069, v_num=6666703]Epoch 1:   7%|▋         | 13/196 [00:05<01:17,  2.35it/s, loss=3.069, v_num=6666703]Epoch 1:   7%|▋         | 13/196 [00:05<01:18,  2.35it/s, loss=3.009, v_num=6666703]Epoch 1:   7%|▋         | 14/196 [00:05<01:16,  2.37it/s, loss=3.009, v_num=6666703]Epoch 1:   7%|▋         | 14/196 [00:05<01:16,  2.37it/s, loss=2.952, v_num=6666703]Epoch 1:   8%|▊         | 15/196 [00:06<01:15,  2.40it/s, loss=2.952, v_num=6666703]Epoch 1:   8%|▊         | 15/196 [00:06<01:15,  2.40it/s, loss=2.901, v_num=6666703]Epoch 1:   8%|▊         | 16/196 [00:06<01:14,  2.43it/s, loss=2.901, v_num=6666703]Epoch 1:   8%|▊         | 16/196 [00:06<01:14,  2.43it/s, loss=2.859, v_num=6666703]Epoch 1:   9%|▊         | 17/196 [00:06<01:13,  2.45it/s, loss=2.859, v_num=6666703]Epoch 1:   9%|▊         | 17/196 [00:06<01:13,  2.45it/s, loss=2.821, v_num=6666703]Epoch 1:   9%|▉         | 18/196 [00:07<01:12,  2.47it/s, loss=2.821, v_num=6666703]Epoch 1:   9%|▉         | 18/196 [00:07<01:12,  2.47it/s, loss=2.786, v_num=6666703]Epoch 1:  10%|▉         | 19/196 [00:07<01:11,  2.49it/s, loss=2.786, v_num=6666703]Epoch 1:  10%|▉         | 19/196 [00:07<01:11,  2.49it/s, loss=2.754, v_num=6666703]Epoch 1:  10%|█         | 20/196 [00:07<01:10,  2.50it/s, loss=2.754, v_num=6666703]Epoch 1:  10%|█         | 20/196 [00:07<01:10,  2.50it/s, loss=2.722, v_num=6666703]Epoch 1:  11%|█         | 21/196 [00:08<01:09,  2.52it/s, loss=2.722, v_num=6666703]Epoch 1:  11%|█         | 21/196 [00:08<01:09,  2.52it/s, loss=2.696, v_num=6666703]Epoch 1:  11%|█         | 22/196 [00:08<01:08,  2.53it/s, loss=2.696, v_num=6666703]Epoch 1:  11%|█         | 22/196 [00:08<01:08,  2.53it/s, loss=2.625, v_num=6666703]Epoch 1:  12%|█▏        | 23/196 [00:09<01:08,  2.54it/s, loss=2.625, v_num=6666703]Epoch 1:  12%|█▏        | 23/196 [00:09<01:08,  2.54it/s, loss=2.522, v_num=6666703]Epoch 1:  12%|█▏        | 24/196 [00:09<01:07,  2.55it/s, loss=2.522, v_num=6666703]Epoch 1:  12%|█▏        | 24/196 [00:09<01:07,  2.55it/s, loss=2.428, v_num=6666703]Epoch 1:  13%|█▎        | 25/196 [00:09<01:07,  2.55it/s, loss=2.428, v_num=6666703]Epoch 1:  13%|█▎        | 25/196 [00:09<01:07,  2.55it/s, loss=2.358, v_num=6666703]Epoch 1:  13%|█▎        | 26/196 [00:10<01:06,  2.56it/s, loss=2.358, v_num=6666703]Epoch 1:  13%|█▎        | 26/196 [00:10<01:06,  2.56it/s, loss=2.295, v_num=6666703]Epoch 1:  14%|█▍        | 27/196 [00:10<01:05,  2.57it/s, loss=2.295, v_num=6666703]Epoch 1:  14%|█▍        | 27/196 [00:10<01:05,  2.57it/s, loss=2.269, v_num=6666703]Epoch 1:  14%|█▍        | 28/196 [00:10<01:05,  2.58it/s, loss=2.269, v_num=6666703]Epoch 1:  14%|█▍        | 28/196 [00:10<01:05,  2.58it/s, loss=2.177, v_num=6666703]Epoch 1:  15%|█▍        | 29/196 [00:11<01:04,  2.58it/s, loss=2.177, v_num=6666703]Epoch 1:  15%|█▍        | 29/196 [00:11<01:04,  2.58it/s, loss=2.169, v_num=6666703]Epoch 1:  15%|█▌        | 30/196 [00:11<01:04,  2.59it/s, loss=2.169, v_num=6666703]Epoch 1:  15%|█▌        | 30/196 [00:11<01:04,  2.59it/s, loss=2.155, v_num=6666703]Epoch 1:  16%|█▌        | 31/196 [00:11<01:03,  2.60it/s, loss=2.155, v_num=6666703]Epoch 1:  16%|█▌        | 31/196 [00:11<01:03,  2.60it/s, loss=2.136, v_num=6666703]Epoch 1:  16%|█▋        | 32/196 [00:12<01:02,  2.61it/s, loss=2.136, v_num=6666703]Epoch 1:  16%|█▋        | 32/196 [00:12<01:02,  2.61it/s, loss=2.123, v_num=6666703]Epoch 1:  17%|█▋        | 33/196 [00:12<01:02,  2.61it/s, loss=2.123, v_num=6666703]Epoch 1:  17%|█▋        | 33/196 [00:12<01:02,  2.61it/s, loss=2.111, v_num=6666703]Epoch 1:  17%|█▋        | 34/196 [00:12<01:01,  2.62it/s, loss=2.111, v_num=6666703]Epoch 1:  17%|█▋        | 34/196 [00:12<01:01,  2.62it/s, loss=2.102, v_num=6666703]Epoch 1:  18%|█▊        | 35/196 [00:13<01:01,  2.62it/s, loss=2.102, v_num=6666703]Epoch 1:  18%|█▊        | 35/196 [00:13<01:01,  2.62it/s, loss=2.099, v_num=6666703]Epoch 1:  18%|█▊        | 36/196 [00:13<01:00,  2.63it/s, loss=2.099, v_num=6666703]Epoch 1:  18%|█▊        | 36/196 [00:13<01:00,  2.63it/s, loss=2.092, v_num=6666703]Epoch 1:  19%|█▉        | 37/196 [00:14<01:00,  2.63it/s, loss=2.092, v_num=6666703]Epoch 1:  19%|█▉        | 37/196 [00:14<01:00,  2.63it/s, loss=2.085, v_num=6666703]Epoch 1:  19%|█▉        | 38/196 [00:14<00:59,  2.64it/s, loss=2.085, v_num=6666703]Epoch 1:  19%|█▉        | 38/196 [00:14<00:59,  2.64it/s, loss=2.078, v_num=6666703]Epoch 1:  20%|█▉        | 39/196 [00:14<00:59,  2.64it/s, loss=2.078, v_num=6666703]Epoch 1:  20%|█▉        | 39/196 [00:14<00:59,  2.64it/s, loss=2.072, v_num=6666703]Epoch 1:  20%|██        | 40/196 [00:15<00:58,  2.65it/s, loss=2.072, v_num=6666703]Epoch 1:  20%|██        | 40/196 [00:15<00:58,  2.65it/s, loss=2.069, v_num=6666703]Epoch 1:  21%|██        | 41/196 [00:15<00:58,  2.65it/s, loss=2.069, v_num=6666703]Epoch 1:  21%|██        | 41/196 [00:15<00:58,  2.65it/s, loss=2.062, v_num=6666703]Epoch 1:  21%|██▏       | 42/196 [00:15<00:58,  2.65it/s, loss=2.062, v_num=6666703]Epoch 1:  21%|██▏       | 42/196 [00:15<00:58,  2.65it/s, loss=2.063, v_num=6666703]Epoch 1:  22%|██▏       | 43/196 [00:16<00:57,  2.65it/s, loss=2.063, v_num=6666703]Epoch 1:  22%|██▏       | 43/196 [00:16<00:57,  2.65it/s, loss=2.056, v_num=6666703]Epoch 1:  22%|██▏       | 44/196 [00:16<00:57,  2.66it/s, loss=2.056, v_num=6666703]Epoch 1:  22%|██▏       | 44/196 [00:16<00:57,  2.66it/s, loss=2.056, v_num=6666703]Epoch 1:  23%|██▎       | 45/196 [00:16<00:56,  2.66it/s, loss=2.056, v_num=6666703]Epoch 1:  23%|██▎       | 45/196 [00:16<00:56,  2.66it/s, loss=2.051, v_num=6666703]Epoch 1:  23%|██▎       | 46/196 [00:17<00:56,  2.66it/s, loss=2.051, v_num=6666703]Epoch 1:  23%|██▎       | 46/196 [00:17<00:56,  2.66it/s, loss=2.045, v_num=6666703]Epoch 1:  24%|██▍       | 47/196 [00:17<00:55,  2.67it/s, loss=2.045, v_num=6666703]Epoch 1:  24%|██▍       | 47/196 [00:17<00:55,  2.66it/s, loss=2.048, v_num=6666703]Epoch 1:  24%|██▍       | 48/196 [00:17<00:55,  2.67it/s, loss=2.048, v_num=6666703]Epoch 1:  24%|██▍       | 48/196 [00:17<00:55,  2.67it/s, loss=2.048, v_num=6666703]Epoch 1:  25%|██▌       | 49/196 [00:18<00:54,  2.67it/s, loss=2.048, v_num=6666703]Epoch 1:  25%|██▌       | 49/196 [00:18<00:54,  2.67it/s, loss=2.043, v_num=6666703]Epoch 1:  26%|██▌       | 50/196 [00:18<00:54,  2.68it/s, loss=2.043, v_num=6666703]Epoch 1:  26%|██▌       | 50/196 [00:18<00:54,  2.68it/s, loss=2.036, v_num=6666703]Epoch 1:  26%|██▌       | 51/196 [00:19<00:54,  2.68it/s, loss=2.036, v_num=6666703]Epoch 1:  26%|██▌       | 51/196 [00:19<00:54,  2.68it/s, loss=2.027, v_num=6666703]Epoch 1:  27%|██▋       | 52/196 [00:19<00:53,  2.68it/s, loss=2.027, v_num=6666703]Epoch 1:  27%|██▋       | 52/196 [00:19<00:53,  2.68it/s, loss=2.021, v_num=6666703]Epoch 1:  27%|██▋       | 53/196 [00:19<00:53,  2.69it/s, loss=2.021, v_num=6666703]Epoch 1:  27%|██▋       | 53/196 [00:19<00:53,  2.69it/s, loss=2.019, v_num=6666703]Epoch 1:  28%|██▊       | 54/196 [00:20<00:52,  2.69it/s, loss=2.019, v_num=6666703]Epoch 1:  28%|██▊       | 54/196 [00:20<00:52,  2.69it/s, loss=2.017, v_num=6666703]Epoch 1:  28%|██▊       | 55/196 [00:20<00:52,  2.69it/s, loss=2.017, v_num=6666703]Epoch 1:  28%|██▊       | 55/196 [00:20<00:52,  2.69it/s, loss=2.008, v_num=6666703]Epoch 1:  29%|██▊       | 56/196 [00:20<00:51,  2.69it/s, loss=2.008, v_num=6666703]Epoch 1:  29%|██▊       | 56/196 [00:20<00:51,  2.69it/s, loss=2.003, v_num=6666703]Epoch 1:  29%|██▉       | 57/196 [00:21<00:51,  2.70it/s, loss=2.003, v_num=6666703]Epoch 1:  29%|██▉       | 57/196 [00:21<00:51,  2.70it/s, loss=2.000, v_num=6666703]Epoch 1:  30%|██▉       | 58/196 [00:21<00:51,  2.70it/s, loss=2.000, v_num=6666703]Epoch 1:  30%|██▉       | 58/196 [00:21<00:51,  2.70it/s, loss=1.996, v_num=6666703]Epoch 1:  30%|███       | 59/196 [00:21<00:50,  2.70it/s, loss=1.996, v_num=6666703]Epoch 1:  30%|███       | 59/196 [00:21<00:50,  2.70it/s, loss=1.991, v_num=6666703]Epoch 1:  31%|███       | 60/196 [00:22<00:50,  2.70it/s, loss=1.991, v_num=6666703]Epoch 1:  31%|███       | 60/196 [00:22<00:50,  2.70it/s, loss=1.988, v_num=6666703]Epoch 1:  31%|███       | 61/196 [00:22<00:49,  2.70it/s, loss=1.988, v_num=6666703]Epoch 1:  31%|███       | 61/196 [00:22<00:49,  2.70it/s, loss=1.989, v_num=6666703]Epoch 1:  32%|███▏      | 62/196 [00:22<00:49,  2.71it/s, loss=1.989, v_num=6666703]Epoch 1:  32%|███▏      | 62/196 [00:22<00:49,  2.71it/s, loss=1.985, v_num=6666703]Epoch 1:  32%|███▏      | 63/196 [00:23<00:49,  2.71it/s, loss=1.985, v_num=6666703]Epoch 1:  32%|███▏      | 63/196 [00:23<00:49,  2.71it/s, loss=1.978, v_num=6666703]Epoch 1:  33%|███▎      | 64/196 [00:23<00:48,  2.71it/s, loss=1.978, v_num=6666703]Epoch 1:  33%|███▎      | 64/196 [00:23<00:48,  2.71it/s, loss=1.972, v_num=6666703]Epoch 1:  33%|███▎      | 65/196 [00:23<00:48,  2.71it/s, loss=1.972, v_num=6666703]Epoch 1:  33%|███▎      | 65/196 [00:23<00:48,  2.71it/s, loss=1.972, v_num=6666703]Epoch 1:  34%|███▎      | 66/196 [00:24<00:47,  2.71it/s, loss=1.972, v_num=6666703]Epoch 1:  34%|███▎      | 66/196 [00:24<00:47,  2.71it/s, loss=1.973, v_num=6666703]Epoch 1:  34%|███▍      | 67/196 [00:24<00:47,  2.72it/s, loss=1.973, v_num=6666703]Epoch 1:  34%|███▍      | 67/196 [00:24<00:47,  2.72it/s, loss=1.968, v_num=6666703]Epoch 1:  35%|███▍      | 68/196 [00:25<00:47,  2.72it/s, loss=1.968, v_num=6666703]Epoch 1:  35%|███▍      | 68/196 [00:25<00:47,  2.72it/s, loss=1.963, v_num=6666703]Epoch 1:  35%|███▌      | 69/196 [00:25<00:46,  2.72it/s, loss=1.963, v_num=6666703]Epoch 1:  35%|███▌      | 69/196 [00:25<00:46,  2.72it/s, loss=1.954, v_num=6666703]Epoch 1:  36%|███▌      | 70/196 [00:25<00:46,  2.72it/s, loss=1.954, v_num=6666703]Epoch 1:  36%|███▌      | 70/196 [00:25<00:46,  2.72it/s, loss=1.955, v_num=6666703]Epoch 1:  36%|███▌      | 71/196 [00:26<00:45,  2.72it/s, loss=1.955, v_num=6666703]Epoch 1:  36%|███▌      | 71/196 [00:26<00:45,  2.72it/s, loss=1.957, v_num=6666703]Epoch 1:  37%|███▋      | 72/196 [00:26<00:45,  2.73it/s, loss=1.957, v_num=6666703]Epoch 1:  37%|███▋      | 72/196 [00:26<00:45,  2.73it/s, loss=1.956, v_num=6666703]Epoch 1:  37%|███▋      | 73/196 [00:26<00:45,  2.73it/s, loss=1.956, v_num=6666703]Epoch 1:  37%|███▋      | 73/196 [00:26<00:45,  2.73it/s, loss=1.954, v_num=6666703]Epoch 1:  38%|███▊      | 74/196 [00:27<00:44,  2.73it/s, loss=1.954, v_num=6666703]Epoch 1:  38%|███▊      | 74/196 [00:27<00:44,  2.73it/s, loss=1.952, v_num=6666703]Epoch 1:  38%|███▊      | 75/196 [00:27<00:44,  2.73it/s, loss=1.952, v_num=6666703]Epoch 1:  38%|███▊      | 75/196 [00:27<00:44,  2.73it/s, loss=1.953, v_num=6666703]Epoch 1:  39%|███▉      | 76/196 [00:27<00:43,  2.73it/s, loss=1.953, v_num=6666703]Epoch 1:  39%|███▉      | 76/196 [00:27<00:43,  2.73it/s, loss=1.948, v_num=6666703]Epoch 1:  39%|███▉      | 77/196 [00:28<00:43,  2.73it/s, loss=1.948, v_num=6666703]Epoch 1:  39%|███▉      | 77/196 [00:28<00:43,  2.73it/s, loss=1.946, v_num=6666703]Epoch 1:  40%|███▉      | 78/196 [00:28<00:43,  2.74it/s, loss=1.946, v_num=6666703]Epoch 1:  40%|███▉      | 78/196 [00:28<00:43,  2.74it/s, loss=1.948, v_num=6666703]Epoch 1:  40%|████      | 79/196 [00:28<00:42,  2.74it/s, loss=1.948, v_num=6666703]Epoch 1:  40%|████      | 79/196 [00:28<00:42,  2.74it/s, loss=1.947, v_num=6666703]Epoch 1:  41%|████      | 80/196 [00:29<00:42,  2.74it/s, loss=1.947, v_num=6666703]Epoch 1:  41%|████      | 80/196 [00:29<00:42,  2.74it/s, loss=1.939, v_num=6666703]Epoch 1:  41%|████▏     | 81/196 [00:29<00:41,  2.74it/s, loss=1.939, v_num=6666703]Epoch 1:  41%|████▏     | 81/196 [00:29<00:41,  2.74it/s, loss=1.936, v_num=6666703]Epoch 1:  42%|████▏     | 82/196 [00:29<00:41,  2.74it/s, loss=1.936, v_num=6666703]Epoch 1:  42%|████▏     | 82/196 [00:29<00:41,  2.74it/s, loss=1.935, v_num=6666703]Epoch 1:  42%|████▏     | 83/196 [00:30<00:41,  2.74it/s, loss=1.935, v_num=6666703]Epoch 1:  42%|████▏     | 83/196 [00:30<00:41,  2.74it/s, loss=1.933, v_num=6666703]Epoch 1:  43%|████▎     | 84/196 [00:30<00:40,  2.74it/s, loss=1.933, v_num=6666703]Epoch 1:  43%|████▎     | 84/196 [00:30<00:40,  2.74it/s, loss=1.928, v_num=6666703]Epoch 1:  43%|████▎     | 85/196 [00:30<00:40,  2.74it/s, loss=1.928, v_num=6666703]Epoch 1:  43%|████▎     | 85/196 [00:30<00:40,  2.74it/s, loss=1.929, v_num=6666703]Epoch 1:  44%|████▍     | 86/196 [00:31<00:40,  2.74it/s, loss=1.929, v_num=6666703]Epoch 1:  44%|████▍     | 86/196 [00:31<00:40,  2.74it/s, loss=1.933, v_num=6666703]Epoch 1:  44%|████▍     | 87/196 [00:31<00:39,  2.75it/s, loss=1.933, v_num=6666703]Epoch 1:  44%|████▍     | 87/196 [00:31<00:39,  2.75it/s, loss=1.930, v_num=6666703]Epoch 1:  45%|████▍     | 88/196 [00:32<00:39,  2.75it/s, loss=1.930, v_num=6666703]Epoch 1:  45%|████▍     | 88/196 [00:32<00:39,  2.75it/s, loss=1.929, v_num=6666703]Epoch 1:  45%|████▌     | 89/196 [00:32<00:38,  2.75it/s, loss=1.929, v_num=6666703]Epoch 1:  45%|████▌     | 89/196 [00:32<00:38,  2.75it/s, loss=1.938, v_num=6666703]Epoch 1:  46%|████▌     | 90/196 [00:32<00:38,  2.75it/s, loss=1.938, v_num=6666703]Epoch 1:  46%|████▌     | 90/196 [00:32<00:38,  2.75it/s, loss=1.936, v_num=6666703]Epoch 1:  46%|████▋     | 91/196 [00:33<00:38,  2.75it/s, loss=1.936, v_num=6666703]Epoch 1:  46%|████▋     | 91/196 [00:33<00:38,  2.75it/s, loss=1.935, v_num=6666703]Epoch 1:  47%|████▋     | 92/196 [00:33<00:37,  2.75it/s, loss=1.935, v_num=6666703]Epoch 1:  47%|████▋     | 92/196 [00:33<00:37,  2.75it/s, loss=1.938, v_num=6666703]Epoch 1:  47%|████▋     | 93/196 [00:33<00:37,  2.75it/s, loss=1.938, v_num=6666703]Epoch 1:  47%|████▋     | 93/196 [00:33<00:37,  2.75it/s, loss=1.929, v_num=6666703]Epoch 1:  48%|████▊     | 94/196 [00:34<00:37,  2.75it/s, loss=1.929, v_num=6666703]Epoch 1:  48%|████▊     | 94/196 [00:34<00:37,  2.75it/s, loss=1.929, v_num=6666703]Epoch 1:  48%|████▊     | 95/196 [00:34<00:36,  2.75it/s, loss=1.929, v_num=6666703]Epoch 1:  48%|████▊     | 95/196 [00:34<00:36,  2.75it/s, loss=1.930, v_num=6666703]Epoch 1:  49%|████▉     | 96/196 [00:34<00:36,  2.75it/s, loss=1.930, v_num=6666703]Epoch 1:  49%|████▉     | 96/196 [00:34<00:36,  2.75it/s, loss=1.927, v_num=6666703]Epoch 1:  49%|████▉     | 97/196 [00:35<00:35,  2.75it/s, loss=1.927, v_num=6666703]Epoch 1:  49%|████▉     | 97/196 [00:35<00:35,  2.75it/s, loss=1.924, v_num=6666703]Epoch 1:  50%|█████     | 98/196 [00:35<00:35,  2.75it/s, loss=1.924, v_num=6666703]Epoch 1:  50%|█████     | 98/196 [00:35<00:35,  2.75it/s, loss=1.918, v_num=6666703]Epoch 1:  51%|█████     | 99/196 [00:35<00:35,  2.75it/s, loss=1.918, v_num=6666703]Epoch 1:  51%|█████     | 99/196 [00:35<00:35,  2.75it/s, loss=1.915, v_num=6666703]Epoch 1:  51%|█████     | 100/196 [00:36<00:34,  2.75it/s, loss=1.915, v_num=6666703]Epoch 1:  51%|█████     | 100/196 [00:36<00:34,  2.75it/s, loss=1.925, v_num=6666703]Epoch 1:  52%|█████▏    | 101/196 [00:36<00:34,  2.75it/s, loss=1.925, v_num=6666703]Epoch 1:  52%|█████▏    | 101/196 [00:36<00:34,  2.75it/s, loss=1.922, v_num=6666703]Epoch 1:  52%|█████▏    | 102/196 [00:37<00:34,  2.75it/s, loss=1.922, v_num=6666703]Epoch 1:  52%|█████▏    | 102/196 [00:37<00:34,  2.75it/s, loss=1.917, v_num=6666703]Epoch 1:  53%|█████▎    | 103/196 [00:37<00:33,  2.75it/s, loss=1.917, v_num=6666703]Epoch 1:  53%|█████▎    | 103/196 [00:37<00:33,  2.75it/s, loss=1.920, v_num=6666703]Epoch 1:  53%|█████▎    | 104/196 [00:37<00:33,  2.75it/s, loss=1.920, v_num=6666703]Epoch 1:  53%|█████▎    | 104/196 [00:37<00:33,  2.75it/s, loss=1.925, v_num=6666703]Epoch 1:  54%|█████▎    | 105/196 [00:38<00:33,  2.75it/s, loss=1.925, v_num=6666703]Epoch 1:  54%|█████▎    | 105/196 [00:38<00:33,  2.75it/s, loss=1.918, v_num=6666703]Epoch 1:  54%|█████▍    | 106/196 [00:38<00:32,  2.76it/s, loss=1.918, v_num=6666703]Epoch 1:  54%|█████▍    | 106/196 [00:38<00:32,  2.76it/s, loss=1.911, v_num=6666703]Epoch 1:  55%|█████▍    | 107/196 [00:38<00:32,  2.76it/s, loss=1.911, v_num=6666703]Epoch 1:  55%|█████▍    | 107/196 [00:38<00:32,  2.76it/s, loss=1.907, v_num=6666703]Epoch 1:  55%|█████▌    | 108/196 [00:39<00:31,  2.76it/s, loss=1.907, v_num=6666703]Epoch 1:  55%|█████▌    | 108/196 [00:39<00:31,  2.76it/s, loss=1.910, v_num=6666703]Epoch 1:  56%|█████▌    | 109/196 [00:39<00:31,  2.76it/s, loss=1.910, v_num=6666703]Epoch 1:  56%|█████▌    | 109/196 [00:39<00:31,  2.76it/s, loss=1.904, v_num=6666703]Epoch 1:  56%|█████▌    | 110/196 [00:39<00:31,  2.76it/s, loss=1.904, v_num=6666703]Epoch 1:  56%|█████▌    | 110/196 [00:39<00:31,  2.76it/s, loss=1.904, v_num=6666703]Epoch 1:  57%|█████▋    | 111/196 [00:40<00:30,  2.76it/s, loss=1.904, v_num=6666703]Epoch 1:  57%|█████▋    | 111/196 [00:40<00:30,  2.76it/s, loss=1.907, v_num=6666703]Epoch 1:  57%|█████▋    | 112/196 [00:40<00:30,  2.76it/s, loss=1.907, v_num=6666703]Epoch 1:  57%|█████▋    | 112/196 [00:40<00:30,  2.76it/s, loss=1.899, v_num=6666703]Epoch 1:  58%|█████▊    | 113/196 [00:40<00:30,  2.76it/s, loss=1.899, v_num=6666703]Epoch 1:  58%|█████▊    | 113/196 [00:40<00:30,  2.76it/s, loss=1.902, v_num=6666703]Epoch 1:  58%|█████▊    | 114/196 [00:41<00:29,  2.76it/s, loss=1.902, v_num=6666703]Epoch 1:  58%|█████▊    | 114/196 [00:41<00:29,  2.76it/s, loss=1.899, v_num=6666703]Epoch 1:  59%|█████▊    | 115/196 [00:41<00:29,  2.76it/s, loss=1.899, v_num=6666703]Epoch 1:  59%|█████▊    | 115/196 [00:41<00:29,  2.76it/s, loss=1.892, v_num=6666703]Epoch 1:  59%|█████▉    | 116/196 [00:42<00:28,  2.76it/s, loss=1.892, v_num=6666703]Epoch 1:  59%|█████▉    | 116/196 [00:42<00:28,  2.76it/s, loss=1.894, v_num=6666703]Epoch 1:  60%|█████▉    | 117/196 [00:42<00:28,  2.76it/s, loss=1.894, v_num=6666703]Epoch 1:  60%|█████▉    | 117/196 [00:42<00:28,  2.76it/s, loss=1.888, v_num=6666703]Epoch 1:  60%|██████    | 118/196 [00:42<00:28,  2.76it/s, loss=1.888, v_num=6666703]Epoch 1:  60%|██████    | 118/196 [00:42<00:28,  2.76it/s, loss=1.884, v_num=6666703]Epoch 1:  61%|██████    | 119/196 [00:43<00:27,  2.76it/s, loss=1.884, v_num=6666703]Epoch 1:  61%|██████    | 119/196 [00:43<00:27,  2.76it/s, loss=1.881, v_num=6666703]Epoch 1:  61%|██████    | 120/196 [00:43<00:27,  2.76it/s, loss=1.881, v_num=6666703]Epoch 1:  61%|██████    | 120/196 [00:43<00:27,  2.76it/s, loss=1.869, v_num=6666703]Epoch 1:  62%|██████▏   | 121/196 [00:43<00:27,  2.76it/s, loss=1.869, v_num=6666703]Epoch 1:  62%|██████▏   | 121/196 [00:43<00:27,  2.76it/s, loss=1.864, v_num=6666703]Epoch 1:  62%|██████▏   | 122/196 [00:44<00:26,  2.76it/s, loss=1.864, v_num=6666703]Epoch 1:  62%|██████▏   | 122/196 [00:44<00:26,  2.76it/s, loss=1.864, v_num=6666703]Epoch 1:  63%|██████▎   | 123/196 [00:44<00:26,  2.76it/s, loss=1.864, v_num=6666703]Epoch 1:  63%|██████▎   | 123/196 [00:44<00:26,  2.76it/s, loss=1.864, v_num=6666703]Epoch 1:  63%|██████▎   | 124/196 [00:44<00:26,  2.76it/s, loss=1.864, v_num=6666703]Epoch 1:  63%|██████▎   | 124/196 [00:44<00:26,  2.76it/s, loss=1.854, v_num=6666703]Epoch 1:  64%|██████▍   | 125/196 [00:45<00:25,  2.76it/s, loss=1.854, v_num=6666703]Epoch 1:  64%|██████▍   | 125/196 [00:45<00:25,  2.76it/s, loss=1.852, v_num=6666703]Epoch 1:  64%|██████▍   | 126/196 [00:45<00:25,  2.76it/s, loss=1.852, v_num=6666703]Epoch 1:  64%|██████▍   | 126/196 [00:45<00:25,  2.76it/s, loss=1.843, v_num=6666703]Epoch 1:  65%|██████▍   | 127/196 [00:45<00:24,  2.76it/s, loss=1.843, v_num=6666703]Epoch 1:  65%|██████▍   | 127/196 [00:45<00:24,  2.76it/s, loss=1.841, v_num=6666703]Epoch 1:  65%|██████▌   | 128/196 [00:46<00:24,  2.76it/s, loss=1.841, v_num=6666703]Epoch 1:  65%|██████▌   | 128/196 [00:46<00:24,  2.76it/s, loss=1.834, v_num=6666703]Epoch 1:  66%|██████▌   | 129/196 [00:46<00:24,  2.77it/s, loss=1.834, v_num=6666703]Epoch 1:  66%|██████▌   | 129/196 [00:46<00:24,  2.77it/s, loss=1.832, v_num=6666703]Epoch 1:  66%|██████▋   | 130/196 [00:46<00:23,  2.77it/s, loss=1.832, v_num=6666703]Epoch 1:  66%|██████▋   | 130/196 [00:46<00:23,  2.77it/s, loss=1.830, v_num=6666703]Epoch 1:  67%|██████▋   | 131/196 [00:47<00:23,  2.77it/s, loss=1.830, v_num=6666703]Epoch 1:  67%|██████▋   | 131/196 [00:47<00:23,  2.77it/s, loss=1.827, v_num=6666703]Epoch 1:  67%|██████▋   | 132/196 [00:47<00:23,  2.77it/s, loss=1.827, v_num=6666703]Epoch 1:  67%|██████▋   | 132/196 [00:47<00:23,  2.77it/s, loss=1.830, v_num=6666703]Epoch 1:  68%|██████▊   | 133/196 [00:48<00:22,  2.77it/s, loss=1.830, v_num=6666703]Epoch 1:  68%|██████▊   | 133/196 [00:48<00:22,  2.77it/s, loss=1.827, v_num=6666703]Epoch 1:  68%|██████▊   | 134/196 [00:48<00:22,  2.77it/s, loss=1.827, v_num=6666703]Epoch 1:  68%|██████▊   | 134/196 [00:48<00:22,  2.77it/s, loss=1.819, v_num=6666703]Epoch 1:  69%|██████▉   | 135/196 [00:48<00:22,  2.77it/s, loss=1.819, v_num=6666703]Epoch 1:  69%|██████▉   | 135/196 [00:48<00:22,  2.77it/s, loss=1.816, v_num=6666703]Epoch 1:  69%|██████▉   | 136/196 [00:49<00:21,  2.77it/s, loss=1.816, v_num=6666703]Epoch 1:  69%|██████▉   | 136/196 [00:49<00:21,  2.77it/s, loss=1.818, v_num=6666703]Epoch 1:  70%|██████▉   | 137/196 [00:49<00:21,  2.77it/s, loss=1.818, v_num=6666703]Epoch 1:  70%|██████▉   | 137/196 [00:49<00:21,  2.77it/s, loss=1.818, v_num=6666703]Epoch 1:  70%|███████   | 138/196 [00:49<00:20,  2.77it/s, loss=1.818, v_num=6666703]Epoch 1:  70%|███████   | 138/196 [00:49<00:20,  2.77it/s, loss=1.817, v_num=6666703]Epoch 1:  71%|███████   | 139/196 [00:50<00:20,  2.77it/s, loss=1.817, v_num=6666703]Epoch 1:  71%|███████   | 139/196 [00:50<00:20,  2.77it/s, loss=1.816, v_num=6666703]Epoch 1:  71%|███████▏  | 140/196 [00:50<00:20,  2.77it/s, loss=1.816, v_num=6666703]Epoch 1:  71%|███████▏  | 140/196 [00:50<00:20,  2.77it/s, loss=1.815, v_num=6666703]Epoch 1:  72%|███████▏  | 141/196 [00:50<00:19,  2.77it/s, loss=1.815, v_num=6666703]Epoch 1:  72%|███████▏  | 141/196 [00:50<00:19,  2.77it/s, loss=1.818, v_num=6666703]Epoch 1:  72%|███████▏  | 142/196 [00:51<00:19,  2.77it/s, loss=1.818, v_num=6666703]Epoch 1:  72%|███████▏  | 142/196 [00:51<00:19,  2.77it/s, loss=1.813, v_num=6666703]Epoch 1:  73%|███████▎  | 143/196 [00:51<00:19,  2.77it/s, loss=1.813, v_num=6666703]Epoch 1:  73%|███████▎  | 143/196 [00:51<00:19,  2.77it/s, loss=1.810, v_num=6666703]Epoch 1:  73%|███████▎  | 144/196 [00:51<00:18,  2.77it/s, loss=1.810, v_num=6666703]Epoch 1:  73%|███████▎  | 144/196 [00:51<00:18,  2.77it/s, loss=1.814, v_num=6666703]Epoch 1:  74%|███████▍  | 145/196 [00:52<00:18,  2.77it/s, loss=1.814, v_num=6666703]Epoch 1:  74%|███████▍  | 145/196 [00:52<00:18,  2.77it/s, loss=1.816, v_num=6666703]Epoch 1:  74%|███████▍  | 146/196 [00:52<00:18,  2.77it/s, loss=1.816, v_num=6666703]Epoch 1:  74%|███████▍  | 146/196 [00:52<00:18,  2.77it/s, loss=1.821, v_num=6666703]Epoch 1:  75%|███████▌  | 147/196 [00:52<00:17,  2.77it/s, loss=1.821, v_num=6666703]Epoch 1:  75%|███████▌  | 147/196 [00:52<00:17,  2.77it/s, loss=1.822, v_num=6666703]Epoch 1:  76%|███████▌  | 148/196 [00:53<00:17,  2.77it/s, loss=1.822, v_num=6666703]Epoch 1:  76%|███████▌  | 148/196 [00:53<00:17,  2.77it/s, loss=1.817, v_num=6666703]Epoch 1:  76%|███████▌  | 149/196 [00:53<00:16,  2.77it/s, loss=1.817, v_num=6666703]Epoch 1:  76%|███████▌  | 149/196 [00:53<00:16,  2.77it/s, loss=1.814, v_num=6666703]Epoch 1:  77%|███████▋  | 150/196 [00:54<00:16,  2.77it/s, loss=1.814, v_num=6666703]Epoch 1:  77%|███████▋  | 150/196 [00:54<00:16,  2.77it/s, loss=1.808, v_num=6666703]Epoch 1:  77%|███████▋  | 151/196 [00:54<00:16,  2.77it/s, loss=1.808, v_num=6666703]Epoch 1:  77%|███████▋  | 151/196 [00:54<00:16,  2.77it/s, loss=1.802, v_num=6666703]Epoch 1:  78%|███████▊  | 152/196 [00:54<00:15,  2.78it/s, loss=1.802, v_num=6666703]Epoch 1:  78%|███████▊  | 152/196 [00:54<00:15,  2.78it/s, loss=1.790, v_num=6666703]Epoch 1:  78%|███████▊  | 153/196 [00:55<00:15,  2.78it/s, loss=1.790, v_num=6666703]Epoch 1:  78%|███████▊  | 153/196 [00:55<00:15,  2.78it/s, loss=1.788, v_num=6666703]Epoch 1:  79%|███████▊  | 154/196 [00:55<00:15,  2.78it/s, loss=1.788, v_num=6666703]Epoch 1:  79%|███████▊  | 154/196 [00:55<00:15,  2.78it/s, loss=1.789, v_num=6666703]Epoch 1:  79%|███████▉  | 155/196 [00:55<00:14,  2.78it/s, loss=1.789, v_num=6666703]Epoch 1:  79%|███████▉  | 155/196 [00:55<00:14,  2.78it/s, loss=1.785, v_num=6666703]Epoch 1:  80%|███████▉  | 156/196 [00:56<00:14,  2.78it/s, loss=1.785, v_num=6666703]Epoch 1:  80%|███████▉  | 156/196 [00:56<00:14,  2.78it/s, loss=1.776, v_num=6666703]Epoch 1:  80%|████████  | 157/196 [00:56<00:14,  2.78it/s, loss=1.776, v_num=6666703]Epoch 1:  80%|████████  | 157/196 [00:56<00:14,  2.78it/s, loss=1.775, v_num=6666703]Epoch 1:  81%|████████  | 158/196 [00:56<00:13,  2.78it/s, loss=1.775, v_num=6666703]Epoch 1:  81%|████████  | 158/196 [00:56<00:13,  2.78it/s, loss=1.769, v_num=6666703]Epoch 1:  81%|████████  | 159/196 [00:57<00:13,  2.78it/s, loss=1.769, v_num=6666703]Epoch 1:  81%|████████  | 159/196 [00:57<00:13,  2.78it/s, loss=1.769, v_num=6666703]Epoch 1:  82%|████████▏ | 160/196 [00:57<00:12,  2.78it/s, loss=1.769, v_num=6666703]Epoch 1:  82%|████████▏ | 160/196 [00:57<00:12,  2.78it/s, loss=1.765, v_num=6666703]Epoch 1:  82%|████████▏ | 161/196 [00:57<00:12,  2.78it/s, loss=1.765, v_num=6666703]Epoch 1:  82%|████████▏ | 161/196 [00:57<00:12,  2.78it/s, loss=1.756, v_num=6666703]Epoch 1:  83%|████████▎ | 162/196 [00:58<00:12,  2.78it/s, loss=1.756, v_num=6666703]Epoch 1:  83%|████████▎ | 162/196 [00:58<00:12,  2.78it/s, loss=1.756, v_num=6666703]Epoch 1:  83%|████████▎ | 163/196 [00:58<00:11,  2.78it/s, loss=1.756, v_num=6666703]Epoch 1:  83%|████████▎ | 163/196 [00:58<00:11,  2.78it/s, loss=1.750, v_num=6666703]Epoch 1:  84%|████████▎ | 164/196 [00:59<00:11,  2.78it/s, loss=1.750, v_num=6666703]Epoch 1:  84%|████████▎ | 164/196 [00:59<00:11,  2.78it/s, loss=1.744, v_num=6666703]Epoch 1:  84%|████████▍ | 165/196 [00:59<00:11,  2.78it/s, loss=1.744, v_num=6666703]Epoch 1:  84%|████████▍ | 165/196 [00:59<00:11,  2.78it/s, loss=1.739, v_num=6666703]Epoch 1:  85%|████████▍ | 166/196 [00:59<00:10,  2.78it/s, loss=1.739, v_num=6666703]Epoch 1:  85%|████████▍ | 166/196 [00:59<00:10,  2.78it/s, loss=1.736, v_num=6666703]Epoch 1:  85%|████████▌ | 167/196 [01:00<00:10,  2.78it/s, loss=1.736, v_num=6666703]Epoch 1:  85%|████████▌ | 167/196 [01:00<00:10,  2.78it/s, loss=1.729, v_num=6666703]Epoch 1:  86%|████████▌ | 168/196 [01:00<00:10,  2.78it/s, loss=1.729, v_num=6666703]Epoch 1:  86%|████████▌ | 168/196 [01:00<00:10,  2.78it/s, loss=1.733, v_num=6666703]Epoch 1:  86%|████████▌ | 169/196 [01:00<00:09,  2.78it/s, loss=1.733, v_num=6666703]Epoch 1:  86%|████████▌ | 169/196 [01:00<00:09,  2.78it/s, loss=1.733, v_num=6666703]Epoch 1:  87%|████████▋ | 170/196 [01:01<00:09,  2.78it/s, loss=1.733, v_num=6666703]Epoch 1:  87%|████████▋ | 170/196 [01:01<00:09,  2.78it/s, loss=1.731, v_num=6666703]Epoch 1:  87%|████████▋ | 171/196 [01:01<00:08,  2.78it/s, loss=1.731, v_num=6666703]Epoch 1:  87%|████████▋ | 171/196 [01:01<00:08,  2.78it/s, loss=1.727, v_num=6666703]Epoch 1:  88%|████████▊ | 172/196 [01:01<00:08,  2.78it/s, loss=1.727, v_num=6666703]Epoch 1:  88%|████████▊ | 172/196 [01:01<00:08,  2.78it/s, loss=1.732, v_num=6666703]Epoch 1:  88%|████████▊ | 173/196 [01:02<00:08,  2.78it/s, loss=1.732, v_num=6666703]Epoch 1:  88%|████████▊ | 173/196 [01:02<00:08,  2.78it/s, loss=1.729, v_num=6666703]Epoch 1:  89%|████████▉ | 174/196 [01:02<00:07,  2.78it/s, loss=1.729, v_num=6666703]Epoch 1:  89%|████████▉ | 174/196 [01:02<00:07,  2.78it/s, loss=1.727, v_num=6666703]Epoch 1:  89%|████████▉ | 175/196 [01:02<00:07,  2.78it/s, loss=1.727, v_num=6666703]Epoch 1:  89%|████████▉ | 175/196 [01:02<00:07,  2.78it/s, loss=1.729, v_num=6666703]Epoch 1:  90%|████████▉ | 176/196 [01:03<00:07,  2.78it/s, loss=1.729, v_num=6666703]Epoch 1:  90%|████████▉ | 176/196 [01:03<00:07,  2.78it/s, loss=1.731, v_num=6666703]
Validating: 0it [00:00, ?it/s][AWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).

Validating:   5%|▌         | 1/20 [00:00<00:18,  1.03it/s][AEpoch 1:  90%|█████████ | 177/196 [01:04<00:06,  2.75it/s, loss=1.731, v_num=6666703]
Validating:  10%|█         | 2/20 [00:01<00:08,  2.12it/s][AEpoch 1:  91%|█████████ | 178/196 [01:04<00:06,  2.76it/s, loss=1.731, v_num=6666703]
Validating:  15%|█▌        | 3/20 [00:01<00:05,  3.10it/s][AEpoch 1:  91%|█████████▏| 179/196 [01:04<00:06,  2.77it/s, loss=1.731, v_num=6666703]
Validating:  20%|██        | 4/20 [00:01<00:03,  4.10it/s][AEpoch 1:  92%|█████████▏| 180/196 [01:04<00:05,  2.78it/s, loss=1.731, v_num=6666703]
Validating:  25%|██▌       | 5/20 [00:01<00:03,  4.91it/s][AEpoch 1:  92%|█████████▏| 181/196 [01:04<00:05,  2.79it/s, loss=1.731, v_num=6666703]
Validating:  30%|███       | 6/20 [00:01<00:02,  5.67it/s][AEpoch 1:  93%|█████████▎| 182/196 [01:04<00:04,  2.80it/s, loss=1.731, v_num=6666703]
Validating:  35%|███▌      | 7/20 [00:01<00:02,  6.14it/s][AEpoch 1:  93%|█████████▎| 183/196 [01:05<00:04,  2.81it/s, loss=1.731, v_num=6666703]
Validating:  40%|████      | 8/20 [00:01<00:01,  6.48it/s][AEpoch 1:  94%|█████████▍| 184/196 [01:05<00:04,  2.82it/s, loss=1.731, v_num=6666703]
Validating:  45%|████▌     | 9/20 [00:02<00:01,  6.92it/s][AEpoch 1:  94%|█████████▍| 185/196 [01:05<00:03,  2.83it/s, loss=1.731, v_num=6666703]
Validating:  50%|█████     | 10/20 [00:02<00:01,  7.06it/s][AEpoch 1:  95%|█████████▍| 186/196 [01:05<00:03,  2.84it/s, loss=1.731, v_num=6666703]
Validating:  55%|█████▌    | 11/20 [00:02<00:01,  7.36it/s][AEpoch 1:  95%|█████████▌| 187/196 [01:05<00:03,  2.85it/s, loss=1.731, v_num=6666703]
Validating:  60%|██████    | 12/20 [00:02<00:01,  7.59it/s][AEpoch 1:  96%|█████████▌| 188/196 [01:05<00:02,  2.86it/s, loss=1.731, v_num=6666703]
Validating:  65%|██████▌   | 13/20 [00:02<00:00,  7.75it/s][AEpoch 1:  96%|█████████▋| 189/196 [01:05<00:02,  2.87it/s, loss=1.731, v_num=6666703]
Validating:  70%|███████   | 14/20 [00:02<00:00,  7.87it/s][AEpoch 1:  97%|█████████▋| 190/196 [01:05<00:02,  2.88it/s, loss=1.731, v_num=6666703]
Validating:  75%|███████▌  | 15/20 [00:02<00:00,  7.95it/s][AEpoch 1:  97%|█████████▋| 191/196 [01:06<00:01,  2.89it/s, loss=1.731, v_num=6666703]
Validating:  80%|████████  | 16/20 [00:02<00:00,  8.01it/s][AEpoch 1:  98%|█████████▊| 192/196 [01:06<00:01,  2.90it/s, loss=1.731, v_num=6666703]
Validating:  85%|████████▌ | 17/20 [00:03<00:00,  8.05it/s][AEpoch 1:  98%|█████████▊| 193/196 [01:06<00:01,  2.91it/s, loss=1.731, v_num=6666703]
Validating:  90%|█████████ | 18/20 [00:03<00:00,  8.08it/s][AEpoch 1:  99%|█████████▉| 194/196 [01:06<00:00,  2.92it/s, loss=1.731, v_num=6666703]
Validating:  95%|█████████▌| 19/20 [00:03<00:00,  8.10it/s][AEpoch 1:  99%|█████████▉| 195/196 [01:06<00:00,  2.93it/s, loss=1.731, v_num=6666703]Epoch 1: 100%|██████████| 196/196 [01:06<00:00,  2.93it/s, loss=1.731, v_num=6666703]
                                                           [AEpoch 1:   0%|          | 0/196 [00:00<?, ?it/s, loss=1.731, v_num=6666703]          Epoch 2:   0%|          | 0/196 [00:00<?, ?it/s, loss=1.731, v_num=6666703]/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Epoch 2:   1%|          | 1/196 [00:01<04:26,  1.37s/it, loss=1.731, v_num=6666703]Epoch 2:   1%|          | 1/196 [00:01<04:26,  1.37s/it, loss=1.726, v_num=6666703]Epoch 2:   1%|          | 2/196 [00:01<02:46,  1.16it/s, loss=1.726, v_num=6666703]Epoch 2:   1%|          | 2/196 [00:01<02:46,  1.16it/s, loss=1.729, v_num=6666703]Epoch 2:   2%|▏         | 3/196 [00:02<02:12,  1.45it/s, loss=1.729, v_num=6666703]Epoch 2:   2%|▏         | 3/196 [00:02<02:12,  1.45it/s, loss=1.729, v_num=6666703]Epoch 2:   2%|▏         | 4/196 [00:02<01:55,  1.66it/s, loss=1.729, v_num=6666703]Epoch 2:   2%|▏         | 4/196 [00:02<01:55,  1.66it/s, loss=1.727, v_num=6666703]Epoch 2:   3%|▎         | 5/196 [00:02<01:45,  1.81it/s, loss=1.727, v_num=6666703]Epoch 2:   3%|▎         | 5/196 [00:02<01:45,  1.81it/s, loss=1.730, v_num=6666703]Epoch 2:   3%|▎         | 6/196 [00:03<01:39,  1.92it/s, loss=1.730, v_num=6666703]Epoch 2:   3%|▎         | 6/196 [00:03<01:39,  1.92it/s, loss=1.731, v_num=6666703]Epoch 2:   4%|▎         | 7/196 [00:03<01:34,  2.00it/s, loss=1.731, v_num=6666703]Epoch 2:   4%|▎         | 7/196 [00:03<01:34,  2.00it/s, loss=1.736, v_num=6666703]Epoch 2:   4%|▍         | 8/196 [00:03<01:30,  2.08it/s, loss=1.736, v_num=6666703]Epoch 2:   4%|▍         | 8/196 [00:03<01:30,  2.08it/s, loss=1.732, v_num=6666703]Epoch 2:   5%|▍         | 9/196 [00:04<01:27,  2.15it/s, loss=1.732, v_num=6666703]Epoch 2:   5%|▍         | 9/196 [00:04<01:27,  2.15it/s, loss=1.730, v_num=6666703]Epoch 2:   5%|▌         | 10/196 [00:04<01:24,  2.20it/s, loss=1.730, v_num=6666703]Epoch 2:   5%|▌         | 10/196 [00:04<01:24,  2.20it/s, loss=1.727, v_num=6666703]Epoch 2:   6%|▌         | 11/196 [00:04<01:22,  2.25it/s, loss=1.727, v_num=6666703]Epoch 2:   6%|▌         | 11/196 [00:04<01:22,  2.25it/s, loss=1.727, v_num=6666703]Epoch 2:   6%|▌         | 12/196 [00:05<01:20,  2.29it/s, loss=1.727, v_num=6666703]Epoch 2:   6%|▌         | 12/196 [00:05<01:20,  2.29it/s, loss=1.718, v_num=6666703]Epoch 2:   7%|▋         | 13/196 [00:05<01:18,  2.33it/s, loss=1.718, v_num=6666703]Epoch 2:   7%|▋         | 13/196 [00:05<01:18,  2.33it/s, loss=1.715, v_num=6666703]Epoch 2:   7%|▋         | 14/196 [00:05<01:17,  2.36it/s, loss=1.715, v_num=6666703]Epoch 2:   7%|▋         | 14/196 [00:05<01:17,  2.36it/s, loss=1.714, v_num=6666703]Epoch 2:   8%|▊         | 15/196 [00:06<01:15,  2.39it/s, loss=1.714, v_num=6666703]Epoch 2:   8%|▊         | 15/196 [00:06<01:15,  2.39it/s, loss=1.711, v_num=6666703]Epoch 2:   8%|▊         | 16/196 [00:06<01:14,  2.41it/s, loss=1.711, v_num=6666703]Epoch 2:   8%|▊         | 16/196 [00:06<01:14,  2.41it/s, loss=1.705, v_num=6666703]Epoch 2:   9%|▊         | 17/196 [00:07<01:13,  2.43it/s, loss=1.705, v_num=6666703]Epoch 2:   9%|▊         | 17/196 [00:07<01:13,  2.43it/s, loss=1.705, v_num=6666703]Epoch 2:   9%|▉         | 18/196 [00:07<01:12,  2.45it/s, loss=1.705, v_num=6666703]Epoch 2:   9%|▉         | 18/196 [00:07<01:12,  2.45it/s, loss=1.704, v_num=6666703]Epoch 2:  10%|▉         | 19/196 [00:07<01:11,  2.47it/s, loss=1.704, v_num=6666703]Epoch 2:  10%|▉         | 19/196 [00:07<01:11,  2.47it/s, loss=1.703, v_num=6666703]Epoch 2:  10%|█         | 20/196 [00:08<01:10,  2.48it/s, loss=1.703, v_num=6666703]Epoch 2:  10%|█         | 20/196 [00:08<01:10,  2.48it/s, loss=1.698, v_num=6666703]Epoch 2:  11%|█         | 21/196 [00:08<01:10,  2.49it/s, loss=1.698, v_num=6666703]Epoch 2:  11%|█         | 21/196 [00:08<01:10,  2.49it/s, loss=1.694, v_num=6666703]Epoch 2:  11%|█         | 22/196 [00:08<01:09,  2.51it/s, loss=1.694, v_num=6666703]Epoch 2:  11%|█         | 22/196 [00:08<01:09,  2.51it/s, loss=1.696, v_num=6666703]Epoch 2:  12%|█▏        | 23/196 [00:09<01:08,  2.52it/s, loss=1.696, v_num=6666703]Epoch 2:  12%|█▏        | 23/196 [00:09<01:08,  2.52it/s, loss=1.692, v_num=6666703]Epoch 2:  12%|█▏        | 24/196 [00:09<01:08,  2.53it/s, loss=1.692, v_num=6666703]Epoch 2:  12%|█▏        | 24/196 [00:09<01:08,  2.53it/s, loss=1.689, v_num=6666703]Epoch 2:  13%|█▎        | 25/196 [00:09<01:07,  2.54it/s, loss=1.689, v_num=6666703]Epoch 2:  13%|█▎        | 25/196 [00:09<01:07,  2.54it/s, loss=1.681, v_num=6666703]Epoch 2:  13%|█▎        | 26/196 [00:10<01:06,  2.55it/s, loss=1.681, v_num=6666703]Epoch 2:  13%|█▎        | 26/196 [00:10<01:06,  2.55it/s, loss=1.674, v_num=6666703]Epoch 2:  14%|█▍        | 27/196 [00:10<01:06,  2.56it/s, loss=1.674, v_num=6666703]Epoch 2:  14%|█▍        | 27/196 [00:10<01:06,  2.56it/s, loss=1.662, v_num=6666703]Epoch 2:  14%|█▍        | 28/196 [00:10<01:05,  2.57it/s, loss=1.662, v_num=6666703]Epoch 2:  14%|█▍        | 28/196 [00:10<01:05,  2.57it/s, loss=1.665, v_num=6666703]Epoch 2:  15%|█▍        | 29/196 [00:11<01:04,  2.58it/s, loss=1.665, v_num=6666703]Epoch 2:  15%|█▍        | 29/196 [00:11<01:04,  2.58it/s, loss=1.665, v_num=6666703]Epoch 2:  15%|█▌        | 30/196 [00:11<01:04,  2.58it/s, loss=1.665, v_num=6666703]Epoch 2:  15%|█▌        | 30/196 [00:11<01:04,  2.58it/s, loss=1.663, v_num=6666703]Epoch 2:  16%|█▌        | 31/196 [00:11<01:03,  2.59it/s, loss=1.663, v_num=6666703]Epoch 2:  16%|█▌        | 31/196 [00:11<01:03,  2.59it/s, loss=1.667, v_num=6666703]Exception in thread Thread-1:
Traceback (most recent call last):
  File "/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/tensorboard/summary/writer/event_file_writer.py", line 238, in run
    self._record_writer.write(data)
  File "/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/tensorboard/summary/writer/record_writer.py", line 40, in write
    self._writer.write(header + header_crc + data + footer_crc)
  File "/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 535, in write
    self.fs.append(self.filename, file_content, self.binary_mode)
  File "/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 158, in append
    self._write(filename, file_content, "ab" if binary_mode else "a")
  File "/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 162, in _write
    with io.open(filename, mode, encoding=encoding) as f:
FileNotFoundError: [Errno 2] No such file or directory: b'/scratch/nsk367/SP21/vit-pytorch/vit_pytorch/lightning_logs/version_6666703/events.out.tfevents.1620673313.gr015.nyu.cluster.1578386.0'
slurmstepd: error: *** JOB 6666703 ON gr015-ib0 CANCELLED AT 2021-05-10T15:04:57 ***
