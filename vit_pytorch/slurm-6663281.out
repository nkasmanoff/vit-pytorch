/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO:lightning:GPU available: True, used: True
INFO:lightning:CUDA_VISIBLE_DEVICES: [0]
INFO:lightning:Set SLURM handle signals.
INFO:lightning:
    | Name                                                    | Type        | Params
------------------------------------------------------------------------------------
0   | _ViT_Trainer__model                                     | ViT         | 25 M  
1   | _ViT_Trainer__model.to_patch_embedding                  | Sequential  | 25 K  
2   | _ViT_Trainer__model.to_patch_embedding.0                | Rearrange   | 0     
3   | _ViT_Trainer__model.to_patch_embedding.1                | Linear      | 25 K  
4   | _ViT_Trainer__model.dropout                             | Dropout     | 0     
5   | _ViT_Trainer__model.transformer                         | Transformer | 25 M  
6   | _ViT_Trainer__model.transformer.layers                  | ModuleList  | 25 M  
7   | _ViT_Trainer__model.transformer.layers.0                | ModuleList  | 2 M   
8   | _ViT_Trainer__model.transformer.layers.0.0              | PreNorm     | 1 M   
9   | _ViT_Trainer__model.transformer.layers.0.0.norm         | LayerNorm   | 1 K   
10  | _ViT_Trainer__model.transformer.layers.0.0.fn           | Attention   | 1 M   
11  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_qkv    | Linear      | 1 M   
12  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_out    | Sequential  | 393 K 
13  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_out.0  | Linear      | 393 K 
14  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_out.1  | Dropout     | 0     
15  | _ViT_Trainer__model.transformer.layers.0.1              | PreNorm     | 526 K 
16  | _ViT_Trainer__model.transformer.layers.0.1.norm         | LayerNorm   | 1 K   
17  | _ViT_Trainer__model.transformer.layers.0.1.fn           | FeedForward | 525 K 
18  | _ViT_Trainer__model.transformer.layers.0.1.fn.net       | Sequential  | 525 K 
19  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.0     | Linear      | 262 K 
20  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.1     | GELU        | 0     
21  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.2     | Dropout     | 0     
22  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.3     | Linear      | 262 K 
23  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.4     | Dropout     | 0     
24  | _ViT_Trainer__model.transformer.layers.1                | ModuleList  | 2 M   
25  | _ViT_Trainer__model.transformer.layers.1.0              | PreNorm     | 1 M   
26  | _ViT_Trainer__model.transformer.layers.1.0.norm         | LayerNorm   | 1 K   
27  | _ViT_Trainer__model.transformer.layers.1.0.fn           | Attention   | 1 M   
28  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_qkv    | Linear      | 1 M   
29  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_out    | Sequential  | 393 K 
30  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_out.0  | Linear      | 393 K 
31  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_out.1  | Dropout     | 0     
32  | _ViT_Trainer__model.transformer.layers.1.1              | PreNorm     | 526 K 
33  | _ViT_Trainer__model.transformer.layers.1.1.norm         | LayerNorm   | 1 K   
34  | _ViT_Trainer__model.transformer.layers.1.1.fn           | FeedForward | 525 K 
35  | _ViT_Trainer__model.transformer.layers.1.1.fn.net       | Sequential  | 525 K 
36  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.0     | Linear      | 262 K 
37  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.1     | GELU        | 0     
38  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.2     | Dropout     | 0     
39  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.3     | Linear      | 262 K 
40  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.4     | Dropout     | 0     
41  | _ViT_Trainer__model.transformer.layers.2                | ModuleList  | 2 M   
42  | _ViT_Trainer__model.transformer.layers.2.0              | PreNorm     | 1 M   
43  | _ViT_Trainer__model.transformer.layers.2.0.norm         | LayerNorm   | 1 K   
44  | _ViT_Trainer__model.transformer.layers.2.0.fn           | Attention   | 1 M   
45  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_qkv    | Linear      | 1 M   
46  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_out    | Sequential  | 393 K 
47  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_out.0  | Linear      | 393 K 
48  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_out.1  | Dropout     | 0     
49  | _ViT_Trainer__model.transformer.layers.2.1              | PreNorm     | 526 K 
50  | _ViT_Trainer__model.transformer.layers.2.1.norm         | LayerNorm   | 1 K   
51  | _ViT_Trainer__model.transformer.layers.2.1.fn           | FeedForward | 525 K 
52  | _ViT_Trainer__model.transformer.layers.2.1.fn.net       | Sequential  | 525 K 
53  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.0     | Linear      | 262 K 
54  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.1     | GELU        | 0     
55  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.2     | Dropout     | 0     
56  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.3     | Linear      | 262 K 
57  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.4     | Dropout     | 0     
58  | _ViT_Trainer__model.transformer.layers.3                | ModuleList  | 2 M   
59  | _ViT_Trainer__model.transformer.layers.3.0              | PreNorm     | 1 M   
60  | _ViT_Trainer__model.transformer.layers.3.0.norm         | LayerNorm   | 1 K   
61  | _ViT_Trainer__model.transformer.layers.3.0.fn           | Attention   | 1 M   
62  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_qkv    | Linear      | 1 M   
63  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_out    | Sequential  | 393 K 
64  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_out.0  | Linear      | 393 K 
65  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_out.1  | Dropout     | 0     
66  | _ViT_Trainer__model.transformer.layers.3.1              | PreNorm     | 526 K 
67  | _ViT_Trainer__model.transformer.layers.3.1.norm         | LayerNorm   | 1 K   
68  | _ViT_Trainer__model.transformer.layers.3.1.fn           | FeedForward | 525 K 
69  | _ViT_Trainer__model.transformer.layers.3.1.fn.net       | Sequential  | 525 K 
70  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.0     | Linear      | 262 K 
71  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.1     | GELU        | 0     
72  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.2     | Dropout     | 0     
73  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.3     | Linear      | 262 K 
74  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.4     | Dropout     | 0     
75  | _ViT_Trainer__model.transformer.layers.4                | ModuleList  | 2 M   
76  | _ViT_Trainer__model.transformer.layers.4.0              | PreNorm     | 1 M   
77  | _ViT_Trainer__model.transformer.layers.4.0.norm         | LayerNorm   | 1 K   
78  | _ViT_Trainer__model.transformer.layers.4.0.fn           | Attention   | 1 M   
79  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_qkv    | Linear      | 1 M   
80  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_out    | Sequential  | 393 K 
81  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_out.0  | Linear      | 393 K 
82  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_out.1  | Dropout     | 0     
83  | _ViT_Trainer__model.transformer.layers.4.1              | PreNorm     | 526 K 
84  | _ViT_Trainer__model.transformer.layers.4.1.norm         | LayerNorm   | 1 K   
85  | _ViT_Trainer__model.transformer.layers.4.1.fn           | FeedForward | 525 K 
86  | _ViT_Trainer__model.transformer.layers.4.1.fn.net       | Sequential  | 525 K 
87  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.0     | Linear      | 262 K 
88  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.1     | GELU        | 0     
89  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.2     | Dropout     | 0     
90  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.3     | Linear      | 262 K 
91  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.4     | Dropout     | 0     
92  | _ViT_Trainer__model.transformer.layers.5                | ModuleList  | 2 M   
93  | _ViT_Trainer__model.transformer.layers.5.0              | PreNorm     | 1 M   
94  | _ViT_Trainer__model.transformer.layers.5.0.norm         | LayerNorm   | 1 K   
95  | _ViT_Trainer__model.transformer.layers.5.0.fn           | Attention   | 1 M   
96  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_qkv    | Linear      | 1 M   
97  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_out    | Sequential  | 393 K 
98  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_out.0  | Linear      | 393 K 
99  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_out.1  | Dropout     | 0     
100 | _ViT_Trainer__model.transformer.layers.5.1              | PreNorm     | 526 K 
101 | _ViT_Trainer__model.transformer.layers.5.1.norm         | LayerNorm   | 1 K   
102 | _ViT_Trainer__model.transformer.layers.5.1.fn           | FeedForward | 525 K 
103 | _ViT_Trainer__model.transformer.layers.5.1.fn.net       | Sequential  | 525 K 
104 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.0     | Linear      | 262 K 
105 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.1     | GELU        | 0     
106 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.2     | Dropout     | 0     
107 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.3     | Linear      | 262 K 
108 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.4     | Dropout     | 0     
109 | _ViT_Trainer__model.transformer.layers.6                | ModuleList  | 2 M   
110 | _ViT_Trainer__model.transformer.layers.6.0              | PreNorm     | 1 M   
111 | _ViT_Trainer__model.transformer.layers.6.0.norm         | LayerNorm   | 1 K   
112 | _ViT_Trainer__model.transformer.layers.6.0.fn           | Attention   | 1 M   
113 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_qkv    | Linear      | 1 M   
114 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_out    | Sequential  | 393 K 
115 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_out.0  | Linear      | 393 K 
116 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_out.1  | Dropout     | 0     
117 | _ViT_Trainer__model.transformer.layers.6.1              | PreNorm     | 526 K 
118 | _ViT_Trainer__model.transformer.layers.6.1.norm         | LayerNorm   | 1 K   
119 | _ViT_Trainer__model.transformer.layers.6.1.fn           | FeedForward | 525 K 
120 | _ViT_Trainer__model.transformer.layers.6.1.fn.net       | Sequential  | 525 K 
121 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.0     | Linear      | 262 K 
122 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.1     | GELU        | 0     
123 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.2     | Dropout     | 0     
124 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.3     | Linear      | 262 K 
125 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.4     | Dropout     | 0     
126 | _ViT_Trainer__model.transformer.layers.7                | ModuleList  | 2 M   
127 | _ViT_Trainer__model.transformer.layers.7.0              | PreNorm     | 1 M   
128 | _ViT_Trainer__model.transformer.layers.7.0.norm         | LayerNorm   | 1 K   
129 | _ViT_Trainer__model.transformer.layers.7.0.fn           | Attention   | 1 M   
130 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_qkv    | Linear      | 1 M   
131 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_out    | Sequential  | 393 K 
132 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_out.0  | Linear      | 393 K 
133 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_out.1  | Dropout     | 0     
134 | _ViT_Trainer__model.transformer.layers.7.1              | PreNorm     | 526 K 
135 | _ViT_Trainer__model.transformer.layers.7.1.norm         | LayerNorm   | 1 K   
136 | _ViT_Trainer__model.transformer.layers.7.1.fn           | FeedForward | 525 K 
137 | _ViT_Trainer__model.transformer.layers.7.1.fn.net       | Sequential  | 525 K 
138 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.0     | Linear      | 262 K 
139 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.1     | GELU        | 0     
140 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.2     | Dropout     | 0     
141 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.3     | Linear      | 262 K 
142 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.4     | Dropout     | 0     
143 | _ViT_Trainer__model.transformer.layers.8                | ModuleList  | 2 M   
144 | _ViT_Trainer__model.transformer.layers.8.0              | PreNorm     | 1 M   
145 | _ViT_Trainer__model.transformer.layers.8.0.norm         | LayerNorm   | 1 K   
146 | _ViT_Trainer__model.transformer.layers.8.0.fn           | Attention   | 1 M   
147 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_qkv    | Linear      | 1 M   
148 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_out    | Sequential  | 393 K 
149 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_out.0  | Linear      | 393 K 
150 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_out.1  | Dropout     | 0     
151 | _ViT_Trainer__model.transformer.layers.8.1              | PreNorm     | 526 K 
152 | _ViT_Trainer__model.transformer.layers.8.1.norm         | LayerNorm   | 1 K   
153 | _ViT_Trainer__model.transformer.layers.8.1.fn           | FeedForward | 525 K 
154 | _ViT_Trainer__model.transformer.layers.8.1.fn.net       | Sequential  | 525 K 
155 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.0     | Linear      | 262 K 
156 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.1     | GELU        | 0     
157 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.2     | Dropout     | 0     
158 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.3     | Linear      | 262 K 
159 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.4     | Dropout     | 0     
160 | _ViT_Trainer__model.transformer.layers.9                | ModuleList  | 2 M   
161 | _ViT_Trainer__model.transformer.layers.9.0              | PreNorm     | 1 M   
162 | _ViT_Trainer__model.transformer.layers.9.0.norm         | LayerNorm   | 1 K   
163 | _ViT_Trainer__model.transformer.layers.9.0.fn           | Attention   | 1 M   
164 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_qkv    | Linear      | 1 M   
165 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_out    | Sequential  | 393 K 
166 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_out.0  | Linear      | 393 K 
167 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_out.1  | Dropout     | 0     
168 | _ViT_Trainer__model.transformer.layers.9.1              | PreNorm     | 526 K 
169 | _ViT_Trainer__model.transformer.layers.9.1.norm         | LayerNorm   | 1 K   
170 | _ViT_Trainer__model.transformer.layers.9.1.fn           | FeedForward | 525 K 
171 | _ViT_Trainer__model.transformer.layers.9.1.fn.net       | Sequential  | 525 K 
172 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.0     | Linear      | 262 K 
173 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.1     | GELU        | 0     
174 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.2     | Dropout     | 0     
175 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.3     | Linear      | 262 K 
176 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.4     | Dropout     | 0     
177 | _ViT_Trainer__model.transformer.layers.10               | ModuleList  | 2 M   
178 | _ViT_Trainer__model.transformer.layers.10.0             | PreNorm     | 1 M   
179 | _ViT_Trainer__model.transformer.layers.10.0.norm        | LayerNorm   | 1 K   
180 | _ViT_Trainer__model.transformer.layers.10.0.fn          | Attention   | 1 M   
181 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_qkv   | Linear      | 1 M   
182 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_out   | Sequential  | 393 K 
183 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_out.0 | Linear      | 393 K 
184 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_out.1 | Dropout     | 0     
185 | _ViT_Trainer__model.transformer.layers.10.1             | PreNorm     | 526 K 
186 | _ViT_Trainer__model.transformer.layers.10.1.norm        | LayerNorm   | 1 K   
187 | _ViT_Trainer__model.transformer.layers.10.1.fn          | FeedForward | 525 K 
188 | _ViT_Trainer__model.transformer.layers.10.1.fn.net      | Sequential  | 525 K 
189 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.0    | Linear      | 262 K 
190 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.1    | GELU        | 0     
191 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.2    | Dropout     | 0     
192 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.3    | Linear      | 262 K 
193 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.4    | Dropout     | 0     
194 | _ViT_Trainer__model.transformer.layers.11               | ModuleList  | 2 M   
195 | _ViT_Trainer__model.transformer.layers.11.0             | PreNorm     | 1 M   
196 | _ViT_Trainer__model.transformer.layers.11.0.norm        | LayerNorm   | 1 K   
197 | _ViT_Trainer__model.transformer.layers.11.0.fn          | Attention   | 1 M   
198 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_qkv   | Linear      | 1 M   
199 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_out   | Sequential  | 393 K 
200 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_out.0 | Linear      | 393 K 
201 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_out.1 | Dropout     | 0     
202 | _ViT_Trainer__model.transformer.layers.11.1             | PreNorm     | 526 K 
203 | _ViT_Trainer__model.transformer.layers.11.1.norm        | LayerNorm   | 1 K   
204 | _ViT_Trainer__model.transformer.layers.11.1.fn          | FeedForward | 525 K 
205 | _ViT_Trainer__model.transformer.layers.11.1.fn.net      | Sequential  | 525 K 
206 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.0    | Linear      | 262 K 
207 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.1    | GELU        | 0     
208 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.2    | Dropout     | 0     
209 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.3    | Linear      | 262 K 
210 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.4    | Dropout     | 0     
211 | _ViT_Trainer__model.to_latent                           | Identity    | 0     
212 | _ViT_Trainer__model.mlp_head                            | Sequential  | 6 K   
213 | _ViT_Trainer__model.mlp_head.0                          | LayerNorm   | 1 K   
214 | _ViT_Trainer__model.mlp_head.1                          | Linear      | 5 K   
Files already downloaded and verified
Files already downloaded and verified
Validation sanity check: 0it [00:00, ?it/s]WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Validation sanity check:  20%|██        | 1/5 [00:04<00:16,  4.23s/it]Validation sanity check:  40%|████      | 2/5 [00:04<00:05,  1.81s/it]Validation sanity check:  60%|██████    | 3/5 [00:04<00:02,  1.04s/it]Validation sanity check:  80%|████████  | 4/5 [00:04<00:00,  1.47it/s]Validation sanity check: 100%|██████████| 5/5 [00:04<00:00,  2.07it/s]                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/196 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/196 [00:00<?, ?it/s] /scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Epoch 1:   1%|          | 1/196 [00:01<04:16,  1.31s/it]Epoch 1:   1%|          | 1/196 [00:01<04:16,  1.31s/it, loss=2.398, v_num=6663281]Epoch 1:   1%|          | 2/196 [00:01<02:42,  1.19it/s, loss=2.398, v_num=6663281]Epoch 1:   1%|          | 2/196 [00:01<02:42,  1.19it/s, loss=3.471, v_num=6663281]Epoch 1:   2%|▏         | 3/196 [00:02<02:11,  1.46it/s, loss=3.471, v_num=6663281]Epoch 1:   2%|▏         | 3/196 [00:02<02:11,  1.46it/s, loss=3.589, v_num=6663281]Epoch 1:   2%|▏         | 4/196 [00:02<01:55,  1.66it/s, loss=3.589, v_num=6663281]Epoch 1:   2%|▏         | 4/196 [00:02<01:55,  1.66it/s, loss=3.543, v_num=6663281]Epoch 1:   3%|▎         | 5/196 [00:02<01:46,  1.79it/s, loss=3.543, v_num=6663281]Epoch 1:   3%|▎         | 5/196 [00:02<01:46,  1.79it/s, loss=3.502, v_num=6663281]Epoch 1:   3%|▎         | 6/196 [00:03<01:39,  1.90it/s, loss=3.502, v_num=6663281]Epoch 1:   3%|▎         | 6/196 [00:03<01:39,  1.90it/s, loss=3.420, v_num=6663281]Epoch 1:   4%|▎         | 7/196 [00:03<01:35,  1.99it/s, loss=3.420, v_num=6663281]Epoch 1:   4%|▎         | 7/196 [00:03<01:35,  1.99it/s, loss=3.320, v_num=6663281]Epoch 1:   4%|▍         | 8/196 [00:03<01:31,  2.06it/s, loss=3.320, v_num=6663281]Epoch 1:   4%|▍         | 8/196 [00:03<01:31,  2.06it/s, loss=3.192, v_num=6663281]Epoch 1:   5%|▍         | 9/196 [00:04<01:28,  2.11it/s, loss=3.192, v_num=6663281]Epoch 1:   5%|▍         | 9/196 [00:04<01:28,  2.11it/s, loss=3.092, v_num=6663281]Epoch 1:   5%|▌         | 10/196 [00:04<01:25,  2.16it/s, loss=3.092, v_num=6663281]Epoch 1:   5%|▌         | 10/196 [00:04<01:25,  2.16it/s, loss=3.009, v_num=6663281]Epoch 1:   6%|▌         | 11/196 [00:04<01:23,  2.20it/s, loss=3.009, v_num=6663281]Epoch 1:   6%|▌         | 11/196 [00:04<01:23,  2.20it/s, loss=2.945, v_num=6663281]Epoch 1:   6%|▌         | 12/196 [00:05<01:22,  2.24it/s, loss=2.945, v_num=6663281]Epoch 1:   6%|▌         | 12/196 [00:05<01:22,  2.24it/s, loss=2.896, v_num=6663281]Epoch 1:   7%|▋         | 13/196 [00:05<01:20,  2.27it/s, loss=2.896, v_num=6663281]Epoch 1:   7%|▋         | 13/196 [00:05<01:20,  2.27it/s, loss=2.849, v_num=6663281]Epoch 1:   7%|▋         | 14/196 [00:06<01:19,  2.30it/s, loss=2.849, v_num=6663281]Epoch 1:   7%|▋         | 14/196 [00:06<01:19,  2.30it/s, loss=2.806, v_num=6663281]Epoch 1:   8%|▊         | 15/196 [00:06<01:18,  2.32it/s, loss=2.806, v_num=6663281]Epoch 1:   8%|▊         | 15/196 [00:06<01:18,  2.32it/s, loss=2.769, v_num=6663281]Epoch 1:   8%|▊         | 16/196 [00:06<01:16,  2.34it/s, loss=2.769, v_num=6663281]Epoch 1:   8%|▊         | 16/196 [00:06<01:16,  2.34it/s, loss=2.730, v_num=6663281]Epoch 1:   9%|▊         | 17/196 [00:07<01:15,  2.36it/s, loss=2.730, v_num=6663281]Epoch 1:   9%|▊         | 17/196 [00:07<01:15,  2.36it/s, loss=2.699, v_num=6663281]Epoch 1:   9%|▉         | 18/196 [00:07<01:15,  2.37it/s, loss=2.699, v_num=6663281]Epoch 1:   9%|▉         | 18/196 [00:07<01:15,  2.37it/s, loss=2.672, v_num=6663281]Epoch 1:  10%|▉         | 19/196 [00:07<01:14,  2.38it/s, loss=2.672, v_num=6663281]Epoch 1:  10%|▉         | 19/196 [00:07<01:14,  2.38it/s, loss=2.649, v_num=6663281]Epoch 1:  10%|█         | 20/196 [00:08<01:13,  2.40it/s, loss=2.649, v_num=6663281]Epoch 1:  10%|█         | 20/196 [00:08<01:13,  2.40it/s, loss=2.626, v_num=6663281]Epoch 1:  11%|█         | 21/196 [00:08<01:12,  2.41it/s, loss=2.626, v_num=6663281]Epoch 1:  11%|█         | 21/196 [00:08<01:12,  2.41it/s, loss=2.615, v_num=6663281]Epoch 1:  11%|█         | 22/196 [00:09<01:11,  2.42it/s, loss=2.615, v_num=6663281]Epoch 1:  11%|█         | 22/196 [00:09<01:11,  2.42it/s, loss=2.490, v_num=6663281]Epoch 1:  12%|█▏        | 23/196 [00:09<01:11,  2.44it/s, loss=2.490, v_num=6663281]Epoch 1:  12%|█▏        | 23/196 [00:09<01:11,  2.44it/s, loss=2.402, v_num=6663281]Epoch 1:  12%|█▏        | 24/196 [00:09<01:10,  2.44it/s, loss=2.402, v_num=6663281]Epoch 1:  12%|█▏        | 24/196 [00:09<01:10,  2.44it/s, loss=2.337, v_num=6663281]Epoch 1:  13%|█▎        | 25/196 [00:10<01:09,  2.45it/s, loss=2.337, v_num=6663281]Epoch 1:  13%|█▎        | 25/196 [00:10<01:09,  2.45it/s, loss=2.277, v_num=6663281]Epoch 1:  13%|█▎        | 26/196 [00:10<01:08,  2.47it/s, loss=2.277, v_num=6663281]Epoch 1:  13%|█▎        | 26/196 [00:10<01:08,  2.47it/s, loss=2.237, v_num=6663281]Epoch 1:  14%|█▍        | 27/196 [00:10<01:08,  2.47it/s, loss=2.237, v_num=6663281]Epoch 1:  14%|█▍        | 27/196 [00:10<01:08,  2.47it/s, loss=2.206, v_num=6663281]Epoch 1:  14%|█▍        | 28/196 [00:11<01:07,  2.48it/s, loss=2.206, v_num=6663281]Epoch 1:  14%|█▍        | 28/196 [00:11<01:07,  2.48it/s, loss=2.195, v_num=6663281]Epoch 1:  15%|█▍        | 29/196 [00:11<01:07,  2.49it/s, loss=2.195, v_num=6663281]Epoch 1:  15%|█▍        | 29/196 [00:11<01:07,  2.49it/s, loss=2.188, v_num=6663281]Epoch 1:  15%|█▌        | 30/196 [00:12<01:06,  2.50it/s, loss=2.188, v_num=6663281]Epoch 1:  15%|█▌        | 30/196 [00:12<01:06,  2.50it/s, loss=2.179, v_num=6663281]Epoch 1:  16%|█▌        | 31/196 [00:12<01:05,  2.50it/s, loss=2.179, v_num=6663281]Epoch 1:  16%|█▌        | 31/196 [00:12<01:05,  2.50it/s, loss=2.166, v_num=6663281]Epoch 1:  16%|█▋        | 32/196 [00:12<01:05,  2.51it/s, loss=2.166, v_num=6663281]Epoch 1:  16%|█▋        | 32/196 [00:12<01:05,  2.51it/s, loss=2.156, v_num=6663281]Epoch 1:  17%|█▋        | 33/196 [00:13<01:04,  2.51it/s, loss=2.156, v_num=6663281]Epoch 1:  17%|█▋        | 33/196 [00:13<01:04,  2.51it/s, loss=2.153, v_num=6663281]Epoch 1:  17%|█▋        | 34/196 [00:13<01:04,  2.52it/s, loss=2.153, v_num=6663281]Epoch 1:  17%|█▋        | 34/196 [00:13<01:04,  2.52it/s, loss=2.150, v_num=6663281]Epoch 1:  18%|█▊        | 35/196 [00:13<01:03,  2.52it/s, loss=2.150, v_num=6663281]Epoch 1:  18%|█▊        | 35/196 [00:13<01:03,  2.52it/s, loss=2.141, v_num=6663281]Epoch 1:  18%|█▊        | 36/196 [00:14<01:03,  2.53it/s, loss=2.141, v_num=6663281]Epoch 1:  18%|█▊        | 36/196 [00:14<01:03,  2.53it/s, loss=2.137, v_num=6663281]Epoch 1:  19%|█▉        | 37/196 [00:14<01:02,  2.53it/s, loss=2.137, v_num=6663281]Epoch 1:  19%|█▉        | 37/196 [00:14<01:02,  2.53it/s, loss=2.134, v_num=6663281]Epoch 1:  19%|█▉        | 38/196 [00:15<01:02,  2.53it/s, loss=2.134, v_num=6663281]Epoch 1:  19%|█▉        | 38/196 [00:15<01:02,  2.53it/s, loss=2.126, v_num=6663281]Epoch 1:  20%|█▉        | 39/196 [00:15<01:01,  2.54it/s, loss=2.126, v_num=6663281]Epoch 1:  20%|█▉        | 39/196 [00:15<01:01,  2.54it/s, loss=2.117, v_num=6663281]Epoch 1:  20%|██        | 40/196 [00:15<01:01,  2.54it/s, loss=2.117, v_num=6663281]Epoch 1:  20%|██        | 40/196 [00:15<01:01,  2.54it/s, loss=2.110, v_num=6663281]Epoch 1:  21%|██        | 41/196 [00:16<01:00,  2.55it/s, loss=2.110, v_num=6663281]Epoch 1:  21%|██        | 41/196 [00:16<01:00,  2.55it/s, loss=2.103, v_num=6663281]Epoch 1:  21%|██▏       | 42/196 [00:16<01:00,  2.55it/s, loss=2.103, v_num=6663281]Epoch 1:  21%|██▏       | 42/196 [00:16<01:00,  2.55it/s, loss=2.104, v_num=6663281]Epoch 1:  22%|██▏       | 43/196 [00:16<00:59,  2.55it/s, loss=2.104, v_num=6663281]Epoch 1:  22%|██▏       | 43/196 [00:16<00:59,  2.55it/s, loss=2.105, v_num=6663281]Epoch 1:  22%|██▏       | 44/196 [00:17<00:59,  2.56it/s, loss=2.105, v_num=6663281]Epoch 1:  22%|██▏       | 44/196 [00:17<00:59,  2.56it/s, loss=2.103, v_num=6663281]Epoch 1:  23%|██▎       | 45/196 [00:17<00:58,  2.56it/s, loss=2.103, v_num=6663281]Epoch 1:  23%|██▎       | 45/196 [00:17<00:58,  2.56it/s, loss=2.101, v_num=6663281]Epoch 1:  23%|██▎       | 46/196 [00:17<00:58,  2.56it/s, loss=2.101, v_num=6663281]Epoch 1:  23%|██▎       | 46/196 [00:17<00:58,  2.56it/s, loss=2.097, v_num=6663281]Epoch 1:  24%|██▍       | 47/196 [00:18<00:58,  2.56it/s, loss=2.097, v_num=6663281]Epoch 1:  24%|██▍       | 47/196 [00:18<00:58,  2.56it/s, loss=2.088, v_num=6663281]Epoch 1:  24%|██▍       | 48/196 [00:18<00:57,  2.57it/s, loss=2.088, v_num=6663281]Epoch 1:  24%|██▍       | 48/196 [00:18<00:57,  2.57it/s, loss=2.087, v_num=6663281]Epoch 1:  25%|██▌       | 49/196 [00:19<00:57,  2.57it/s, loss=2.087, v_num=6663281]Epoch 1:  25%|██▌       | 49/196 [00:19<00:57,  2.57it/s, loss=2.082, v_num=6663281]Epoch 1:  26%|██▌       | 50/196 [00:19<00:56,  2.57it/s, loss=2.082, v_num=6663281]Epoch 1:  26%|██▌       | 50/196 [00:19<00:56,  2.57it/s, loss=2.078, v_num=6663281]Epoch 1:  26%|██▌       | 51/196 [00:19<00:56,  2.58it/s, loss=2.078, v_num=6663281]Epoch 1:  26%|██▌       | 51/196 [00:19<00:56,  2.58it/s, loss=2.080, v_num=6663281]Epoch 1:  27%|██▋       | 52/196 [00:20<00:55,  2.58it/s, loss=2.080, v_num=6663281]Epoch 1:  27%|██▋       | 52/196 [00:20<00:55,  2.58it/s, loss=2.073, v_num=6663281]Epoch 1:  27%|██▋       | 53/196 [00:20<00:55,  2.58it/s, loss=2.073, v_num=6663281]Epoch 1:  27%|██▋       | 53/196 [00:20<00:55,  2.58it/s, loss=2.064, v_num=6663281]Epoch 1:  28%|██▊       | 54/196 [00:20<00:54,  2.58it/s, loss=2.064, v_num=6663281]Epoch 1:  28%|██▊       | 54/196 [00:20<00:54,  2.58it/s, loss=2.058, v_num=6663281]Epoch 1:  28%|██▊       | 55/196 [00:21<00:54,  2.59it/s, loss=2.058, v_num=6663281]Epoch 1:  28%|██▊       | 55/196 [00:21<00:54,  2.59it/s, loss=2.055, v_num=6663281]Epoch 1:  29%|██▊       | 56/196 [00:21<00:54,  2.59it/s, loss=2.055, v_num=6663281]Epoch 1:  29%|██▊       | 56/196 [00:21<00:54,  2.59it/s, loss=2.053, v_num=6663281]Epoch 1:  29%|██▉       | 57/196 [00:21<00:53,  2.59it/s, loss=2.053, v_num=6663281]Epoch 1:  29%|██▉       | 57/196 [00:21<00:53,  2.59it/s, loss=2.041, v_num=6663281]Epoch 1:  30%|██▉       | 58/196 [00:22<00:53,  2.59it/s, loss=2.041, v_num=6663281]Epoch 1:  30%|██▉       | 58/196 [00:22<00:53,  2.59it/s, loss=2.038, v_num=6663281]Epoch 1:  30%|███       | 59/196 [00:22<00:52,  2.60it/s, loss=2.038, v_num=6663281]Epoch 1:  30%|███       | 59/196 [00:22<00:52,  2.60it/s, loss=2.036, v_num=6663281]Epoch 1:  31%|███       | 60/196 [00:23<00:52,  2.60it/s, loss=2.036, v_num=6663281]Epoch 1:  31%|███       | 60/196 [00:23<00:52,  2.60it/s, loss=2.031, v_num=6663281]Epoch 1:  31%|███       | 61/196 [00:23<00:51,  2.60it/s, loss=2.031, v_num=6663281]Epoch 1:  31%|███       | 61/196 [00:23<00:51,  2.60it/s, loss=2.027, v_num=6663281]Epoch 1:  32%|███▏      | 62/196 [00:23<00:51,  2.60it/s, loss=2.027, v_num=6663281]Epoch 1:  32%|███▏      | 62/196 [00:23<00:51,  2.60it/s, loss=2.021, v_num=6663281]Epoch 1:  32%|███▏      | 63/196 [00:24<00:51,  2.60it/s, loss=2.021, v_num=6663281]Epoch 1:  32%|███▏      | 63/196 [00:24<00:51,  2.60it/s, loss=2.017, v_num=6663281]Epoch 1:  33%|███▎      | 64/196 [00:24<00:50,  2.60it/s, loss=2.017, v_num=6663281]Epoch 1:  33%|███▎      | 64/196 [00:24<00:50,  2.60it/s, loss=2.010, v_num=6663281]Epoch 1:  33%|███▎      | 65/196 [00:24<00:50,  2.61it/s, loss=2.010, v_num=6663281]Epoch 1:  33%|███▎      | 65/196 [00:24<00:50,  2.61it/s, loss=2.008, v_num=6663281]Epoch 1:  34%|███▎      | 66/196 [00:25<00:49,  2.61it/s, loss=2.008, v_num=6663281]Epoch 1:  34%|███▎      | 66/196 [00:25<00:49,  2.61it/s, loss=1.997, v_num=6663281]Epoch 1:  34%|███▍      | 67/196 [00:25<00:49,  2.61it/s, loss=1.997, v_num=6663281]Epoch 1:  34%|███▍      | 67/196 [00:25<00:49,  2.61it/s, loss=2.001, v_num=6663281]Epoch 1:  35%|███▍      | 68/196 [00:26<00:49,  2.61it/s, loss=2.001, v_num=6663281]Epoch 1:  35%|███▍      | 68/196 [00:26<00:49,  2.61it/s, loss=1.995, v_num=6663281]Epoch 1:  35%|███▌      | 69/196 [00:26<00:48,  2.61it/s, loss=1.995, v_num=6663281]Epoch 1:  35%|███▌      | 69/196 [00:26<00:48,  2.61it/s, loss=1.987, v_num=6663281]Epoch 1:  36%|███▌      | 70/196 [00:26<00:48,  2.61it/s, loss=1.987, v_num=6663281]Epoch 1:  36%|███▌      | 70/196 [00:26<00:48,  2.61it/s, loss=1.980, v_num=6663281]Epoch 1:  36%|███▌      | 71/196 [00:27<00:47,  2.61it/s, loss=1.980, v_num=6663281]Epoch 1:  36%|███▌      | 71/196 [00:27<00:47,  2.61it/s, loss=1.974, v_num=6663281]Epoch 1:  37%|███▋      | 72/196 [00:27<00:47,  2.61it/s, loss=1.974, v_num=6663281]Epoch 1:  37%|███▋      | 72/196 [00:27<00:47,  2.61it/s, loss=1.972, v_num=6663281]Epoch 1:  37%|███▋      | 73/196 [00:27<00:47,  2.61it/s, loss=1.972, v_num=6663281]Epoch 1:  37%|███▋      | 73/196 [00:27<00:47,  2.61it/s, loss=1.967, v_num=6663281]Epoch 1:  38%|███▊      | 74/196 [00:28<00:46,  2.61it/s, loss=1.967, v_num=6663281]Epoch 1:  38%|███▊      | 74/196 [00:28<00:46,  2.61it/s, loss=1.961, v_num=6663281]Epoch 1:  38%|███▊      | 75/196 [00:28<00:46,  2.62it/s, loss=1.961, v_num=6663281]Epoch 1:  38%|███▊      | 75/196 [00:28<00:46,  2.62it/s, loss=1.954, v_num=6663281]Epoch 1:  39%|███▉      | 76/196 [00:29<00:45,  2.62it/s, loss=1.954, v_num=6663281]Epoch 1:  39%|███▉      | 76/196 [00:29<00:45,  2.62it/s, loss=1.947, v_num=6663281]Epoch 1:  39%|███▉      | 77/196 [00:29<00:45,  2.62it/s, loss=1.947, v_num=6663281]Epoch 1:  39%|███▉      | 77/196 [00:29<00:45,  2.62it/s, loss=1.950, v_num=6663281]Epoch 1:  40%|███▉      | 78/196 [00:29<00:45,  2.62it/s, loss=1.950, v_num=6663281]Epoch 1:  40%|███▉      | 78/196 [00:29<00:45,  2.62it/s, loss=1.945, v_num=6663281]Epoch 1:  40%|████      | 79/196 [00:30<00:44,  2.62it/s, loss=1.945, v_num=6663281]Epoch 1:  40%|████      | 79/196 [00:30<00:44,  2.62it/s, loss=1.942, v_num=6663281]Epoch 1:  41%|████      | 80/196 [00:30<00:44,  2.62it/s, loss=1.942, v_num=6663281]Epoch 1:  41%|████      | 80/196 [00:30<00:44,  2.62it/s, loss=1.937, v_num=6663281]Epoch 1:  41%|████▏     | 81/196 [00:30<00:43,  2.62it/s, loss=1.937, v_num=6663281]Epoch 1:  41%|████▏     | 81/196 [00:30<00:43,  2.62it/s, loss=1.937, v_num=6663281]Epoch 1:  42%|████▏     | 82/196 [00:31<00:43,  2.62it/s, loss=1.937, v_num=6663281]Epoch 1:  42%|████▏     | 82/196 [00:31<00:43,  2.62it/s, loss=1.939, v_num=6663281]Epoch 1:  42%|████▏     | 83/196 [00:31<00:43,  2.62it/s, loss=1.939, v_num=6663281]Epoch 1:  42%|████▏     | 83/196 [00:31<00:43,  2.62it/s, loss=1.931, v_num=6663281]Epoch 1:  43%|████▎     | 84/196 [00:32<00:42,  2.62it/s, loss=1.931, v_num=6663281]Epoch 1:  43%|████▎     | 84/196 [00:32<00:42,  2.62it/s, loss=1.934, v_num=6663281]Epoch 1:  43%|████▎     | 85/196 [00:32<00:42,  2.62it/s, loss=1.934, v_num=6663281]Epoch 1:  43%|████▎     | 85/196 [00:32<00:42,  2.62it/s, loss=1.927, v_num=6663281]Epoch 1:  44%|████▍     | 86/196 [00:32<00:41,  2.63it/s, loss=1.927, v_num=6663281]Epoch 1:  44%|████▍     | 86/196 [00:32<00:41,  2.63it/s, loss=1.928, v_num=6663281]Epoch 1:  44%|████▍     | 87/196 [00:33<00:41,  2.63it/s, loss=1.928, v_num=6663281]Epoch 1:  44%|████▍     | 87/196 [00:33<00:41,  2.63it/s, loss=1.922, v_num=6663281]Epoch 1:  45%|████▍     | 88/196 [00:33<00:41,  2.63it/s, loss=1.922, v_num=6663281]Epoch 1:  45%|████▍     | 88/196 [00:33<00:41,  2.63it/s, loss=1.922, v_num=6663281]Epoch 1:  45%|████▌     | 89/196 [00:33<00:40,  2.63it/s, loss=1.922, v_num=6663281]Epoch 1:  45%|████▌     | 89/196 [00:33<00:40,  2.63it/s, loss=1.923, v_num=6663281]Epoch 1:  46%|████▌     | 90/196 [00:34<00:40,  2.63it/s, loss=1.923, v_num=6663281]Epoch 1:  46%|████▌     | 90/196 [00:34<00:40,  2.63it/s, loss=1.925, v_num=6663281]Epoch 1:  46%|████▋     | 91/196 [00:34<00:39,  2.63it/s, loss=1.925, v_num=6663281]Epoch 1:  46%|████▋     | 91/196 [00:34<00:39,  2.63it/s, loss=1.922, v_num=6663281]Epoch 1:  47%|████▋     | 92/196 [00:34<00:39,  2.63it/s, loss=1.922, v_num=6663281]Epoch 1:  47%|████▋     | 92/196 [00:34<00:39,  2.63it/s, loss=1.918, v_num=6663281]Epoch 1:  47%|████▋     | 93/196 [00:35<00:39,  2.63it/s, loss=1.918, v_num=6663281]Epoch 1:  47%|████▋     | 93/196 [00:35<00:39,  2.63it/s, loss=1.916, v_num=6663281]Epoch 1:  48%|████▊     | 94/196 [00:35<00:38,  2.63it/s, loss=1.916, v_num=6663281]Epoch 1:  48%|████▊     | 94/196 [00:35<00:38,  2.63it/s, loss=1.909, v_num=6663281]Epoch 1:  48%|████▊     | 95/196 [00:36<00:38,  2.63it/s, loss=1.909, v_num=6663281]Epoch 1:  48%|████▊     | 95/196 [00:36<00:38,  2.63it/s, loss=1.911, v_num=6663281]Epoch 1:  49%|████▉     | 96/196 [00:36<00:37,  2.63it/s, loss=1.911, v_num=6663281]Epoch 1:  49%|████▉     | 96/196 [00:36<00:37,  2.63it/s, loss=1.909, v_num=6663281]Epoch 1:  49%|████▉     | 97/196 [00:36<00:37,  2.63it/s, loss=1.909, v_num=6663281]Epoch 1:  49%|████▉     | 97/196 [00:36<00:37,  2.63it/s, loss=1.905, v_num=6663281]Epoch 1:  50%|█████     | 98/196 [00:37<00:37,  2.63it/s, loss=1.905, v_num=6663281]Epoch 1:  50%|█████     | 98/196 [00:37<00:37,  2.63it/s, loss=1.905, v_num=6663281]Epoch 1:  51%|█████     | 99/196 [00:37<00:36,  2.64it/s, loss=1.905, v_num=6663281]Epoch 1:  51%|█████     | 99/196 [00:37<00:36,  2.64it/s, loss=1.901, v_num=6663281]Epoch 1:  51%|█████     | 100/196 [00:37<00:36,  2.64it/s, loss=1.901, v_num=6663281]Epoch 1:  51%|█████     | 100/196 [00:37<00:36,  2.64it/s, loss=1.900, v_num=6663281]Epoch 1:  52%|█████▏    | 101/196 [00:38<00:36,  2.64it/s, loss=1.900, v_num=6663281]Epoch 1:  52%|█████▏    | 101/196 [00:38<00:36,  2.64it/s, loss=1.895, v_num=6663281]Epoch 1:  52%|█████▏    | 102/196 [00:38<00:35,  2.64it/s, loss=1.895, v_num=6663281]Epoch 1:  52%|█████▏    | 102/196 [00:38<00:35,  2.64it/s, loss=1.885, v_num=6663281]Epoch 1:  53%|█████▎    | 103/196 [00:39<00:35,  2.64it/s, loss=1.885, v_num=6663281]Epoch 1:  53%|█████▎    | 103/196 [00:39<00:35,  2.64it/s, loss=1.887, v_num=6663281]Epoch 1:  53%|█████▎    | 104/196 [00:39<00:34,  2.64it/s, loss=1.887, v_num=6663281]Epoch 1:  53%|█████▎    | 104/196 [00:39<00:34,  2.64it/s, loss=1.885, v_num=6663281]Epoch 1:  54%|█████▎    | 105/196 [00:39<00:34,  2.64it/s, loss=1.885, v_num=6663281]Epoch 1:  54%|█████▎    | 105/196 [00:39<00:34,  2.64it/s, loss=1.883, v_num=6663281]Epoch 1:  54%|█████▍    | 106/196 [00:40<00:34,  2.64it/s, loss=1.883, v_num=6663281]Epoch 1:  54%|█████▍    | 106/196 [00:40<00:34,  2.64it/s, loss=1.884, v_num=6663281]Epoch 1:  55%|█████▍    | 107/196 [00:40<00:33,  2.64it/s, loss=1.884, v_num=6663281]Epoch 1:  55%|█████▍    | 107/196 [00:40<00:33,  2.64it/s, loss=1.878, v_num=6663281]Epoch 1:  55%|█████▌    | 108/196 [00:40<00:33,  2.64it/s, loss=1.878, v_num=6663281]Epoch 1:  55%|█████▌    | 108/196 [00:40<00:33,  2.64it/s, loss=1.872, v_num=6663281]Epoch 1:  56%|█████▌    | 109/196 [00:41<00:32,  2.64it/s, loss=1.872, v_num=6663281]Epoch 1:  56%|█████▌    | 109/196 [00:41<00:32,  2.64it/s, loss=1.867, v_num=6663281]Epoch 1:  56%|█████▌    | 110/196 [00:41<00:32,  2.64it/s, loss=1.867, v_num=6663281]Epoch 1:  56%|█████▌    | 110/196 [00:41<00:32,  2.64it/s, loss=1.867, v_num=6663281]Epoch 1:  57%|█████▋    | 111/196 [00:41<00:32,  2.64it/s, loss=1.867, v_num=6663281]Epoch 1:  57%|█████▋    | 111/196 [00:41<00:32,  2.64it/s, loss=1.867, v_num=6663281]Epoch 1:  57%|█████▋    | 112/196 [00:42<00:31,  2.65it/s, loss=1.867, v_num=6663281]Epoch 1:  57%|█████▋    | 112/196 [00:42<00:31,  2.65it/s, loss=1.864, v_num=6663281]Epoch 1:  58%|█████▊    | 113/196 [00:42<00:31,  2.65it/s, loss=1.864, v_num=6663281]Epoch 1:  58%|█████▊    | 113/196 [00:42<00:31,  2.65it/s, loss=1.861, v_num=6663281]Epoch 1:  58%|█████▊    | 114/196 [00:43<00:30,  2.65it/s, loss=1.861, v_num=6663281]Epoch 1:  58%|█████▊    | 114/196 [00:43<00:30,  2.65it/s, loss=1.861, v_num=6663281]Epoch 1:  59%|█████▊    | 115/196 [00:43<00:30,  2.65it/s, loss=1.861, v_num=6663281]Epoch 1:  59%|█████▊    | 115/196 [00:43<00:30,  2.65it/s, loss=1.854, v_num=6663281]Epoch 1:  59%|█████▉    | 116/196 [00:43<00:30,  2.65it/s, loss=1.854, v_num=6663281]Epoch 1:  59%|█████▉    | 116/196 [00:43<00:30,  2.65it/s, loss=1.858, v_num=6663281]Epoch 1:  60%|█████▉    | 117/196 [00:44<00:29,  2.65it/s, loss=1.858, v_num=6663281]Epoch 1:  60%|█████▉    | 117/196 [00:44<00:29,  2.65it/s, loss=1.855, v_num=6663281]Epoch 1:  60%|██████    | 118/196 [00:44<00:29,  2.65it/s, loss=1.855, v_num=6663281]Epoch 1:  60%|██████    | 118/196 [00:44<00:29,  2.65it/s, loss=1.850, v_num=6663281]Epoch 1:  61%|██████    | 119/196 [00:44<00:29,  2.65it/s, loss=1.850, v_num=6663281]Epoch 1:  61%|██████    | 119/196 [00:44<00:29,  2.65it/s, loss=1.851, v_num=6663281]Epoch 1:  61%|██████    | 120/196 [00:45<00:28,  2.65it/s, loss=1.851, v_num=6663281]Epoch 1:  61%|██████    | 120/196 [00:45<00:28,  2.65it/s, loss=1.847, v_num=6663281]Epoch 1:  62%|██████▏   | 121/196 [00:45<00:28,  2.65it/s, loss=1.847, v_num=6663281]Epoch 1:  62%|██████▏   | 121/196 [00:45<00:28,  2.65it/s, loss=1.847, v_num=6663281]Epoch 1:  62%|██████▏   | 122/196 [00:46<00:27,  2.65it/s, loss=1.847, v_num=6663281]Epoch 1:  62%|██████▏   | 122/196 [00:46<00:27,  2.65it/s, loss=1.846, v_num=6663281]Epoch 1:  63%|██████▎   | 123/196 [00:46<00:27,  2.65it/s, loss=1.846, v_num=6663281]Epoch 1:  63%|██████▎   | 123/196 [00:46<00:27,  2.65it/s, loss=1.844, v_num=6663281]Epoch 1:  63%|██████▎   | 124/196 [00:46<00:27,  2.65it/s, loss=1.844, v_num=6663281]Epoch 1:  63%|██████▎   | 124/196 [00:46<00:27,  2.65it/s, loss=1.837, v_num=6663281]Epoch 1:  64%|██████▍   | 125/196 [00:47<00:26,  2.65it/s, loss=1.837, v_num=6663281]Epoch 1:  64%|██████▍   | 125/196 [00:47<00:26,  2.65it/s, loss=1.831, v_num=6663281]Epoch 1:  64%|██████▍   | 126/196 [00:47<00:26,  2.65it/s, loss=1.831, v_num=6663281]Epoch 1:  64%|██████▍   | 126/196 [00:47<00:26,  2.65it/s, loss=1.825, v_num=6663281]Epoch 1:  65%|██████▍   | 127/196 [00:47<00:26,  2.65it/s, loss=1.825, v_num=6663281]Epoch 1:  65%|██████▍   | 127/196 [00:47<00:26,  2.65it/s, loss=1.827, v_num=6663281]Epoch 1:  65%|██████▌   | 128/196 [00:48<00:25,  2.65it/s, loss=1.827, v_num=6663281]Epoch 1:  65%|██████▌   | 128/196 [00:48<00:25,  2.65it/s, loss=1.827, v_num=6663281]Epoch 1:  66%|██████▌   | 129/196 [00:48<00:25,  2.65it/s, loss=1.827, v_num=6663281]Epoch 1:  66%|██████▌   | 129/196 [00:48<00:25,  2.65it/s, loss=1.833, v_num=6663281]Epoch 1:  66%|██████▋   | 130/196 [00:49<00:24,  2.65it/s, loss=1.833, v_num=6663281]Epoch 1:  66%|██████▋   | 130/196 [00:49<00:24,  2.65it/s, loss=1.827, v_num=6663281]Epoch 1:  67%|██████▋   | 131/196 [00:49<00:24,  2.65it/s, loss=1.827, v_num=6663281]Epoch 1:  67%|██████▋   | 131/196 [00:49<00:24,  2.65it/s, loss=1.830, v_num=6663281]Epoch 1:  67%|██████▋   | 132/196 [00:49<00:24,  2.65it/s, loss=1.830, v_num=6663281]Epoch 1:  67%|██████▋   | 132/196 [00:49<00:24,  2.65it/s, loss=1.826, v_num=6663281]Epoch 1:  68%|██████▊   | 133/196 [00:50<00:23,  2.65it/s, loss=1.826, v_num=6663281]Epoch 1:  68%|██████▊   | 133/196 [00:50<00:23,  2.65it/s, loss=1.819, v_num=6663281]Epoch 1:  68%|██████▊   | 134/196 [00:50<00:23,  2.65it/s, loss=1.819, v_num=6663281]Epoch 1:  68%|██████▊   | 134/196 [00:50<00:23,  2.65it/s, loss=1.819, v_num=6663281]Epoch 1:  69%|██████▉   | 135/196 [00:50<00:22,  2.65it/s, loss=1.819, v_num=6663281]Epoch 1:  69%|██████▉   | 135/196 [00:50<00:22,  2.65it/s, loss=1.818, v_num=6663281]Epoch 1:  69%|██████▉   | 136/196 [00:51<00:22,  2.65it/s, loss=1.818, v_num=6663281]Epoch 1:  69%|██████▉   | 136/196 [00:51<00:22,  2.65it/s, loss=1.815, v_num=6663281]Epoch 1:  70%|██████▉   | 137/196 [00:51<00:22,  2.65it/s, loss=1.815, v_num=6663281]Epoch 1:  70%|██████▉   | 137/196 [00:51<00:22,  2.65it/s, loss=1.815, v_num=6663281]Epoch 1:  70%|███████   | 138/196 [00:51<00:21,  2.66it/s, loss=1.815, v_num=6663281]Epoch 1:  70%|███████   | 138/196 [00:51<00:21,  2.66it/s, loss=1.820, v_num=6663281]Epoch 1:  71%|███████   | 139/196 [00:52<00:21,  2.66it/s, loss=1.820, v_num=6663281]Epoch 1:  71%|███████   | 139/196 [00:52<00:21,  2.66it/s, loss=1.817, v_num=6663281]Epoch 1:  71%|███████▏  | 140/196 [00:52<00:21,  2.66it/s, loss=1.817, v_num=6663281]Epoch 1:  71%|███████▏  | 140/196 [00:52<00:21,  2.66it/s, loss=1.818, v_num=6663281]Epoch 1:  72%|███████▏  | 141/196 [00:53<00:20,  2.66it/s, loss=1.818, v_num=6663281]Epoch 1:  72%|███████▏  | 141/196 [00:53<00:20,  2.66it/s, loss=1.817, v_num=6663281]Epoch 1:  72%|███████▏  | 142/196 [00:53<00:20,  2.66it/s, loss=1.817, v_num=6663281]Epoch 1:  72%|███████▏  | 142/196 [00:53<00:20,  2.66it/s, loss=1.816, v_num=6663281]Epoch 1:  73%|███████▎  | 143/196 [00:53<00:19,  2.66it/s, loss=1.816, v_num=6663281]Epoch 1:  73%|███████▎  | 143/196 [00:53<00:19,  2.66it/s, loss=1.818, v_num=6663281]Epoch 1:  73%|███████▎  | 144/196 [00:54<00:19,  2.66it/s, loss=1.818, v_num=6663281]Epoch 1:  73%|███████▎  | 144/196 [00:54<00:19,  2.66it/s, loss=1.817, v_num=6663281]Epoch 1:  74%|███████▍  | 145/196 [00:54<00:19,  2.66it/s, loss=1.817, v_num=6663281]Epoch 1:  74%|███████▍  | 145/196 [00:54<00:19,  2.66it/s, loss=1.813, v_num=6663281]Epoch 1:  74%|███████▍  | 146/196 [00:54<00:18,  2.66it/s, loss=1.813, v_num=6663281]Epoch 1:  74%|███████▍  | 146/196 [00:54<00:18,  2.66it/s, loss=1.809, v_num=6663281]Epoch 1:  75%|███████▌  | 147/196 [00:55<00:18,  2.66it/s, loss=1.809, v_num=6663281]Epoch 1:  75%|███████▌  | 147/196 [00:55<00:18,  2.66it/s, loss=1.808, v_num=6663281]Epoch 1:  76%|███████▌  | 148/196 [00:55<00:18,  2.66it/s, loss=1.808, v_num=6663281]Epoch 1:  76%|███████▌  | 148/196 [00:55<00:18,  2.66it/s, loss=1.803, v_num=6663281]Epoch 1:  76%|███████▌  | 149/196 [00:56<00:17,  2.66it/s, loss=1.803, v_num=6663281]Epoch 1:  76%|███████▌  | 149/196 [00:56<00:17,  2.66it/s, loss=1.792, v_num=6663281]Epoch 1:  77%|███████▋  | 150/196 [00:56<00:17,  2.66it/s, loss=1.792, v_num=6663281]Epoch 1:  77%|███████▋  | 150/196 [00:56<00:17,  2.66it/s, loss=1.791, v_num=6663281]Epoch 1:  77%|███████▋  | 151/196 [00:56<00:16,  2.66it/s, loss=1.791, v_num=6663281]Epoch 1:  77%|███████▋  | 151/196 [00:56<00:16,  2.66it/s, loss=1.780, v_num=6663281]Epoch 1:  78%|███████▊  | 152/196 [00:57<00:16,  2.66it/s, loss=1.780, v_num=6663281]Epoch 1:  78%|███████▊  | 152/196 [00:57<00:16,  2.66it/s, loss=1.776, v_num=6663281]Epoch 1:  78%|███████▊  | 153/196 [00:57<00:16,  2.66it/s, loss=1.776, v_num=6663281]Epoch 1:  78%|███████▊  | 153/196 [00:57<00:16,  2.66it/s, loss=1.773, v_num=6663281]Epoch 1:  79%|███████▊  | 154/196 [00:57<00:15,  2.66it/s, loss=1.773, v_num=6663281]Epoch 1:  79%|███████▊  | 154/196 [00:57<00:15,  2.66it/s, loss=1.769, v_num=6663281]Epoch 1:  79%|███████▉  | 155/196 [00:58<00:15,  2.66it/s, loss=1.769, v_num=6663281]Epoch 1:  79%|███████▉  | 155/196 [00:58<00:15,  2.66it/s, loss=1.763, v_num=6663281]Epoch 1:  80%|███████▉  | 156/196 [00:58<00:15,  2.66it/s, loss=1.763, v_num=6663281]Epoch 1:  80%|███████▉  | 156/196 [00:58<00:15,  2.66it/s, loss=1.762, v_num=6663281]Epoch 1:  80%|████████  | 157/196 [00:59<00:14,  2.66it/s, loss=1.762, v_num=6663281]Epoch 1:  80%|████████  | 157/196 [00:59<00:14,  2.66it/s, loss=1.765, v_num=6663281]Epoch 1:  81%|████████  | 158/196 [00:59<00:14,  2.66it/s, loss=1.765, v_num=6663281]Epoch 1:  81%|████████  | 158/196 [00:59<00:14,  2.66it/s, loss=1.754, v_num=6663281]Epoch 1:  81%|████████  | 159/196 [00:59<00:13,  2.66it/s, loss=1.754, v_num=6663281]Epoch 1:  81%|████████  | 159/196 [00:59<00:13,  2.66it/s, loss=1.745, v_num=6663281]Epoch 1:  82%|████████▏ | 160/196 [01:00<00:13,  2.66it/s, loss=1.745, v_num=6663281]Epoch 1:  82%|████████▏ | 160/196 [01:00<00:13,  2.66it/s, loss=1.744, v_num=6663281]Epoch 1:  82%|████████▏ | 161/196 [01:00<00:13,  2.66it/s, loss=1.744, v_num=6663281]Epoch 1:  82%|████████▏ | 161/196 [01:00<00:13,  2.66it/s, loss=1.736, v_num=6663281]Epoch 1:  83%|████████▎ | 162/196 [01:00<00:12,  2.66it/s, loss=1.736, v_num=6663281]Epoch 1:  83%|████████▎ | 162/196 [01:00<00:12,  2.66it/s, loss=1.727, v_num=6663281]Epoch 1:  83%|████████▎ | 163/196 [01:01<00:12,  2.66it/s, loss=1.727, v_num=6663281]Epoch 1:  83%|████████▎ | 163/196 [01:01<00:12,  2.66it/s, loss=1.722, v_num=6663281]Epoch 1:  84%|████████▎ | 164/196 [01:01<00:12,  2.66it/s, loss=1.722, v_num=6663281]Epoch 1:  84%|████████▎ | 164/196 [01:01<00:12,  2.66it/s, loss=1.722, v_num=6663281]Epoch 1:  84%|████████▍ | 165/196 [01:01<00:11,  2.66it/s, loss=1.722, v_num=6663281]Epoch 1:  84%|████████▍ | 165/196 [01:01<00:11,  2.66it/s, loss=1.721, v_num=6663281]Epoch 1:  85%|████████▍ | 166/196 [01:02<00:11,  2.66it/s, loss=1.721, v_num=6663281]Epoch 1:  85%|████████▍ | 166/196 [01:02<00:11,  2.66it/s, loss=1.719, v_num=6663281]Epoch 1:  85%|████████▌ | 167/196 [01:02<00:10,  2.66it/s, loss=1.719, v_num=6663281]Epoch 1:  85%|████████▌ | 167/196 [01:02<00:10,  2.66it/s, loss=1.712, v_num=6663281]Epoch 1:  86%|████████▌ | 168/196 [01:03<00:10,  2.66it/s, loss=1.712, v_num=6663281]Epoch 1:  86%|████████▌ | 168/196 [01:03<00:10,  2.66it/s, loss=1.714, v_num=6663281]Epoch 1:  86%|████████▌ | 169/196 [01:03<00:10,  2.66it/s, loss=1.714, v_num=6663281]Epoch 1:  86%|████████▌ | 169/196 [01:03<00:10,  2.66it/s, loss=1.716, v_num=6663281]Epoch 1:  87%|████████▋ | 170/196 [01:03<00:09,  2.66it/s, loss=1.716, v_num=6663281]Epoch 1:  87%|████████▋ | 170/196 [01:03<00:09,  2.66it/s, loss=1.711, v_num=6663281]Epoch 1:  87%|████████▋ | 171/196 [01:04<00:09,  2.66it/s, loss=1.711, v_num=6663281]Epoch 1:  87%|████████▋ | 171/196 [01:04<00:09,  2.66it/s, loss=1.711, v_num=6663281]Epoch 1:  88%|████████▊ | 172/196 [01:04<00:09,  2.66it/s, loss=1.711, v_num=6663281]Epoch 1:  88%|████████▊ | 172/196 [01:04<00:09,  2.66it/s, loss=1.717, v_num=6663281]Epoch 1:  88%|████████▊ | 173/196 [01:04<00:08,  2.67it/s, loss=1.717, v_num=6663281]Epoch 1:  88%|████████▊ | 173/196 [01:04<00:08,  2.67it/s, loss=1.723, v_num=6663281]Epoch 1:  89%|████████▉ | 174/196 [01:05<00:08,  2.67it/s, loss=1.723, v_num=6663281]Epoch 1:  89%|████████▉ | 174/196 [01:05<00:08,  2.67it/s, loss=1.724, v_num=6663281]Epoch 1:  89%|████████▉ | 175/196 [01:05<00:07,  2.67it/s, loss=1.724, v_num=6663281]Epoch 1:  89%|████████▉ | 175/196 [01:05<00:07,  2.67it/s, loss=1.725, v_num=6663281]Epoch 1:  90%|████████▉ | 176/196 [01:06<00:07,  2.66it/s, loss=1.725, v_num=6663281]Epoch 1:  90%|████████▉ | 176/196 [01:06<00:07,  2.66it/s, loss=1.721, v_num=6663281]
Validating: 0it [00:00, ?it/s][AWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).

Validating:   5%|▌         | 1/20 [00:01<00:20,  1.05s/it][AEpoch 1:  90%|█████████ | 177/196 [01:07<00:07,  2.64it/s, loss=1.721, v_num=6663281]
Validating:  10%|█         | 2/20 [00:01<00:09,  1.94it/s][AEpoch 1:  91%|█████████ | 178/196 [01:07<00:06,  2.65it/s, loss=1.721, v_num=6663281]
Validating:  15%|█▌        | 3/20 [00:01<00:05,  2.97it/s][AEpoch 1:  91%|█████████▏| 179/196 [01:07<00:06,  2.66it/s, loss=1.721, v_num=6663281]
Validating:  20%|██        | 4/20 [00:01<00:04,  3.95it/s][AEpoch 1:  92%|█████████▏| 180/196 [01:07<00:06,  2.67it/s, loss=1.721, v_num=6663281]
Validating:  25%|██▌       | 5/20 [00:01<00:03,  4.83it/s][AEpoch 1:  92%|█████████▏| 181/196 [01:07<00:05,  2.68it/s, loss=1.721, v_num=6663281]
Validating:  30%|███       | 6/20 [00:01<00:02,  5.45it/s][AEpoch 1:  93%|█████████▎| 182/196 [01:07<00:05,  2.68it/s, loss=1.721, v_num=6663281]
Validating:  35%|███▌      | 7/20 [00:01<00:02,  6.08it/s][AEpoch 1:  93%|█████████▎| 183/196 [01:07<00:04,  2.69it/s, loss=1.721, v_num=6663281]
Validating:  40%|████      | 8/20 [00:01<00:01,  6.59it/s][AEpoch 1:  94%|█████████▍| 184/196 [01:08<00:04,  2.70it/s, loss=1.721, v_num=6663281]
Validating:  45%|████▌     | 9/20 [00:02<00:01,  6.79it/s][AEpoch 1:  94%|█████████▍| 185/196 [01:08<00:04,  2.71it/s, loss=1.721, v_num=6663281]
Validating:  50%|█████     | 10/20 [00:02<00:01,  7.13it/s][AEpoch 1:  95%|█████████▍| 186/196 [01:08<00:03,  2.72it/s, loss=1.721, v_num=6663281]
Validating:  55%|█████▌    | 11/20 [00:02<00:01,  7.17it/s][AEpoch 1:  95%|█████████▌| 187/196 [01:08<00:03,  2.73it/s, loss=1.721, v_num=6663281]
Validating:  60%|██████    | 12/20 [00:02<00:01,  7.28it/s][AEpoch 1:  96%|█████████▌| 188/196 [01:08<00:02,  2.74it/s, loss=1.721, v_num=6663281]
Validating:  65%|██████▌   | 13/20 [00:02<00:00,  7.49it/s][AEpoch 1:  96%|█████████▋| 189/196 [01:08<00:02,  2.75it/s, loss=1.721, v_num=6663281]
Validating:  70%|███████   | 14/20 [00:02<00:00,  7.64it/s][AEpoch 1:  97%|█████████▋| 190/196 [01:08<00:02,  2.76it/s, loss=1.721, v_num=6663281]
Validating:  75%|███████▌  | 15/20 [00:02<00:00,  7.74it/s][AEpoch 1:  97%|█████████▋| 191/196 [01:08<00:01,  2.77it/s, loss=1.721, v_num=6663281]
Validating:  80%|████████  | 16/20 [00:02<00:00,  7.82it/s][AEpoch 1:  98%|█████████▊| 192/196 [01:09<00:01,  2.78it/s, loss=1.721, v_num=6663281]
Validating:  85%|████████▌ | 17/20 [00:03<00:00,  7.88it/s][AEpoch 1:  98%|█████████▊| 193/196 [01:09<00:01,  2.79it/s, loss=1.721, v_num=6663281]
Validating:  90%|█████████ | 18/20 [00:03<00:00,  7.92it/s][AEpoch 1:  99%|█████████▉| 194/196 [01:09<00:00,  2.80it/s, loss=1.721, v_num=6663281]
Validating:  95%|█████████▌| 19/20 [00:03<00:00,  7.93it/s][AEpoch 1:  99%|█████████▉| 195/196 [01:09<00:00,  2.81it/s, loss=1.721, v_num=6663281]Epoch 1: 100%|██████████| 196/196 [01:09<00:00,  2.81it/s, loss=1.721, v_num=6663281]
                                                           [AEpoch 1:   0%|          | 0/196 [00:00<?, ?it/s, loss=1.721, v_num=6663281]          Epoch 2:   0%|          | 0/196 [00:00<?, ?it/s, loss=1.721, v_num=6663281]/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Epoch 2:   1%|          | 1/196 [00:01<04:40,  1.44s/it, loss=1.721, v_num=6663281]Epoch 2:   1%|          | 1/196 [00:01<04:40,  1.44s/it, loss=1.712, v_num=6663281]Epoch 2:   1%|          | 2/196 [00:01<02:54,  1.11it/s, loss=1.712, v_num=6663281]Epoch 2:   1%|          | 2/196 [00:01<02:54,  1.11it/s, loss=1.715, v_num=6663281]Epoch 2:   2%|▏         | 3/196 [00:02<02:20,  1.38it/s, loss=1.715, v_num=6663281]Epoch 2:   2%|▏         | 3/196 [00:02<02:20,  1.38it/s, loss=1.715, v_num=6663281]Epoch 2:   2%|▏         | 4/196 [00:02<02:02,  1.56it/s, loss=1.715, v_num=6663281]Epoch 2:   2%|▏         | 4/196 [00:02<02:02,  1.56it/s, loss=1.711, v_num=6663281]Epoch 2:   3%|▎         | 5/196 [00:02<01:51,  1.71it/s, loss=1.711, v_num=6663281]Epoch 2:   3%|▎         | 5/196 [00:02<01:51,  1.71it/s, loss=1.715, v_num=6663281]Epoch 2:   3%|▎         | 6/196 [00:03<01:44,  1.82it/s, loss=1.715, v_num=6663281]Epoch 2:   3%|▎         | 6/196 [00:03<01:44,  1.82it/s, loss=1.719, v_num=6663281]Epoch 2:   4%|▎         | 7/196 [00:03<01:38,  1.91it/s, loss=1.719, v_num=6663281]Epoch 2:   4%|▎         | 7/196 [00:03<01:38,  1.91it/s, loss=1.715, v_num=6663281]Epoch 2:   4%|▍         | 8/196 [00:04<01:34,  1.98it/s, loss=1.715, v_num=6663281]Epoch 2:   4%|▍         | 8/196 [00:04<01:34,  1.98it/s, loss=1.711, v_num=6663281]Epoch 2:   5%|▍         | 9/196 [00:04<01:31,  2.04it/s, loss=1.711, v_num=6663281]Epoch 2:   5%|▍         | 9/196 [00:04<01:31,  2.04it/s, loss=1.715, v_num=6663281]Epoch 2:   5%|▌         | 10/196 [00:04<01:28,  2.10it/s, loss=1.715, v_num=6663281]Epoch 2:   5%|▌         | 10/196 [00:04<01:28,  2.10it/s, loss=1.711, v_num=6663281]Epoch 2:   6%|▌         | 11/196 [00:05<01:26,  2.14it/s, loss=1.711, v_num=6663281]Epoch 2:   6%|▌         | 11/196 [00:05<01:26,  2.14it/s, loss=1.716, v_num=6663281]Epoch 2:   6%|▌         | 12/196 [00:05<01:24,  2.18it/s, loss=1.716, v_num=6663281]Epoch 2:   6%|▌         | 12/196 [00:05<01:24,  2.18it/s, loss=1.711, v_num=6663281]Epoch 2:   7%|▋         | 13/196 [00:05<01:22,  2.21it/s, loss=1.711, v_num=6663281]Epoch 2:   7%|▋         | 13/196 [00:05<01:22,  2.21it/s, loss=1.708, v_num=6663281]