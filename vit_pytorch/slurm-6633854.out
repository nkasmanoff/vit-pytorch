/scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO:lightning:GPU available: True, used: True
INFO:lightning:CUDA_VISIBLE_DEVICES: [0]
INFO:lightning:Set SLURM handle signals.
INFO:lightning:
    | Name                                                    | Type        | Params
------------------------------------------------------------------------------------
0   | _ViT_Trainer__model                                     | ViT         | 94 M  
1   | _ViT_Trainer__model.to_patch_embedding                  | Sequential  | 37 K  
2   | _ViT_Trainer__model.to_patch_embedding.0                | Rearrange   | 0     
3   | _ViT_Trainer__model.to_patch_embedding.1                | Linear      | 37 K  
4   | _ViT_Trainer__model.dropout                             | Dropout     | 0     
5   | _ViT_Trainer__model.transformer                         | Transformer | 94 M  
6   | _ViT_Trainer__model.transformer.layers                  | ModuleList  | 94 M  
7   | _ViT_Trainer__model.transformer.layers.0                | ModuleList  | 3 M   
8   | _ViT_Trainer__model.transformer.layers.0.0              | PreNorm     | 3 M   
9   | _ViT_Trainer__model.transformer.layers.0.0.norm         | LayerNorm   | 1 K   
10  | _ViT_Trainer__model.transformer.layers.0.0.fn           | Attention   | 3 M   
11  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_qkv    | Linear      | 2 M   
12  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_out    | Sequential  | 787 K 
13  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_out.0  | Linear      | 787 K 
14  | _ViT_Trainer__model.transformer.layers.0.0.fn.to_out.1  | Dropout     | 0     
15  | _ViT_Trainer__model.transformer.layers.0.1              | PreNorm     | 789 K 
16  | _ViT_Trainer__model.transformer.layers.0.1.norm         | LayerNorm   | 1 K   
17  | _ViT_Trainer__model.transformer.layers.0.1.fn           | FeedForward | 787 K 
18  | _ViT_Trainer__model.transformer.layers.0.1.fn.net       | Sequential  | 787 K 
19  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.0     | Linear      | 393 K 
20  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.1     | GELU        | 0     
21  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.2     | Dropout     | 0     
22  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.3     | Linear      | 393 K 
23  | _ViT_Trainer__model.transformer.layers.0.1.fn.net.4     | Dropout     | 0     
24  | _ViT_Trainer__model.transformer.layers.1                | ModuleList  | 3 M   
25  | _ViT_Trainer__model.transformer.layers.1.0              | PreNorm     | 3 M   
26  | _ViT_Trainer__model.transformer.layers.1.0.norm         | LayerNorm   | 1 K   
27  | _ViT_Trainer__model.transformer.layers.1.0.fn           | Attention   | 3 M   
28  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_qkv    | Linear      | 2 M   
29  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_out    | Sequential  | 787 K 
30  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_out.0  | Linear      | 787 K 
31  | _ViT_Trainer__model.transformer.layers.1.0.fn.to_out.1  | Dropout     | 0     
32  | _ViT_Trainer__model.transformer.layers.1.1              | PreNorm     | 789 K 
33  | _ViT_Trainer__model.transformer.layers.1.1.norm         | LayerNorm   | 1 K   
34  | _ViT_Trainer__model.transformer.layers.1.1.fn           | FeedForward | 787 K 
35  | _ViT_Trainer__model.transformer.layers.1.1.fn.net       | Sequential  | 787 K 
36  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.0     | Linear      | 393 K 
37  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.1     | GELU        | 0     
38  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.2     | Dropout     | 0     
39  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.3     | Linear      | 393 K 
40  | _ViT_Trainer__model.transformer.layers.1.1.fn.net.4     | Dropout     | 0     
41  | _ViT_Trainer__model.transformer.layers.2                | ModuleList  | 3 M   
42  | _ViT_Trainer__model.transformer.layers.2.0              | PreNorm     | 3 M   
43  | _ViT_Trainer__model.transformer.layers.2.0.norm         | LayerNorm   | 1 K   
44  | _ViT_Trainer__model.transformer.layers.2.0.fn           | Attention   | 3 M   
45  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_qkv    | Linear      | 2 M   
46  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_out    | Sequential  | 787 K 
47  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_out.0  | Linear      | 787 K 
48  | _ViT_Trainer__model.transformer.layers.2.0.fn.to_out.1  | Dropout     | 0     
49  | _ViT_Trainer__model.transformer.layers.2.1              | PreNorm     | 789 K 
50  | _ViT_Trainer__model.transformer.layers.2.1.norm         | LayerNorm   | 1 K   
51  | _ViT_Trainer__model.transformer.layers.2.1.fn           | FeedForward | 787 K 
52  | _ViT_Trainer__model.transformer.layers.2.1.fn.net       | Sequential  | 787 K 
53  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.0     | Linear      | 393 K 
54  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.1     | GELU        | 0     
55  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.2     | Dropout     | 0     
56  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.3     | Linear      | 393 K 
57  | _ViT_Trainer__model.transformer.layers.2.1.fn.net.4     | Dropout     | 0     
58  | _ViT_Trainer__model.transformer.layers.3                | ModuleList  | 3 M   
59  | _ViT_Trainer__model.transformer.layers.3.0              | PreNorm     | 3 M   
60  | _ViT_Trainer__model.transformer.layers.3.0.norm         | LayerNorm   | 1 K   
61  | _ViT_Trainer__model.transformer.layers.3.0.fn           | Attention   | 3 M   
62  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_qkv    | Linear      | 2 M   
63  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_out    | Sequential  | 787 K 
64  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_out.0  | Linear      | 787 K 
65  | _ViT_Trainer__model.transformer.layers.3.0.fn.to_out.1  | Dropout     | 0     
66  | _ViT_Trainer__model.transformer.layers.3.1              | PreNorm     | 789 K 
67  | _ViT_Trainer__model.transformer.layers.3.1.norm         | LayerNorm   | 1 K   
68  | _ViT_Trainer__model.transformer.layers.3.1.fn           | FeedForward | 787 K 
69  | _ViT_Trainer__model.transformer.layers.3.1.fn.net       | Sequential  | 787 K 
70  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.0     | Linear      | 393 K 
71  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.1     | GELU        | 0     
72  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.2     | Dropout     | 0     
73  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.3     | Linear      | 393 K 
74  | _ViT_Trainer__model.transformer.layers.3.1.fn.net.4     | Dropout     | 0     
75  | _ViT_Trainer__model.transformer.layers.4                | ModuleList  | 3 M   
76  | _ViT_Trainer__model.transformer.layers.4.0              | PreNorm     | 3 M   
77  | _ViT_Trainer__model.transformer.layers.4.0.norm         | LayerNorm   | 1 K   
78  | _ViT_Trainer__model.transformer.layers.4.0.fn           | Attention   | 3 M   
79  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_qkv    | Linear      | 2 M   
80  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_out    | Sequential  | 787 K 
81  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_out.0  | Linear      | 787 K 
82  | _ViT_Trainer__model.transformer.layers.4.0.fn.to_out.1  | Dropout     | 0     
83  | _ViT_Trainer__model.transformer.layers.4.1              | PreNorm     | 789 K 
84  | _ViT_Trainer__model.transformer.layers.4.1.norm         | LayerNorm   | 1 K   
85  | _ViT_Trainer__model.transformer.layers.4.1.fn           | FeedForward | 787 K 
86  | _ViT_Trainer__model.transformer.layers.4.1.fn.net       | Sequential  | 787 K 
87  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.0     | Linear      | 393 K 
88  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.1     | GELU        | 0     
89  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.2     | Dropout     | 0     
90  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.3     | Linear      | 393 K 
91  | _ViT_Trainer__model.transformer.layers.4.1.fn.net.4     | Dropout     | 0     
92  | _ViT_Trainer__model.transformer.layers.5                | ModuleList  | 3 M   
93  | _ViT_Trainer__model.transformer.layers.5.0              | PreNorm     | 3 M   
94  | _ViT_Trainer__model.transformer.layers.5.0.norm         | LayerNorm   | 1 K   
95  | _ViT_Trainer__model.transformer.layers.5.0.fn           | Attention   | 3 M   
96  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_qkv    | Linear      | 2 M   
97  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_out    | Sequential  | 787 K 
98  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_out.0  | Linear      | 787 K 
99  | _ViT_Trainer__model.transformer.layers.5.0.fn.to_out.1  | Dropout     | 0     
100 | _ViT_Trainer__model.transformer.layers.5.1              | PreNorm     | 789 K 
101 | _ViT_Trainer__model.transformer.layers.5.1.norm         | LayerNorm   | 1 K   
102 | _ViT_Trainer__model.transformer.layers.5.1.fn           | FeedForward | 787 K 
103 | _ViT_Trainer__model.transformer.layers.5.1.fn.net       | Sequential  | 787 K 
104 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.0     | Linear      | 393 K 
105 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.1     | GELU        | 0     
106 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.2     | Dropout     | 0     
107 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.3     | Linear      | 393 K 
108 | _ViT_Trainer__model.transformer.layers.5.1.fn.net.4     | Dropout     | 0     
109 | _ViT_Trainer__model.transformer.layers.6                | ModuleList  | 3 M   
110 | _ViT_Trainer__model.transformer.layers.6.0              | PreNorm     | 3 M   
111 | _ViT_Trainer__model.transformer.layers.6.0.norm         | LayerNorm   | 1 K   
112 | _ViT_Trainer__model.transformer.layers.6.0.fn           | Attention   | 3 M   
113 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_qkv    | Linear      | 2 M   
114 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_out    | Sequential  | 787 K 
115 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_out.0  | Linear      | 787 K 
116 | _ViT_Trainer__model.transformer.layers.6.0.fn.to_out.1  | Dropout     | 0     
117 | _ViT_Trainer__model.transformer.layers.6.1              | PreNorm     | 789 K 
118 | _ViT_Trainer__model.transformer.layers.6.1.norm         | LayerNorm   | 1 K   
119 | _ViT_Trainer__model.transformer.layers.6.1.fn           | FeedForward | 787 K 
120 | _ViT_Trainer__model.transformer.layers.6.1.fn.net       | Sequential  | 787 K 
121 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.0     | Linear      | 393 K 
122 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.1     | GELU        | 0     
123 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.2     | Dropout     | 0     
124 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.3     | Linear      | 393 K 
125 | _ViT_Trainer__model.transformer.layers.6.1.fn.net.4     | Dropout     | 0     
126 | _ViT_Trainer__model.transformer.layers.7                | ModuleList  | 3 M   
127 | _ViT_Trainer__model.transformer.layers.7.0              | PreNorm     | 3 M   
128 | _ViT_Trainer__model.transformer.layers.7.0.norm         | LayerNorm   | 1 K   
129 | _ViT_Trainer__model.transformer.layers.7.0.fn           | Attention   | 3 M   
130 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_qkv    | Linear      | 2 M   
131 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_out    | Sequential  | 787 K 
132 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_out.0  | Linear      | 787 K 
133 | _ViT_Trainer__model.transformer.layers.7.0.fn.to_out.1  | Dropout     | 0     
134 | _ViT_Trainer__model.transformer.layers.7.1              | PreNorm     | 789 K 
135 | _ViT_Trainer__model.transformer.layers.7.1.norm         | LayerNorm   | 1 K   
136 | _ViT_Trainer__model.transformer.layers.7.1.fn           | FeedForward | 787 K 
137 | _ViT_Trainer__model.transformer.layers.7.1.fn.net       | Sequential  | 787 K 
138 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.0     | Linear      | 393 K 
139 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.1     | GELU        | 0     
140 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.2     | Dropout     | 0     
141 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.3     | Linear      | 393 K 
142 | _ViT_Trainer__model.transformer.layers.7.1.fn.net.4     | Dropout     | 0     
143 | _ViT_Trainer__model.transformer.layers.8                | ModuleList  | 3 M   
144 | _ViT_Trainer__model.transformer.layers.8.0              | PreNorm     | 3 M   
145 | _ViT_Trainer__model.transformer.layers.8.0.norm         | LayerNorm   | 1 K   
146 | _ViT_Trainer__model.transformer.layers.8.0.fn           | Attention   | 3 M   
147 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_qkv    | Linear      | 2 M   
148 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_out    | Sequential  | 787 K 
149 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_out.0  | Linear      | 787 K 
150 | _ViT_Trainer__model.transformer.layers.8.0.fn.to_out.1  | Dropout     | 0     
151 | _ViT_Trainer__model.transformer.layers.8.1              | PreNorm     | 789 K 
152 | _ViT_Trainer__model.transformer.layers.8.1.norm         | LayerNorm   | 1 K   
153 | _ViT_Trainer__model.transformer.layers.8.1.fn           | FeedForward | 787 K 
154 | _ViT_Trainer__model.transformer.layers.8.1.fn.net       | Sequential  | 787 K 
155 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.0     | Linear      | 393 K 
156 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.1     | GELU        | 0     
157 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.2     | Dropout     | 0     
158 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.3     | Linear      | 393 K 
159 | _ViT_Trainer__model.transformer.layers.8.1.fn.net.4     | Dropout     | 0     
160 | _ViT_Trainer__model.transformer.layers.9                | ModuleList  | 3 M   
161 | _ViT_Trainer__model.transformer.layers.9.0              | PreNorm     | 3 M   
162 | _ViT_Trainer__model.transformer.layers.9.0.norm         | LayerNorm   | 1 K   
163 | _ViT_Trainer__model.transformer.layers.9.0.fn           | Attention   | 3 M   
164 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_qkv    | Linear      | 2 M   
165 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_out    | Sequential  | 787 K 
166 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_out.0  | Linear      | 787 K 
167 | _ViT_Trainer__model.transformer.layers.9.0.fn.to_out.1  | Dropout     | 0     
168 | _ViT_Trainer__model.transformer.layers.9.1              | PreNorm     | 789 K 
169 | _ViT_Trainer__model.transformer.layers.9.1.norm         | LayerNorm   | 1 K   
170 | _ViT_Trainer__model.transformer.layers.9.1.fn           | FeedForward | 787 K 
171 | _ViT_Trainer__model.transformer.layers.9.1.fn.net       | Sequential  | 787 K 
172 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.0     | Linear      | 393 K 
173 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.1     | GELU        | 0     
174 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.2     | Dropout     | 0     
175 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.3     | Linear      | 393 K 
176 | _ViT_Trainer__model.transformer.layers.9.1.fn.net.4     | Dropout     | 0     
177 | _ViT_Trainer__model.transformer.layers.10               | ModuleList  | 3 M   
178 | _ViT_Trainer__model.transformer.layers.10.0             | PreNorm     | 3 M   
179 | _ViT_Trainer__model.transformer.layers.10.0.norm        | LayerNorm   | 1 K   
180 | _ViT_Trainer__model.transformer.layers.10.0.fn          | Attention   | 3 M   
181 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_qkv   | Linear      | 2 M   
182 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_out   | Sequential  | 787 K 
183 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_out.0 | Linear      | 787 K 
184 | _ViT_Trainer__model.transformer.layers.10.0.fn.to_out.1 | Dropout     | 0     
185 | _ViT_Trainer__model.transformer.layers.10.1             | PreNorm     | 789 K 
186 | _ViT_Trainer__model.transformer.layers.10.1.norm        | LayerNorm   | 1 K   
187 | _ViT_Trainer__model.transformer.layers.10.1.fn          | FeedForward | 787 K 
188 | _ViT_Trainer__model.transformer.layers.10.1.fn.net      | Sequential  | 787 K 
189 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.0    | Linear      | 393 K 
190 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.1    | GELU        | 0     
191 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.2    | Dropout     | 0     
192 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.3    | Linear      | 393 K 
193 | _ViT_Trainer__model.transformer.layers.10.1.fn.net.4    | Dropout     | 0     
194 | _ViT_Trainer__model.transformer.layers.11               | ModuleList  | 3 M   
195 | _ViT_Trainer__model.transformer.layers.11.0             | PreNorm     | 3 M   
196 | _ViT_Trainer__model.transformer.layers.11.0.norm        | LayerNorm   | 1 K   
197 | _ViT_Trainer__model.transformer.layers.11.0.fn          | Attention   | 3 M   
198 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_qkv   | Linear      | 2 M   
199 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_out   | Sequential  | 787 K 
200 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_out.0 | Linear      | 787 K 
201 | _ViT_Trainer__model.transformer.layers.11.0.fn.to_out.1 | Dropout     | 0     
202 | _ViT_Trainer__model.transformer.layers.11.1             | PreNorm     | 789 K 
203 | _ViT_Trainer__model.transformer.layers.11.1.norm        | LayerNorm   | 1 K   
204 | _ViT_Trainer__model.transformer.layers.11.1.fn          | FeedForward | 787 K 
205 | _ViT_Trainer__model.transformer.layers.11.1.fn.net      | Sequential  | 787 K 
206 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.0    | Linear      | 393 K 
207 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.1    | GELU        | 0     
208 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.2    | Dropout     | 0     
209 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.3    | Linear      | 393 K 
210 | _ViT_Trainer__model.transformer.layers.11.1.fn.net.4    | Dropout     | 0     
211 | _ViT_Trainer__model.transformer.layers.12               | ModuleList  | 3 M   
212 | _ViT_Trainer__model.transformer.layers.12.0             | PreNorm     | 3 M   
213 | _ViT_Trainer__model.transformer.layers.12.0.norm        | LayerNorm   | 1 K   
214 | _ViT_Trainer__model.transformer.layers.12.0.fn          | Attention   | 3 M   
215 | _ViT_Trainer__model.transformer.layers.12.0.fn.to_qkv   | Linear      | 2 M   
216 | _ViT_Trainer__model.transformer.layers.12.0.fn.to_out   | Sequential  | 787 K 
217 | _ViT_Trainer__model.transformer.layers.12.0.fn.to_out.0 | Linear      | 787 K 
218 | _ViT_Trainer__model.transformer.layers.12.0.fn.to_out.1 | Dropout     | 0     
219 | _ViT_Trainer__model.transformer.layers.12.1             | PreNorm     | 789 K 
220 | _ViT_Trainer__model.transformer.layers.12.1.norm        | LayerNorm   | 1 K   
221 | _ViT_Trainer__model.transformer.layers.12.1.fn          | FeedForward | 787 K 
222 | _ViT_Trainer__model.transformer.layers.12.1.fn.net      | Sequential  | 787 K 
223 | _ViT_Trainer__model.transformer.layers.12.1.fn.net.0    | Linear      | 393 K 
224 | _ViT_Trainer__model.transformer.layers.12.1.fn.net.1    | GELU        | 0     
225 | _ViT_Trainer__model.transformer.layers.12.1.fn.net.2    | Dropout     | 0     
226 | _ViT_Trainer__model.transformer.layers.12.1.fn.net.3    | Linear      | 393 K 
227 | _ViT_Trainer__model.transformer.layers.12.1.fn.net.4    | Dropout     | 0     
228 | _ViT_Trainer__model.transformer.layers.13               | ModuleList  | 3 M   
229 | _ViT_Trainer__model.transformer.layers.13.0             | PreNorm     | 3 M   
230 | _ViT_Trainer__model.transformer.layers.13.0.norm        | LayerNorm   | 1 K   
231 | _ViT_Trainer__model.transformer.layers.13.0.fn          | Attention   | 3 M   
232 | _ViT_Trainer__model.transformer.layers.13.0.fn.to_qkv   | Linear      | 2 M   
233 | _ViT_Trainer__model.transformer.layers.13.0.fn.to_out   | Sequential  | 787 K 
234 | _ViT_Trainer__model.transformer.layers.13.0.fn.to_out.0 | Linear      | 787 K 
235 | _ViT_Trainer__model.transformer.layers.13.0.fn.to_out.1 | Dropout     | 0     
236 | _ViT_Trainer__model.transformer.layers.13.1             | PreNorm     | 789 K 
237 | _ViT_Trainer__model.transformer.layers.13.1.norm        | LayerNorm   | 1 K   
238 | _ViT_Trainer__model.transformer.layers.13.1.fn          | FeedForward | 787 K 
239 | _ViT_Trainer__model.transformer.layers.13.1.fn.net      | Sequential  | 787 K 
240 | _ViT_Trainer__model.transformer.layers.13.1.fn.net.0    | Linear      | 393 K 
241 | _ViT_Trainer__model.transformer.layers.13.1.fn.net.1    | GELU        | 0     
242 | _ViT_Trainer__model.transformer.layers.13.1.fn.net.2    | Dropout     | 0     
243 | _ViT_Trainer__model.transformer.layers.13.1.fn.net.3    | Linear      | 393 K 
244 | _ViT_Trainer__model.transformer.layers.13.1.fn.net.4    | Dropout     | 0     
245 | _ViT_Trainer__model.transformer.layers.14               | ModuleList  | 3 M   
246 | _ViT_Trainer__model.transformer.layers.14.0             | PreNorm     | 3 M   
247 | _ViT_Trainer__model.transformer.layers.14.0.norm        | LayerNorm   | 1 K   
248 | _ViT_Trainer__model.transformer.layers.14.0.fn          | Attention   | 3 M   
249 | _ViT_Trainer__model.transformer.layers.14.0.fn.to_qkv   | Linear      | 2 M   
250 | _ViT_Trainer__model.transformer.layers.14.0.fn.to_out   | Sequential  | 787 K 
251 | _ViT_Trainer__model.transformer.layers.14.0.fn.to_out.0 | Linear      | 787 K 
252 | _ViT_Trainer__model.transformer.layers.14.0.fn.to_out.1 | Dropout     | 0     
253 | _ViT_Trainer__model.transformer.layers.14.1             | PreNorm     | 789 K 
254 | _ViT_Trainer__model.transformer.layers.14.1.norm        | LayerNorm   | 1 K   
255 | _ViT_Trainer__model.transformer.layers.14.1.fn          | FeedForward | 787 K 
256 | _ViT_Trainer__model.transformer.layers.14.1.fn.net      | Sequential  | 787 K 
257 | _ViT_Trainer__model.transformer.layers.14.1.fn.net.0    | Linear      | 393 K 
258 | _ViT_Trainer__model.transformer.layers.14.1.fn.net.1    | GELU        | 0     
259 | _ViT_Trainer__model.transformer.layers.14.1.fn.net.2    | Dropout     | 0     
260 | _ViT_Trainer__model.transformer.layers.14.1.fn.net.3    | Linear      | 393 K 
261 | _ViT_Trainer__model.transformer.layers.14.1.fn.net.4    | Dropout     | 0     
262 | _ViT_Trainer__model.transformer.layers.15               | ModuleList  | 3 M   
263 | _ViT_Trainer__model.transformer.layers.15.0             | PreNorm     | 3 M   
264 | _ViT_Trainer__model.transformer.layers.15.0.norm        | LayerNorm   | 1 K   
265 | _ViT_Trainer__model.transformer.layers.15.0.fn          | Attention   | 3 M   
266 | _ViT_Trainer__model.transformer.layers.15.0.fn.to_qkv   | Linear      | 2 M   
267 | _ViT_Trainer__model.transformer.layers.15.0.fn.to_out   | Sequential  | 787 K 
268 | _ViT_Trainer__model.transformer.layers.15.0.fn.to_out.0 | Linear      | 787 K 
269 | _ViT_Trainer__model.transformer.layers.15.0.fn.to_out.1 | Dropout     | 0     
270 | _ViT_Trainer__model.transformer.layers.15.1             | PreNorm     | 789 K 
271 | _ViT_Trainer__model.transformer.layers.15.1.norm        | LayerNorm   | 1 K   
272 | _ViT_Trainer__model.transformer.layers.15.1.fn          | FeedForward | 787 K 
273 | _ViT_Trainer__model.transformer.layers.15.1.fn.net      | Sequential  | 787 K 
274 | _ViT_Trainer__model.transformer.layers.15.1.fn.net.0    | Linear      | 393 K 
275 | _ViT_Trainer__model.transformer.layers.15.1.fn.net.1    | GELU        | 0     
276 | _ViT_Trainer__model.transformer.layers.15.1.fn.net.2    | Dropout     | 0     
277 | _ViT_Trainer__model.transformer.layers.15.1.fn.net.3    | Linear      | 393 K 
278 | _ViT_Trainer__model.transformer.layers.15.1.fn.net.4    | Dropout     | 0     
279 | _ViT_Trainer__model.transformer.layers.16               | ModuleList  | 3 M   
280 | _ViT_Trainer__model.transformer.layers.16.0             | PreNorm     | 3 M   
281 | _ViT_Trainer__model.transformer.layers.16.0.norm        | LayerNorm   | 1 K   
282 | _ViT_Trainer__model.transformer.layers.16.0.fn          | Attention   | 3 M   
283 | _ViT_Trainer__model.transformer.layers.16.0.fn.to_qkv   | Linear      | 2 M   
284 | _ViT_Trainer__model.transformer.layers.16.0.fn.to_out   | Sequential  | 787 K 
285 | _ViT_Trainer__model.transformer.layers.16.0.fn.to_out.0 | Linear      | 787 K 
286 | _ViT_Trainer__model.transformer.layers.16.0.fn.to_out.1 | Dropout     | 0     
287 | _ViT_Trainer__model.transformer.layers.16.1             | PreNorm     | 789 K 
288 | _ViT_Trainer__model.transformer.layers.16.1.norm        | LayerNorm   | 1 K   
289 | _ViT_Trainer__model.transformer.layers.16.1.fn          | FeedForward | 787 K 
290 | _ViT_Trainer__model.transformer.layers.16.1.fn.net      | Sequential  | 787 K 
291 | _ViT_Trainer__model.transformer.layers.16.1.fn.net.0    | Linear      | 393 K 
292 | _ViT_Trainer__model.transformer.layers.16.1.fn.net.1    | GELU        | 0     
293 | _ViT_Trainer__model.transformer.layers.16.1.fn.net.2    | Dropout     | 0     
294 | _ViT_Trainer__model.transformer.layers.16.1.fn.net.3    | Linear      | 393 K 
295 | _ViT_Trainer__model.transformer.layers.16.1.fn.net.4    | Dropout     | 0     
296 | _ViT_Trainer__model.transformer.layers.17               | ModuleList  | 3 M   
297 | _ViT_Trainer__model.transformer.layers.17.0             | PreNorm     | 3 M   
298 | _ViT_Trainer__model.transformer.layers.17.0.norm        | LayerNorm   | 1 K   
299 | _ViT_Trainer__model.transformer.layers.17.0.fn          | Attention   | 3 M   
300 | _ViT_Trainer__model.transformer.layers.17.0.fn.to_qkv   | Linear      | 2 M   
301 | _ViT_Trainer__model.transformer.layers.17.0.fn.to_out   | Sequential  | 787 K 
302 | _ViT_Trainer__model.transformer.layers.17.0.fn.to_out.0 | Linear      | 787 K 
303 | _ViT_Trainer__model.transformer.layers.17.0.fn.to_out.1 | Dropout     | 0     
304 | _ViT_Trainer__model.transformer.layers.17.1             | PreNorm     | 789 K 
305 | _ViT_Trainer__model.transformer.layers.17.1.norm        | LayerNorm   | 1 K   
306 | _ViT_Trainer__model.transformer.layers.17.1.fn          | FeedForward | 787 K 
307 | _ViT_Trainer__model.transformer.layers.17.1.fn.net      | Sequential  | 787 K 
308 | _ViT_Trainer__model.transformer.layers.17.1.fn.net.0    | Linear      | 393 K 
309 | _ViT_Trainer__model.transformer.layers.17.1.fn.net.1    | GELU        | 0     
310 | _ViT_Trainer__model.transformer.layers.17.1.fn.net.2    | Dropout     | 0     
311 | _ViT_Trainer__model.transformer.layers.17.1.fn.net.3    | Linear      | 393 K 
312 | _ViT_Trainer__model.transformer.layers.17.1.fn.net.4    | Dropout     | 0     
313 | _ViT_Trainer__model.transformer.layers.18               | ModuleList  | 3 M   
314 | _ViT_Trainer__model.transformer.layers.18.0             | PreNorm     | 3 M   
315 | _ViT_Trainer__model.transformer.layers.18.0.norm        | LayerNorm   | 1 K   
316 | _ViT_Trainer__model.transformer.layers.18.0.fn          | Attention   | 3 M   
317 | _ViT_Trainer__model.transformer.layers.18.0.fn.to_qkv   | Linear      | 2 M   
318 | _ViT_Trainer__model.transformer.layers.18.0.fn.to_out   | Sequential  | 787 K 
319 | _ViT_Trainer__model.transformer.layers.18.0.fn.to_out.0 | Linear      | 787 K 
320 | _ViT_Trainer__model.transformer.layers.18.0.fn.to_out.1 | Dropout     | 0     
321 | _ViT_Trainer__model.transformer.layers.18.1             | PreNorm     | 789 K 
322 | _ViT_Trainer__model.transformer.layers.18.1.norm        | LayerNorm   | 1 K   
323 | _ViT_Trainer__model.transformer.layers.18.1.fn          | FeedForward | 787 K 
324 | _ViT_Trainer__model.transformer.layers.18.1.fn.net      | Sequential  | 787 K 
325 | _ViT_Trainer__model.transformer.layers.18.1.fn.net.0    | Linear      | 393 K 
326 | _ViT_Trainer__model.transformer.layers.18.1.fn.net.1    | GELU        | 0     
327 | _ViT_Trainer__model.transformer.layers.18.1.fn.net.2    | Dropout     | 0     
328 | _ViT_Trainer__model.transformer.layers.18.1.fn.net.3    | Linear      | 393 K 
329 | _ViT_Trainer__model.transformer.layers.18.1.fn.net.4    | Dropout     | 0     
330 | _ViT_Trainer__model.transformer.layers.19               | ModuleList  | 3 M   
331 | _ViT_Trainer__model.transformer.layers.19.0             | PreNorm     | 3 M   
332 | _ViT_Trainer__model.transformer.layers.19.0.norm        | LayerNorm   | 1 K   
333 | _ViT_Trainer__model.transformer.layers.19.0.fn          | Attention   | 3 M   
334 | _ViT_Trainer__model.transformer.layers.19.0.fn.to_qkv   | Linear      | 2 M   
335 | _ViT_Trainer__model.transformer.layers.19.0.fn.to_out   | Sequential  | 787 K 
336 | _ViT_Trainer__model.transformer.layers.19.0.fn.to_out.0 | Linear      | 787 K 
337 | _ViT_Trainer__model.transformer.layers.19.0.fn.to_out.1 | Dropout     | 0     
338 | _ViT_Trainer__model.transformer.layers.19.1             | PreNorm     | 789 K 
339 | _ViT_Trainer__model.transformer.layers.19.1.norm        | LayerNorm   | 1 K   
340 | _ViT_Trainer__model.transformer.layers.19.1.fn          | FeedForward | 787 K 
341 | _ViT_Trainer__model.transformer.layers.19.1.fn.net      | Sequential  | 787 K 
342 | _ViT_Trainer__model.transformer.layers.19.1.fn.net.0    | Linear      | 393 K 
343 | _ViT_Trainer__model.transformer.layers.19.1.fn.net.1    | GELU        | 0     
344 | _ViT_Trainer__model.transformer.layers.19.1.fn.net.2    | Dropout     | 0     
345 | _ViT_Trainer__model.transformer.layers.19.1.fn.net.3    | Linear      | 393 K 
346 | _ViT_Trainer__model.transformer.layers.19.1.fn.net.4    | Dropout     | 0     
347 | _ViT_Trainer__model.transformer.layers.20               | ModuleList  | 3 M   
348 | _ViT_Trainer__model.transformer.layers.20.0             | PreNorm     | 3 M   
349 | _ViT_Trainer__model.transformer.layers.20.0.norm        | LayerNorm   | 1 K   
350 | _ViT_Trainer__model.transformer.layers.20.0.fn          | Attention   | 3 M   
351 | _ViT_Trainer__model.transformer.layers.20.0.fn.to_qkv   | Linear      | 2 M   
352 | _ViT_Trainer__model.transformer.layers.20.0.fn.to_out   | Sequential  | 787 K 
353 | _ViT_Trainer__model.transformer.layers.20.0.fn.to_out.0 | Linear      | 787 K 
354 | _ViT_Trainer__model.transformer.layers.20.0.fn.to_out.1 | Dropout     | 0     
355 | _ViT_Trainer__model.transformer.layers.20.1             | PreNorm     | 789 K 
356 | _ViT_Trainer__model.transformer.layers.20.1.norm        | LayerNorm   | 1 K   
357 | _ViT_Trainer__model.transformer.layers.20.1.fn          | FeedForward | 787 K 
358 | _ViT_Trainer__model.transformer.layers.20.1.fn.net      | Sequential  | 787 K 
359 | _ViT_Trainer__model.transformer.layers.20.1.fn.net.0    | Linear      | 393 K 
360 | _ViT_Trainer__model.transformer.layers.20.1.fn.net.1    | GELU        | 0     
361 | _ViT_Trainer__model.transformer.layers.20.1.fn.net.2    | Dropout     | 0     
362 | _ViT_Trainer__model.transformer.layers.20.1.fn.net.3    | Linear      | 393 K 
363 | _ViT_Trainer__model.transformer.layers.20.1.fn.net.4    | Dropout     | 0     
364 | _ViT_Trainer__model.transformer.layers.21               | ModuleList  | 3 M   
365 | _ViT_Trainer__model.transformer.layers.21.0             | PreNorm     | 3 M   
366 | _ViT_Trainer__model.transformer.layers.21.0.norm        | LayerNorm   | 1 K   
367 | _ViT_Trainer__model.transformer.layers.21.0.fn          | Attention   | 3 M   
368 | _ViT_Trainer__model.transformer.layers.21.0.fn.to_qkv   | Linear      | 2 M   
369 | _ViT_Trainer__model.transformer.layers.21.0.fn.to_out   | Sequential  | 787 K 
370 | _ViT_Trainer__model.transformer.layers.21.0.fn.to_out.0 | Linear      | 787 K 
371 | _ViT_Trainer__model.transformer.layers.21.0.fn.to_out.1 | Dropout     | 0     
372 | _ViT_Trainer__model.transformer.layers.21.1             | PreNorm     | 789 K 
373 | _ViT_Trainer__model.transformer.layers.21.1.norm        | LayerNorm   | 1 K   
374 | _ViT_Trainer__model.transformer.layers.21.1.fn          | FeedForward | 787 K 
375 | _ViT_Trainer__model.transformer.layers.21.1.fn.net      | Sequential  | 787 K 
376 | _ViT_Trainer__model.transformer.layers.21.1.fn.net.0    | Linear      | 393 K 
377 | _ViT_Trainer__model.transformer.layers.21.1.fn.net.1    | GELU        | 0     
378 | _ViT_Trainer__model.transformer.layers.21.1.fn.net.2    | Dropout     | 0     
379 | _ViT_Trainer__model.transformer.layers.21.1.fn.net.3    | Linear      | 393 K 
380 | _ViT_Trainer__model.transformer.layers.21.1.fn.net.4    | Dropout     | 0     
381 | _ViT_Trainer__model.transformer.layers.22               | ModuleList  | 3 M   
382 | _ViT_Trainer__model.transformer.layers.22.0             | PreNorm     | 3 M   
383 | _ViT_Trainer__model.transformer.layers.22.0.norm        | LayerNorm   | 1 K   
384 | _ViT_Trainer__model.transformer.layers.22.0.fn          | Attention   | 3 M   
385 | _ViT_Trainer__model.transformer.layers.22.0.fn.to_qkv   | Linear      | 2 M   
386 | _ViT_Trainer__model.transformer.layers.22.0.fn.to_out   | Sequential  | 787 K 
387 | _ViT_Trainer__model.transformer.layers.22.0.fn.to_out.0 | Linear      | 787 K 
388 | _ViT_Trainer__model.transformer.layers.22.0.fn.to_out.1 | Dropout     | 0     
389 | _ViT_Trainer__model.transformer.layers.22.1             | PreNorm     | 789 K 
390 | _ViT_Trainer__model.transformer.layers.22.1.norm        | LayerNorm   | 1 K   
391 | _ViT_Trainer__model.transformer.layers.22.1.fn          | FeedForward | 787 K 
392 | _ViT_Trainer__model.transformer.layers.22.1.fn.net      | Sequential  | 787 K 
393 | _ViT_Trainer__model.transformer.layers.22.1.fn.net.0    | Linear      | 393 K 
394 | _ViT_Trainer__model.transformer.layers.22.1.fn.net.1    | GELU        | 0     
395 | _ViT_Trainer__model.transformer.layers.22.1.fn.net.2    | Dropout     | 0     
396 | _ViT_Trainer__model.transformer.layers.22.1.fn.net.3    | Linear      | 393 K 
397 | _ViT_Trainer__model.transformer.layers.22.1.fn.net.4    | Dropout     | 0     
398 | _ViT_Trainer__model.transformer.layers.23               | ModuleList  | 3 M   
399 | _ViT_Trainer__model.transformer.layers.23.0             | PreNorm     | 3 M   
400 | _ViT_Trainer__model.transformer.layers.23.0.norm        | LayerNorm   | 1 K   
401 | _ViT_Trainer__model.transformer.layers.23.0.fn          | Attention   | 3 M   
402 | _ViT_Trainer__model.transformer.layers.23.0.fn.to_qkv   | Linear      | 2 M   
403 | _ViT_Trainer__model.transformer.layers.23.0.fn.to_out   | Sequential  | 787 K 
404 | _ViT_Trainer__model.transformer.layers.23.0.fn.to_out.0 | Linear      | 787 K 
405 | _ViT_Trainer__model.transformer.layers.23.0.fn.to_out.1 | Dropout     | 0     
406 | _ViT_Trainer__model.transformer.layers.23.1             | PreNorm     | 789 K 
407 | _ViT_Trainer__model.transformer.layers.23.1.norm        | LayerNorm   | 1 K   
408 | _ViT_Trainer__model.transformer.layers.23.1.fn          | FeedForward | 787 K 
409 | _ViT_Trainer__model.transformer.layers.23.1.fn.net      | Sequential  | 787 K 
410 | _ViT_Trainer__model.transformer.layers.23.1.fn.net.0    | Linear      | 393 K 
411 | _ViT_Trainer__model.transformer.layers.23.1.fn.net.1    | GELU        | 0     
412 | _ViT_Trainer__model.transformer.layers.23.1.fn.net.2    | Dropout     | 0     
413 | _ViT_Trainer__model.transformer.layers.23.1.fn.net.3    | Linear      | 393 K 
414 | _ViT_Trainer__model.transformer.layers.23.1.fn.net.4    | Dropout     | 0     
415 | _ViT_Trainer__model.to_latent                           | Identity    | 0     
416 | _ViT_Trainer__model.mlp_head                            | Sequential  | 9 K   
417 | _ViT_Trainer__model.mlp_head.0                          | LayerNorm   | 1 K   
418 | _ViT_Trainer__model.mlp_head.1                          | Linear      | 7 K   
Files already downloaded and verified
Files already downloaded and verified
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:  20%|██        | 1/5 [00:04<00:19,  4.80s/it]Validation sanity check:  40%|████      | 2/5 [00:05<00:06,  2.22s/it]Validation sanity check:  60%|██████    | 3/5 [00:05<00:02,  1.39s/it]Validation sanity check:  80%|████████  | 4/5 [00:06<00:00,  1.01it/s]Validation sanity check: 100%|██████████| 5/5 [00:06<00:00,  1.28it/s]                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/196 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/196 [00:00<?, ?it/s] /scratch/nsk367/anaconda3/envs/vit/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 1:   1%|          | 1/196 [00:02<06:42,  2.07s/it]Epoch 1:   1%|          | 1/196 [00:02<06:42,  2.07s/it, loss=2.365, v_num=6633854]Epoch 1:   1%|          | 2/196 [00:03<05:12,  1.61s/it, loss=2.365, v_num=6633854]Epoch 1:   1%|          | 2/196 [00:03<05:12,  1.61s/it, loss=3.985, v_num=6633854]Epoch 1:   2%|▏         | 3/196 [00:04<04:42,  1.46s/it, loss=3.985, v_num=6633854]Epoch 1:   2%|▏         | 3/196 [00:04<04:42,  1.46s/it, loss=3.978, v_num=6633854]Epoch 1:   2%|▏         | 4/196 [00:05<04:26,  1.39s/it, loss=3.978, v_num=6633854]Epoch 1:   2%|▏         | 4/196 [00:05<04:26,  1.39s/it, loss=3.931, v_num=6633854]Epoch 1:   3%|▎         | 5/196 [00:06<04:16,  1.34s/it, loss=3.931, v_num=6633854]Epoch 1:   3%|▎         | 5/196 [00:06<04:16,  1.34s/it, loss=3.789, v_num=6633854]Epoch 1:   3%|▎         | 6/196 [00:07<04:09,  1.31s/it, loss=3.789, v_num=6633854]Epoch 1:   3%|▎         | 6/196 [00:07<04:09,  1.31s/it, loss=3.639, v_num=6633854]Epoch 1:   4%|▎         | 7/196 [00:09<04:04,  1.29s/it, loss=3.639, v_num=6633854]Epoch 1:   4%|▎         | 7/196 [00:09<04:04,  1.29s/it, loss=3.501, v_num=6633854]Epoch 1:   4%|▍         | 8/196 [00:10<03:59,  1.28s/it, loss=3.501, v_num=6633854]Epoch 1:   4%|▍         | 8/196 [00:10<03:59,  1.28s/it, loss=3.370, v_num=6633854]Epoch 1:   5%|▍         | 9/196 [00:11<03:55,  1.26s/it, loss=3.370, v_num=6633854]Epoch 1:   5%|▍         | 9/196 [00:11<03:56,  1.26s/it, loss=3.287, v_num=6633854]Epoch 1:   5%|▌         | 10/196 [00:12<03:53,  1.25s/it, loss=3.287, v_num=6633854]Epoch 1:   5%|▌         | 10/196 [00:12<03:53,  1.25s/it, loss=3.228, v_num=6633854]Epoch 1:   6%|▌         | 11/196 [00:13<03:50,  1.25s/it, loss=3.228, v_num=6633854]Epoch 1:   6%|▌         | 11/196 [00:13<03:50,  1.25s/it, loss=3.160, v_num=6633854]Epoch 1:   6%|▌         | 12/196 [00:14<03:47,  1.24s/it, loss=3.160, v_num=6633854]Epoch 1:   6%|▌         | 12/196 [00:14<03:47,  1.24s/it, loss=3.096, v_num=6633854]Epoch 1:   7%|▋         | 13/196 [00:16<03:45,  1.23s/it, loss=3.096, v_num=6633854]Epoch 1:   7%|▋         | 13/196 [00:16<03:45,  1.23s/it, loss=3.040, v_num=6633854]Epoch 1:   7%|▋         | 14/196 [00:17<03:43,  1.23s/it, loss=3.040, v_num=6633854]Epoch 1:   7%|▋         | 14/196 [00:17<03:43,  1.23s/it, loss=2.989, v_num=6633854]Epoch 1:   8%|▊         | 15/196 [00:18<03:41,  1.22s/it, loss=2.989, v_num=6633854]Epoch 1:   8%|▊         | 15/196 [00:18<03:41,  1.22s/it, loss=2.947, v_num=6633854]Epoch 1:   8%|▊         | 16/196 [00:19<03:39,  1.22s/it, loss=2.947, v_num=6633854]Epoch 1:   8%|▊         | 16/196 [00:19<03:39,  1.22s/it, loss=2.912, v_num=6633854]Epoch 1:   9%|▊         | 17/196 [00:20<03:37,  1.22s/it, loss=2.912, v_num=6633854]Epoch 1:   9%|▊         | 17/196 [00:20<03:37,  1.22s/it, loss=2.883, v_num=6633854]Epoch 1:   9%|▉         | 18/196 [00:21<03:36,  1.22s/it, loss=2.883, v_num=6633854]Epoch 1:   9%|▉         | 18/196 [00:21<03:36,  1.22s/it, loss=2.854, v_num=6633854]Epoch 1:  10%|▉         | 19/196 [00:23<03:34,  1.21s/it, loss=2.854, v_num=6633854]Epoch 1:  10%|▉         | 19/196 [00:23<03:34,  1.21s/it, loss=2.829, v_num=6633854]Epoch 1:  10%|█         | 20/196 [00:24<03:32,  1.21s/it, loss=2.829, v_num=6633854]Epoch 1:  10%|█         | 20/196 [00:24<03:32,  1.21s/it, loss=2.809, v_num=6633854]Epoch 1:  11%|█         | 21/196 [00:25<03:31,  1.21s/it, loss=2.809, v_num=6633854]Epoch 1:  11%|█         | 21/196 [00:25<03:31,  1.21s/it, loss=2.809, v_num=6633854]Epoch 1:  11%|█         | 22/196 [00:26<03:29,  1.21s/it, loss=2.809, v_num=6633854]Epoch 1:  11%|█         | 22/196 [00:26<03:29,  1.21s/it, loss=2.645, v_num=6633854]Epoch 1:  12%|█▏        | 23/196 [00:27<03:28,  1.20s/it, loss=2.645, v_num=6633854]Epoch 1:  12%|█▏        | 23/196 [00:27<03:28,  1.20s/it, loss=2.563, v_num=6633854]Epoch 1:  12%|█▏        | 24/196 [00:28<03:26,  1.20s/it, loss=2.563, v_num=6633854]Epoch 1:  12%|█▏        | 24/196 [00:28<03:26,  1.20s/it, loss=2.488, v_num=6633854]Epoch 1:  13%|█▎        | 25/196 [00:30<03:25,  1.20s/it, loss=2.488, v_num=6633854]Epoch 1:  13%|█▎        | 25/196 [00:30<03:25,  1.20s/it, loss=2.442, v_num=6633854]Epoch 1:  13%|█▎        | 26/196 [00:31<03:24,  1.20s/it, loss=2.442, v_num=6633854]Epoch 1:  13%|█▎        | 26/196 [00:31<03:24,  1.20s/it, loss=2.412, v_num=6633854]Epoch 1:  14%|█▍        | 27/196 [00:32<03:22,  1.20s/it, loss=2.412, v_num=6633854]Epoch 1:  14%|█▍        | 27/196 [00:32<03:22,  1.20s/it, loss=2.393, v_num=6633854]Epoch 1:  14%|█▍        | 28/196 [00:33<03:21,  1.20s/it, loss=2.393, v_num=6633854]Epoch 1:  14%|█▍        | 28/196 [00:33<03:21,  1.20s/it, loss=2.386, v_num=6633854]Epoch 1:  15%|█▍        | 29/196 [00:34<03:20,  1.20s/it, loss=2.386, v_num=6633854]Epoch 1:  15%|█▍        | 29/196 [00:34<03:20,  1.20s/it, loss=2.368, v_num=6633854]Epoch 1:  15%|█▌        | 30/196 [00:35<03:18,  1.20s/it, loss=2.368, v_num=6633854]Epoch 1:  15%|█▌        | 30/196 [00:35<03:18,  1.20s/it, loss=2.347, v_num=6633854]Epoch 1:  16%|█▌        | 31/196 [00:37<03:17,  1.20s/it, loss=2.347, v_num=6633854]Epoch 1:  16%|█▌        | 31/196 [00:37<03:17,  1.20s/it, loss=2.338, v_num=6633854]Epoch 1:  16%|█▋        | 32/196 [00:38<03:16,  1.20s/it, loss=2.338, v_num=6633854]Epoch 1:  16%|█▋        | 32/196 [00:38<03:16,  1.20s/it, loss=2.334, v_num=6633854]Epoch 1:  17%|█▋        | 33/196 [00:39<03:15,  1.20s/it, loss=2.334, v_num=6633854]Epoch 1:  17%|█▋        | 33/196 [00:39<03:15,  1.20s/it, loss=2.331, v_num=6633854]Epoch 1:  17%|█▋        | 34/196 [00:40<03:13,  1.20s/it, loss=2.331, v_num=6633854]Epoch 1:  17%|█▋        | 34/196 [00:40<03:13,  1.20s/it, loss=2.328, v_num=6633854]Epoch 1:  18%|█▊        | 35/196 [00:41<03:12,  1.20s/it, loss=2.328, v_num=6633854]Epoch 1:  18%|█▊        | 35/196 [00:41<03:12,  1.20s/it, loss=2.324, v_num=6633854]Epoch 1:  18%|█▊        | 36/196 [00:43<03:11,  1.20s/it, loss=2.324, v_num=6633854]Epoch 1:  18%|█▊        | 36/196 [00:43<03:11,  1.20s/it, loss=2.317, v_num=6633854]Epoch 1:  19%|█▉        | 37/196 [00:44<03:10,  1.20s/it, loss=2.317, v_num=6633854]Epoch 1:  19%|█▉        | 37/196 [00:44<03:10,  1.20s/it, loss=2.311, v_num=6633854]Epoch 1:  19%|█▉        | 38/196 [00:45<03:08,  1.20s/it, loss=2.311, v_num=6633854]Epoch 1:  19%|█▉        | 38/196 [00:45<03:08,  1.20s/it, loss=2.305, v_num=6633854]Epoch 1:  20%|█▉        | 39/196 [00:46<03:07,  1.19s/it, loss=2.305, v_num=6633854]Epoch 1:  20%|█▉        | 39/196 [00:46<03:07,  1.19s/it, loss=2.299, v_num=6633854]Epoch 1:  20%|██        | 40/196 [00:47<03:06,  1.19s/it, loss=2.299, v_num=6633854]Epoch 1:  20%|██        | 40/196 [00:47<03:06,  1.19s/it, loss=2.290, v_num=6633854]Epoch 1:  21%|██        | 41/196 [00:48<03:05,  1.19s/it, loss=2.290, v_num=6633854]Epoch 1:  21%|██        | 41/196 [00:48<03:05,  1.19s/it, loss=2.284, v_num=6633854]Epoch 1:  21%|██▏       | 42/196 [00:50<03:03,  1.19s/it, loss=2.284, v_num=6633854]Epoch 1:  21%|██▏       | 42/196 [00:50<03:03,  1.19s/it, loss=2.281, v_num=6633854]Epoch 1:  22%|██▏       | 43/196 [00:51<03:02,  1.19s/it, loss=2.281, v_num=6633854]Epoch 1:  22%|██▏       | 43/196 [00:51<03:02,  1.19s/it, loss=2.276, v_num=6633854]Epoch 1:  22%|██▏       | 44/196 [00:52<03:01,  1.19s/it, loss=2.276, v_num=6633854]Epoch 1:  22%|██▏       | 44/196 [00:52<03:01,  1.19s/it, loss=2.275, v_num=6633854]Epoch 1:  23%|██▎       | 45/196 [00:53<03:00,  1.19s/it, loss=2.275, v_num=6633854]Epoch 1:  23%|██▎       | 45/196 [00:53<03:00,  1.19s/it, loss=2.270, v_num=6633854]Epoch 1:  23%|██▎       | 46/196 [00:54<02:58,  1.19s/it, loss=2.270, v_num=6633854]Epoch 1:  23%|██▎       | 46/196 [00:54<02:58,  1.19s/it, loss=2.265, v_num=6633854]Epoch 1:  24%|██▍       | 47/196 [00:56<02:57,  1.19s/it, loss=2.265, v_num=6633854]Epoch 1:  24%|██▍       | 47/196 [00:56<02:57,  1.19s/it, loss=2.263, v_num=6633854]Epoch 1:  24%|██▍       | 48/196 [00:57<02:56,  1.19s/it, loss=2.263, v_num=6633854]Epoch 1:  24%|██▍       | 48/196 [00:57<02:56,  1.19s/it, loss=2.257, v_num=6633854]Epoch 1:  25%|██▌       | 49/196 [00:58<02:55,  1.19s/it, loss=2.257, v_num=6633854]Epoch 1:  25%|██▌       | 49/196 [00:58<02:55,  1.19s/it, loss=2.251, v_num=6633854]Epoch 1:  26%|██▌       | 50/196 [00:59<02:53,  1.19s/it, loss=2.251, v_num=6633854]Epoch 1:  26%|██▌       | 50/196 [00:59<02:53,  1.19s/it, loss=2.246, v_num=6633854]Epoch 1:  26%|██▌       | 51/196 [01:00<02:52,  1.19s/it, loss=2.246, v_num=6633854]Epoch 1:  26%|██▌       | 51/196 [01:00<02:52,  1.19s/it, loss=2.244, v_num=6633854]Epoch 1:  27%|██▋       | 52/196 [01:01<02:51,  1.19s/it, loss=2.244, v_num=6633854]Epoch 1:  27%|██▋       | 52/196 [01:01<02:51,  1.19s/it, loss=2.238, v_num=6633854]Epoch 1:  27%|██▋       | 53/196 [01:03<02:50,  1.19s/it, loss=2.238, v_num=6633854]Epoch 1:  27%|██▋       | 53/196 [01:03<02:50,  1.19s/it, loss=2.230, v_num=6633854]Epoch 1:  28%|██▊       | 54/196 [01:04<02:49,  1.19s/it, loss=2.230, v_num=6633854]Epoch 1:  28%|██▊       | 54/196 [01:04<02:49,  1.19s/it, loss=2.222, v_num=6633854]Epoch 1:  28%|██▊       | 55/196 [01:05<02:47,  1.19s/it, loss=2.222, v_num=6633854]Epoch 1:  28%|██▊       | 55/196 [01:05<02:47,  1.19s/it, loss=2.220, v_num=6633854]Epoch 1:  29%|██▊       | 56/196 [01:06<02:46,  1.19s/it, loss=2.220, v_num=6633854]Epoch 1:  29%|██▊       | 56/196 [01:06<02:46,  1.19s/it, loss=2.214, v_num=6633854]Epoch 1:  29%|██▉       | 57/196 [01:07<02:45,  1.19s/it, loss=2.214, v_num=6633854]Epoch 1:  29%|██▉       | 57/196 [01:07<02:45,  1.19s/it, loss=2.211, v_num=6633854]Epoch 1:  30%|██▉       | 58/196 [01:09<02:44,  1.19s/it, loss=2.211, v_num=6633854]Epoch 1:  30%|██▉       | 58/196 [01:09<02:44,  1.19s/it, loss=2.210, v_num=6633854]Epoch 1:  30%|███       | 59/196 [01:10<02:43,  1.19s/it, loss=2.210, v_num=6633854]Epoch 1:  30%|███       | 59/196 [01:10<02:43,  1.19s/it, loss=2.206, v_num=6633854]Epoch 1:  31%|███       | 60/196 [01:11<02:41,  1.19s/it, loss=2.206, v_num=6633854]Epoch 1:  31%|███       | 60/196 [01:11<02:41,  1.19s/it, loss=2.198, v_num=6633854]Epoch 1:  31%|███       | 61/196 [01:12<02:40,  1.19s/it, loss=2.198, v_num=6633854]Epoch 1:  31%|███       | 61/196 [01:12<02:40,  1.19s/it, loss=2.196, v_num=6633854]Epoch 1:  32%|███▏      | 62/196 [01:13<02:39,  1.19s/it, loss=2.196, v_num=6633854]Epoch 1:  32%|███▏      | 62/196 [01:13<02:39,  1.19s/it, loss=2.190, v_num=6633854]Epoch 1:  32%|███▏      | 63/196 [01:14<02:38,  1.19s/it, loss=2.190, v_num=6633854]Epoch 1:  32%|███▏      | 63/196 [01:14<02:38,  1.19s/it, loss=2.186, v_num=6633854]Epoch 1:  33%|███▎      | 64/196 [01:16<02:37,  1.19s/it, loss=2.186, v_num=6633854]Epoch 1:  33%|███▎      | 64/196 [01:16<02:37,  1.19s/it, loss=2.179, v_num=6633854]Epoch 1:  33%|███▎      | 65/196 [01:17<02:35,  1.19s/it, loss=2.179, v_num=6633854]Epoch 1:  33%|███▎      | 65/196 [01:17<02:35,  1.19s/it, loss=2.179, v_num=6633854]Epoch 1:  34%|███▎      | 66/196 [01:18<02:34,  1.19s/it, loss=2.179, v_num=6633854]Epoch 1:  34%|███▎      | 66/196 [01:18<02:34,  1.19s/it, loss=2.173, v_num=6633854]Epoch 1:  34%|███▍      | 67/196 [01:19<02:33,  1.19s/it, loss=2.173, v_num=6633854]Epoch 1:  34%|███▍      | 67/196 [01:19<02:33,  1.19s/it, loss=2.170, v_num=6633854]Epoch 1:  35%|███▍      | 68/196 [01:20<02:32,  1.19s/it, loss=2.170, v_num=6633854]Epoch 1:  35%|███▍      | 68/196 [01:20<02:32,  1.19s/it, loss=2.169, v_num=6633854]Epoch 1:  35%|███▌      | 69/196 [01:22<02:31,  1.19s/it, loss=2.169, v_num=6633854]Epoch 1:  35%|███▌      | 69/196 [01:22<02:31,  1.19s/it, loss=2.170, v_num=6633854]Epoch 1:  36%|███▌      | 70/196 [01:23<02:29,  1.19s/it, loss=2.170, v_num=6633854]Epoch 1:  36%|███▌      | 70/196 [01:23<02:29,  1.19s/it, loss=2.164, v_num=6633854]Epoch 1:  36%|███▌      | 71/196 [01:24<02:28,  1.19s/it, loss=2.164, v_num=6633854]Epoch 1:  36%|███▌      | 71/196 [01:24<02:28,  1.19s/it, loss=2.161, v_num=6633854]Epoch 1:  37%|███▋      | 72/196 [01:25<02:27,  1.19s/it, loss=2.161, v_num=6633854]Epoch 1:  37%|███▋      | 72/196 [01:25<02:27,  1.19s/it, loss=2.161, v_num=6633854]Epoch 1:  37%|███▋      | 73/196 [01:26<02:26,  1.19s/it, loss=2.161, v_num=6633854]Epoch 1:  37%|███▋      | 73/196 [01:26<02:26,  1.19s/it, loss=2.163, v_num=6633854]Epoch 1:  38%|███▊      | 74/196 [01:28<02:25,  1.19s/it, loss=2.163, v_num=6633854]Epoch 1:  38%|███▊      | 74/196 [01:28<02:25,  1.19s/it, loss=2.166, v_num=6633854]Epoch 1:  38%|███▊      | 75/196 [01:29<02:24,  1.19s/it, loss=2.166, v_num=6633854]Epoch 1:  38%|███▊      | 75/196 [01:29<02:24,  1.19s/it, loss=2.163, v_num=6633854]Epoch 1:  39%|███▉      | 76/196 [01:30<02:22,  1.19s/it, loss=2.163, v_num=6633854]Epoch 1:  39%|███▉      | 76/196 [01:30<02:22,  1.19s/it, loss=2.162, v_num=6633854]Epoch 1:  39%|███▉      | 77/196 [01:31<02:21,  1.19s/it, loss=2.162, v_num=6633854]Epoch 1:  39%|███▉      | 77/196 [01:31<02:21,  1.19s/it, loss=2.159, v_num=6633854]